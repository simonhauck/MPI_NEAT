% !TeX spellcheck = de_DE
\section{Evolutionäre Algorithmen}
\label{sec:evolutionary_algos}
Für die Optimierung von \ac{KNN} können verschiedene Algorithmen eingesetzt werden. Der in Kapitel (TODO KApitel) vorgestellte Backpropagation Algorithmus ist hierbei nur ein Beispiel. In dieser Arbeit wird ein Verfahren eingesetzt, welches in Kapitel \ref{sec:neat} vorgestellt wird und zur Gruppe der neuroevolutionären Algorithmen gehört, welche auf den sogenannten \acp{EA} basieren. Zu diesen gehören eine Vielzahl von unterschiedlichen Verfahren, welche dennoch einige gemeinsame Grundprinzipien haben. Ziel von diesen ist, eine möglichst gute Näherungslösung für ein Optimierungsproblem zu finden. Umgesetzt wird dies mit einer simulierten Evolution, welche durch das biolgische Pendant inspiriert ist \cite{weicker2015evolutionare}.
\\\\
Im Folgenden .. 

\subsection{Biologische Evolutionäre Konzepte}
\label{subsec:biological_evolution}
Einer der bedeutendsten Wissenschaftler in Bezug auf die Evolutionstheorie ist Charles Darwin, welcher 1859 mit seiner Arbeit \emph{On the Origin of Species by Means of Natural Selection} einen wichtigen Grundbaustein gelegt hat \cite{russell2013kunstliche}. Theoretisch wird bei Betrachtung der Evolution zwischen unbelebten Systemen und lebenden Organismen unterschieden \cite{weicker2015evolutionare}. Da die \ac{EA} von Letzteren inspiriert sind, wird im weiteren Verlauf dieser Arbeit nur auf diese Bezug genommen.
\\\\
Die später vorgestellten \ac{EA} übernehmen aus der Biologie verschiedene Begriffe, wie zum Beispiel Population, Individuum, Genotyp, Phänotyp, Selektion, Rekombination und Mutation. Diese werden im Folgenden aus Sicht des biologischen Vorbilds betrachtet. Die Erklärungen in dieser Arbeit sind stark vereinfacht und es werden zudem nur die konzeptionellen Prinzipien betrachtet. Der genaue biologische Ablauf ist für diese Arbeit nicht relevant.\\
Eine Population setzt sich aus vielen unterschiedlichen und unabhängigen Individuen zusammen, welche alle zur selben Art gehören. Eine Art ist hierbei so definiert, dass die einzelnen Individuen einen gemeinsamen Genpool teilen und sich miteinander paaren können. Jedes Individuum besitzt ein Genom, welches das genetische Erbgut enthält. Dieses besteht aus mehreren Chromosomen, die wiederum mehrere Gene besitzen \cite{weicker2015evolutionare}. Hierbei kann ein Gen, welches zum Beispiel für die Fell- bzw. Haarfarbe des Individuums verantwortlich ist, verschiedene Werte annehmen. Jede dieser Ausprägungen, in diesem Fall schwarze und braune Haare, werden als Allel bezeichnet \cite{weicker2015evolutionare}. Somit ist das Genom der Bauplan für ein Individuum und bestimmt maßgeblich dessen Erscheinungsbild \cite{kirschbaum2008biopsychologie}. Der Phänotyp wird durch das Genom beeinflusst und beschreibt die tatsächlichen, äußerlich feststellbaren Ausprägungen der einzelnen Gene \cite{weicker2015evolutionare}. Allerdings kann der Phänotyp auch durch die Umwelt beeinflusst werden \cite{kirschbaum2008biopsychologie}. Die Kombination aus Genom und Phänotyp bildet das bereits vorgestellte Individuum. 
\\\\
Nachdem im vorherigen Absatz die grundlegenden Begriffe bezüglich einzelner Individuen erläutert wurden, soll jetzt mit Bezug auf die Evolution die Population als Ganzes betrachtet werden. Die heute existierende Vielfalt an Tier- und Pflanzenarten hat sich über viele Millionen Jahren entwickelt. Der genaue Ursprung, wie die ersten Lebewesen mit Stoffwechselprozessen entstanden sind, ist dennoch unbekannt. Bezüglich der Evolution stellt sich die Frage, wie sich das genetische Material im Laufe der Zeit ändern kann. Hierfür sind fünf Faktoren zu nennen \cite{weicker2015evolutionare}.
\begin{enumerate}
	\item Der erste und wichtigste Faktor sind zufällige Mutationen. Hierbei entstehen beim Vervielfältigen des genetischen Erbguts, zum Beispiel bei der Fortpflanzung, Fehler gemacht, die zu zufälligen Änderungen führen. Hierdurch kann beispielsweise ein neues Allel entstehen, welches zu einer neuen, bisher nicht vorhandenen Haar- bzw. Fellfarbe führt \cite{weicker2015evolutionare}. 
	
	\item Der zweite Faktor betrifft die Selektion. Damit verschiedene Allele langfristig ähnlich häufig in der Population vorkommen, müssen mehrere Faktoren zutreffen. Ein Faktor ist die Überlebenschance der verschiedenen Individuen in der Umwelt, die sogenannte Umweltselektion \cite{weicker2015evolutionare}. Eine auffällige Fellfarbe kann zum Beispiel ein Nachteil sein, da diese von den natürlichen Feinden leichter entdeckt wird. Da diese Individuen häufiger gefressen werden, haben sie eine geringere Chance zur Fortpflanzung und es somit möglich, dass das genetische Material verloren geht. Doch nicht nur die Umweltselektion hat einen Einfluss auf die Anzahl der Nachkommen. Hierfür sind ebenfalls die erfolgreiche Partnersuche sowie Fortpflanzungsrate verantwortlich \cite{weicker2015evolutionare}.
	
	\item Besonders in kleinen Populationen kann der Tod einzelner Individuen große Auswirkungen auf das Verhältnis der unterschiedlichen Allele haben. Hierbei können durch Zufall einzelne Allele komplett verloren gehen und die nachfolgenden Generationen stark beeinflusst werden. In diesem Fall spricht man von Gendrift. Der Effekt hiervon ist bei größeren Populationen vernachlässigbar \cite{weicker2015evolutionare}.
	
	\item Wie bereits beschrieben, sollen sich Individuen einer Art fortpflanzen können. Doch es kommt auch vor, dass Individuen einer Art abwandern und sich an zwei räumlich getrennten Orten weiterentwickeln. Kommt es zu einem späteren Zeitpunkt wieder zu einer Zuwanderung können die neu entwickelten Gene die Population maßgeblich verändern. Dieser Effekt wird auch Genfluss genannt \cite{weicker2015evolutionare}.
	
	\item Der letzte Faktor ist die Rekombination. Bezüglich der biologischen Evolution beschreibt dies den Vorgang der sexuellen Paarung zweier Individuen, sodass ein oder mehrere Nachkommen erzeugt werden. Dabei wird das Ergbut für diese aus einer Kombination der Elterngenome erstellt. Somit handelt es sich aus Sicht der klassischen Evolutionslehre nicht um einen Evaluationsfaktor, da nur Bekanntes neu kombiniert wird und keine neuen Gene oder Allele entstehen. Dennoch wird die Rekombination heute meistens als Evaluationsfaktor genannt. Grund hierfür ist, dass die einzelnen Gene nicht wie lange in der Populationsgenetik angenommen komplett unabhängig voneinander sind, sondern stattdessen stark vernetzt sind und viel Einfluss aufeinander haben. So können auch bei der Kombination von bekannten Genotypen neue phänotypische Eigenschaften entstehen \cite{weicker2015evolutionare}.
\end{enumerate}
Durch die vorgestellten Arten der Evolution kann sich eine Population verschiedensten Umweltsituationen anpassen und gegenüber konkurrierenden Arten behaupten. Beispiel hierfür sind Bakterien, welche Resistenzen gegen bestimmte Antibiotika entwickeln. Während anfänglich nur wenige Individuen die Resistenz besitzen, wird diese aufgrund der hohe Verbreitung von Bakterien schnell an Nachkommen weitergegeben und ist nach kurzer Zeit in der ganzen Population vorhanden.
 
\subsection{Evolutionäre Algorithmen}
\label{subsec:evolutionary_algorithm}
Im vorherigen Kapitel ist die biologische Evolution vorgestellt, durch die eine Vielzahl von unterschiedlichen Lebensformen entstanden ist, die sich sehr gut an ihre jeweilige Umwelt angepasst haben. Da dieses Vorgehen in der Biologie sehr erfolgreich ist, wurden schon im Jahr 1950 erste Versuche durchgeführt, dies auf Computersysteme zu übertragen. Hierbei wird eine bedeutend vereinfachte künstliche Evolution simuliert mit dem Ziel, ein Optimierungsproblem zu lösen \cite{weicker2015evolutionare}. Heute gibt es eine Vielzahl von verschiedenen Algorithmen, die unterschiedliche Aspekte der Evolution imitieren. Im Folgenden werden die Grundkomponenten vorgestellt und verschiedene beispielhafte Umsetzungsmöglichkeiten aufgezeigt.

\subsubsection{Genotyp und Phänotyp}
Wie bei der biologischen Evolution gibt es bei den \ac{EA} Individuen, welche durch ein Genom und einen Phänotyp definiert sind \cite{weicker2015evolutionare}. Das Genom enthält alle Informationen die nötig sind, um den Phänotypen des Individuums zu erstellen. Die eigentliche Form des Phänotyps ist abhängig vom gegebenen Optimierungsproblem und kann je nach Einsatzszenario unterschiedlich umgesetzt sein \cite{rothlauf2006representation}. Die Repräsentation des Genoms ist in vielen klassischen Algorithmen binär. In diesen Fällen wird das Genom durch einen Vektor $x$ von der Länge $l$ repräsentiert, welcher nur aus den Werten $0$ und $1$ besteht, somit gilt $x= (x_1, x_2, ..., x_l) \in \{0, 1\}^l$ \cite{rothlauf2006representation}. Allerdings kann diese Art der Kodierung nicht ausreichend sein. In diesen Fällen kann der Vektor auch natürliche, ganze oder rationale Zahlen enthalten \cite{rothlauf2006representation}. Grundsätzlich sind diese Arten der Repräsentationen nur als Beispiele zu verstehen. Jeder Algorithmus kann die Repräsentation der Genome anpassen, sodass es für das Verfahren zuträglich ist. In Kapitel \ref{subsec:neat_encoding} wird die in dieser Arbeit verwendete Art der Kodierung vorgestellt. 

\subsubsection{Optimierungsproblem}
\label{subsub:optimzation_problem}
Wie bereits beschrieben, ist es das Ziel von \ac{EA}, Optimierungsprobleme zu lösen. Diese können aus vielen verschiednen Bereichen wie Forschung, Wirtschaft sowie Industrie kommen \cite{weicker2015evolutionare} und unterschiedliche Anforderungen haben. Grundsätzlich muss jedes Optimierungsproblem aus einem dreier Tupel $(\Omega, f, \succ)$ bestehen \cite{weicker2015evolutionare}. Die Variable $\Omega$ repräsentiert dabei den Suchraum, also jeden möglichen Lösungsansatz. Dieser wird typischerweise mit einem Individuum und dessen Genom bzw. Phänotyp getestet. Die Funktion $f$ ist definiert als $f: \Omega \rightarrow \mathbb{R}$ und bewertet jeden Lösungsansatz aus dem Suchraum und weist diesem einen reellen Wert zu \cite{weicker2015evolutionare}. Dieser wird auch als Güte- bzw. Fitnesswert bezeichnet. Der letzte Teil des Optimierungsproblems ist eine Vergleichsrelation $\succ \in \{<, >\}$, welche angibt, ob es das Ziel, ist ein Minimum oder Maximum in der Fitnessfunktion zu finden \cite{weicker2015evolutionare}. Im Kontext von \ac{EA} wird meistens das Maximum gesucht, so auch in dieser Arbeit. Daher wird im Weiteren stets angenommen, dass die Maximierung des erreichten Fitnesswertes das Ziel ist.\\
Bei allen Optimierungsproblemen ist die Fitnessfunktion ein elementarer Bestandteil. Nur diese Funktion gibt dem Algorithmus ein Feedback, wie gut oder schlecht eine Lösung ist. Mithilfe dieser Funktion muss jeder \ac{EA} ableiten, in welche Richtung eine Optimierung sich entwickeln soll, um möglichst effizient eine Lösung zu finden \cite{weicker2015evolutionare}. Aus diesem Grund ist die erste Anforderung an eine solche Funktion, dass sie keine absolute sondern eine graduelle Bewertung der verschiedenen Lösungsansätze bietet \cite{weicker2015evolutionare}. Beispiel für eine absolute Bewertung ist, wenn die Fitnessfunktion für eine Lösung den Wert $1$ liefert, wenn das Optimierungsproblem gelöst ist und andernfalls den Wert $0$. In diesem Fall kann nicht festgestellt werden, welche Änderungen der Suchparameter erfolgversprechend sind, somit ist es auch nicht möglich, diese gezielt zu ändern. Infolgedessen müssen mehr Lösungsansätze aus dem Suchraum getestet werden, was den Rechenaufwand und die benötigte Zeit erhöht. Des weiteren muss die Fitnessfunktion möglichst vollständig die Ziele des Optimierungsproblems abbilden. Andernfalls kann zwar durch den Algorithmus das Ergebnis der Fitnessfunktion maximiert werden, aber die hierdurch gefundene Lösung enthält nicht die vom Anwender gewünschten Eigenschaften \cite{weicker2015evolutionare}.

\subsubsection{Ablauf evolutionärer Algorithmen}
Aus den vorherigen Kapiteln ist ersichtlich, dass Individuen aus einem Genotyp sowie Phänotyp bestehen und dass diese versuchen, ein Optimierungsproblem zu lösen. Die Aufgabe eines evolutionären Algorithmus ist es, die Individuen langfristig so anzupassen, dass sie bessere Fitnesswerte in dem Optimierungsproblem erzielen und dementsprechend eine gute Lösung finden. Hierzu werden die aus der Biologie bekannten Verfahren Selektion, Rekombination und Mutation eingesetzt. Bevor in den weiteren Kapiteln verschiedene Umsetzungen beispielhaft vorgestellt werden, wird in diesem Abschnitt der grundlegende Ablauf von \ac{EA} erläutert.
\\\\
Abbildung (TODO ABBILDUNG) zeigt den beispielhaften Ablauf von \ac{EA}, wobei die Phasen Evaluation, Selektion, Mutation und Rekombination die größte Bedeutung haben. Bevor der eigentliche Programmablauf starten kann, muss eine erste initiale Population erzeugt werden. Wie in der biologischen Evolution, besteht diese auch in diesem Fall aus mehreren unabhängigen Individuen \cite{rothlauf2006representation}. Im Gegensatz zum biologischen Vorbild verwenden die meisten Algorithmen ein feste Populationsgröße, da ansonsten die später benötigte Evaluationszeit und der damit verbundene Rechenaufwand stark ansteigen könnte \cite{rothlauf2006representation}. Die für die Individuen benötigten Genome werden zufällig erstellt \cite{weicker2015evolutionare}, wobei je nach Algorithmus verschiedene Zufallsverteilungen genutzt werden können.
\\\\
Danach beginnt die Evaluationsphase mit der initialen Population \cite{rothlauf2006representation}. Hierfür wird der Phänotyp für jedes Individuum mit dem entsprechenden Genom gebildet. Jeder von diesen stellt eine mögliche Lösung für das gegebene Optimierungsproblem dar. Wie im vorherigen Kapitel beschrieben, muss dieses eine Fitnessfunktion enthalten, mit welcher jeder Phänotyp bewertet wird. An dieser Stelle soll nochmals hervorgehoben werden, dass die Gesamtheit aller Gene den Phänotyp bestimmen und daher keine Bewertung der einzelnen Gene möglich ist \cite{rothlauf2006representation}. Die Evaluationsphase endet, wenn für alle Phänotypen ein Fitnesswert ermittelt ist. Der nächste Schritt ist die Überprüfung einer Abbruchbedingung. Trifft diese zu, wird die Ausführung des Algorithmus abgebrochen und das Genome des besten Individuums als Ergebnis zurückgegeben \cite{weicker2015evolutionare}. Je nach Umsetzung der Abbruchbedingung kann zum Beispiel überprüft werden, ob ein gewisser Fitnesswert überschritten und somit eine Lösung mit der gewünschten Genauigkeit bzw. Korrektheit gefunden wurde oder ob eine vorher definierte maximale Ausführungszeit überschritten ist.
\\\\
Die Abbruchbedingung wird zu Beginn mit sehr hoher Wehrscheinlicht nicht erfüllt sein, da die Genome nur zufällig erstellt sind und bisher kein Lernprozess durchgeführt wurde. In diesem Fall werden die Phasen Selektion, Rekombination und Mutation durchgeführt \cite{rothlauf2006representation}. Diese werden in den folgenden Kapiteln ausführlich erläutert, daher wird in diesem Abschnitt nur ein kurzer Überblick gegeben. In der ersten Phase, der Selektion, wird auf Basis des erhaltenen Fitnesswertes für jedes Individuum festgelegt, ob und wenn ja wie viele Nachkommen dieses erzeugen darf \cite{weicker2015evolutionare}. Bei der Rekombination werden die tatsächlichen Nachkommen erzeugt. Typischerweise werden zwei, in machen Fällen auch mehr Individuen als Elterngenome ausgewählt und gekreuzt. Bei diesem Vorgang wird das genetische Material, welches in den Genomen der Eltern-Individuen enthalten ist, gemischt und an das neu erstellte Kind-Individuum übertragen. Das Ziel dieser Operation ist, dass das Kind immer einen Teil der Gene von beiden Eltern erhält und somit auch Eigenschaft von beiden vereint. Langfristig sollen sich durch ein solches Verfahren nur die besten Gene durchsetzen \cite{weicker2015evolutionare}. 
Die letzte Phase ist die Mutation. In diesem Schritt besteht für jedes neu erstellte Individuum die Wahrscheinlichkeit, dass ein kleiner Teil des Genoms zufällig abgeändert wird \cite{rojas1996neural}. Die Art der Mutation ist hierbei abhängig von der Umsetzung des Genotypen und dem Algorithmus. Bezüglich der drei Phasen muss verdeutlicht werden, dass die Selektion auf Basis des Phänotypen mit dem Fitnesswert erfolgt, die Rekombination und Mutation hingegen auf Basis des Genotypen. Somit können keine Eigenschaften, die im Phänotyp gespeichert sind auf die Nachkommen übertragen werden \cite{rothlauf2006representation}.
\\\\
Nach Abschluss dieser drei Phasen sind die neuen Individuen fertig erstellt. Da, wie bereits in diesem Kapitel beschrieben, die Populationsgröße meistens begrenzt ist, wird an dieser Stelle typischerweise die Elterngeneration komplett entfernt und durch dieselbe Anzahl an Nachkommen ersetzt \cite{weicker2015evolutionare}. Allerdings gibt es auch andere Ansätze, bei denen nicht so viele neue Individuen gleichzeitig erstellt werden und diese dann direkt in die bestehende Population integriert werden können \cite{stanley2005real}. Die neue Population mit den neuen Individuen durchläuft dieselben Schritte wie die vorherige Population. Ein kompletter Durchlauf des vorgestellten Zyklus wird als eine Generation bezeichnet \cite{weicker2015evolutionare}. Häufig wird die neu erstellte Population daher auch als neue Generation bezeichnet. 

\subsubsection{Selektion}
\label{subsubsec:ea_selection}
Bei \ac{EA} werden viele Individuen eingesetzt, um verschiedene Lösungsansätze gleichzeitig zu betrachten. In der Phase der Selektion wird bestimmt, welche Individuen als Elternteil für die nächste Generation ausgewählt werden und wie viele Nachkommen ihnen zustehen. Bei einem solchen Auswahlverfahren ist zwischen zwei grundlegenden Umsetzungen zu unterscheiden. Entweder kann allen Individuen einer Generation dieselbe Menge an Nachkommen zugewiesen werden oder die Anzahl ist abhängig von dem erreichten Fitnesswert. Typischerweise wird die zweite Variante in \ac{EA} verwendet, welche auch als fitnessproportionale Selektion bezeichnet wird. Die erste Variante erzeugt keinen Selektionsdruck, da die Individuen unabhängig von ihrer Leistung Nachkommen zugewiesen bekommen. Bei der zweiten Variante werden Individuen mit höheren Fitnesswerten bevorzugt, mit dem Ziel, dass sich die positiven Eigenschaften der erfolgreichen Individuen durchsetzen und schlechte aussterben. Dennoch ist es nicht das Ziel, nur die allerbesten Genome als Elternteile auszuwählen. Wäre dies der Fall, würde die Population sehr schnell konvergieren, ihre Vielfalt verlieren und nur noch ähnliche Lösungsansätze bieten. Somit wird es unwahrscheinlich, dass neue unbekannte, aber eventuell bessere Lösungsstrategien gefunden werden \cite{weicker2015evolutionare}. 
\\\\
Der genaue Selektionsvorgang, wie er mi Algorithmus dieser Arbeit umgesetzt ist, wird in Kapitel \ref{subsec:neat_species} erläutert. Im Folgenden werden zwei verschiedene Varianten der fitnessproportionalen Verfahren vorgestellt, die in anderen Algorithmen als Selektionsfunktion verwendet werden. Bei diesen wird die Anzahl an Nachkommen durch den jeweils erreichten Fitnesswert beeinflusst \cite{weicker2015evolutionare}.

\begin{enumerate}
	\item \textbf{Probabilistische Selektion}:\\
	Einer der bekanntesten Umsetzungen ist die probabilistische Selektion, welche grundsätzlich einfach zu implementieren ist. Im ersten Schritt werden die erreichten Fitnesswerte $f$ der einzelnen Individuen $i$ in der Population $P$ aufsummiert. Im zweiten Schritt wird für jedes Individuum $j$ die Wahrscheinlichkeit $Pr[j]$ berechnet, welche angibt, wie groß die Chance ist, dass dieses als Elternteil ausgewählt wird. Hierzu muss der erhaltene Fitnesswert durch die bereits berechnete Summe geteilt werden. Somit ergibt sich die Formel $Pr[j]=\frac{f_j}{\sum_{i \in P}f_i}$. Diese Art der Selektion ist in vielen Anwendungsfällen sehr erfolgreich. Allerdings kann es vorkommen, dass zum Beispiel bei sehr hohen Fitnesswerten die prozentualen Unterschiede zwischen guten und schlechten Individuen sehr gering sind und infolgedessen der Selektionsvorteil für gute Lösungen niedrig ist. Ein möglicher Lösungsansatz besteht in der Skalierung der Fitnesswerte, sodass auch bei hohen Durchschnittswerten kleine Steigerungen einen evolutionären Vorteil bieten \cite{weicker2015evolutionare}. Ein weiterer Lösungsansatz ist die Verwendung der rangbasierten Selektion, welche im Folgenden vorgestellt wird.
	
	\item  \textbf{Rangbasierte Selektion}:\\
	Bei der rangbasierten Selektion ist der tatsächlich erhaltene Fitnesswert nicht von Bedeutung. Die Individuen werden bezüglich ihrer Fitness geordnet. Das beste Individuum erhält die größte und das schlechteste Individuum die geringste Wahrscheinlichkeit, als Elternteil ausgewählt zu werden \cite{weicker2015evolutionare}. 
\end{enumerate}
% TODO ABBILDUNG
Sind die Wahrscheinlichkeiten für alle Individuen berechnet, ist im letzten Schritt festzulegen, welche Genome tatsächlich als Elternteile ausgewählt werden und wie viele Nachkommen diese erzeugen. Bei der fitnessproportionalen Selektion wird hierfür ein Zufallsgenerator benötigt, welcher basierend auf den Wahrscheinlichkeiten die Elterngenome auswählt. Dies wird häufig mit einem Roulette-Rad veranschaulicht. Die Felder am Rand der Scheibe entsprechen den verschiedenen Individuen und die Größe ist proportional zur berechneten Wahrscheinlichkeit. Für jedes auszuwählende Elternindividuum wird der Zeiger zufällig gedreht und das Individuum  entsprechend zu dem gewählten Feld wird verwendet (TODO ABBILDUNG). Dieses Verfahren kann einen Nachteil haben. Obwohl das beste Individuum die höchste Wahrscheinlichkeit hat, als Elternteil ausgewählt zu werden, kann es auf Basis des Zufalls dazu kommen, dass dieses nicht verwendet wird. Da typischerweise die Population am Ende des Evolutionszyklus ersetzt wird, würde das genetische Material dieses Individuums verloren gehen \cite{weicker2015evolutionare}. 
\\\\
Um einen solchen Verlust zu verhindern, kann bei der Selektion zusätzlich ein sogenannter Elitismus verwendet werden. Hierbei wird typischerweise der Genotyp des besten Individuums ausgewählt, kopiert und unverändert wieder in die nächste Generation eingesetzt \cite{such2017deep}. Zu Beachten ist hierbei, dass im weiteren Verlauf ein Nachkomme weniger produziert wird um eine konstante Populationsgröße zu garantieren. 

\subsubsection{Rekombination}
\label{subsubsec:ea_recombination}
Die Phase der Rekombination wird auch als \emph{Crossover} bezeichnet und findet nach der Selektion statt. Die Aufgabe von dieser ist, die ausgewählten Elternindividuen zu nutzen um neue Nachkommen zu erstellen. Typischerweise werden zwei, in einigen Fällen noch mehr Elternteile kombiniert um mindestens ein Kind-Individuum zu erzeugen \cite{weicker2015evolutionare}. Die Rekombination gilt als eine der wichtigsten Phasen, da die Nachkommen tendenziell bessere Ergebnisse erzielen sollen als die Elternteile \cite{russell2013kunstliche}. Wie auch bei anderen Phasen der \ac{EA} gibt es verschiedene Arten der Umsetzung, die als kombinierende, interpolierende und extrapolierende Selektion bezeichnet werden \cite{weicker2015evolutionare}. Die bekannteste dieser drei Varianten ist die kombinierende Selektion, welche sowohl in dieser Arbeit als auch in vielen anderen Algorithmen verwendet wird. Die beiden Alternativen werden bedeutend seltener gewählt und sind auch in der Literatur oft nicht erwähnt. Dennoch werden im Folgenden alle Varianten kurz vorgestellt.
\\\\
Die kombinierende Rekombination ist stark von der Biologie inspiriert. Bei diesem Vorgang werden die Genome der Elternteile zuerst nebeneinander aufgereiht. Im zweiten Schritt wird zufällig entschieden, welcher Abschnitt von welchem Elternteil für das Genom des Nachkommen verwendet werden sollen \cite{weicker2015evolutionare}. Der Vorteil dieses Verfahrens ist, dass große Informationsblöcke, welche unabhängig voneinander optimiert wurden und sinnvolle Funktionen realisieren, von den Elternteilen geerbt werden können \cite{russell2013kunstliche}. Der aus der Rekombination entstehenden Nachkomme kann hierdurch einen Vorteil bei der Evaluation besitzen und letztendlich eine bessere Lösung für das Optimierungsproblem bieten. Da diese Art der Rekombination keine neuen Gene erstellt bzw. bestehende modifiziert, ist der Erfolg abhängig davon, ob die Population eine gewisse Diversität bietet, sodass bei der Rekombination tatsächlich verschiedene Gene kombiniert werden können \cite{weicker2015evolutionare}. In der praktischen Umsetzung muss zuletzt noch entschieden werden, an welchen Stellen eine Rekombination möglich ist \cite{rojas1996neural}. Bei der uniformen Rekombination wird für jedes einzelne Gen unabhängig zufällig entschieden, von welchem Elternteil es übernommen wird \cite{weicker2015evolutionare}. Allerdings gibt es auch andere Umsetzungen, bei denen die Gene in Gruppen eingeteilt werden und dann zwischen diesen zufällig entschieden wird.
\\\\
Bei der interpolierenden Rekombination, werden die einzelnen Gene nicht direkt von einem Elternteil übernommen, stattdessen werden sie gemischt, sodass ein neuer Wert entsteht, der sich zwischen den Werten der Elternteile befindet. Im Gegensatz zur kombinierenden Selektion, welche versucht die Diversität zu erhalten, wird diese hierbei deutlich verringert. Aus diesem Grund ist es notwendig, dass zu Beginn eine Population mit einer großen Diversität vorhanden ist, sodass der Suchraum  des Optimierungsproblems ausgiebig überprüft wird. Ein Beispiel für eine solche technische Umsetzung ist die sogenannte Arithmetische-Rekombination, welche für reellwertig repräsentierte Genome verwendet werden kann. Angenommen die Werte $A_i$ und $B_i$ repräsentieren die Gene der Eltern $A$ und $B$, dann wird für jedes Gen $i$ eine Zufallszahl $u$ zwischen $0$ und $1$ gewürfelt. Das Gen $C_i$ des Nachkommen $C$ wird dann berechnet mit $C_i=u \cdot A_i + (1-u) \cdot B_i$ \cite{weicker2015evolutionare}.
\\\\
Die letzte Variante ist die extrapolierende Rekombination, welche mit mehreren Elternteilen versucht, eine Prognose darüber abzugeben, wo im Lösungsraum eine Steigerung des Fitnesswertes möglich ist und dementsprechend versucht die Genome der Nachkommen zu ändern. Somit kann diese Art der Rekombination auch neue Gene erstellen. Ein solches Verfahren hat allerdings zwei Nachteile. Um eine Prognose abzugeben, ist es erstens nötig ein Grundwissen über den Lösungsraum zu haben, zweitens besteht die Gefahr, dass die vorgegebene Richtung nicht korrekt und die Funktion danach nicht fähig ist, eine systematische Suche durchzuführen \cite{weicker2015evolutionare}.   

\subsubsection{Mutation}
\label{subsubsec:ea_mutation}
Der letzte Schritt, bevor die bestehende Population durch die neu erstellten Individuen ersetzt wird, ist typischerweise die Mutation. Allerdings ist die Funktionsweise und Relevanz dieser Phase stark abhängig von der verwendeten Kodierung und dem eigentlichen Algorithmus \cite{weicker2015evolutionare}. Zum Beispiel wird in Quelle \cite{such2017deep} gar keine Reproduktion verwendet und die Optimierung wird nur mithilfe der Mutation umgesetzt, während in anderen Quellen, wie zum Beispiel in \cite{zoller2007kunstliche}, diese Phase als untergeordnet beschrieben wird, welche nur selten eingesetzt werden sollte.
\\\\
Wird die Mutation häufig verwendet, erfüllt sie zwei Aufgaben. Das erste Ziel ist die Feinabstimmung der einzelnen Individuen, sodass das tatsächliche Optimum so genau wie möglich erreicht wird. Das zweite Ziel ist die Erforschung des Suchraums, welche stichprobenartig durchgeführt wird, um ein besseres Optimum zu finden \cite{weicker2015evolutionare}.  Wird die Mutation selten eingesetzt, müssen die Funktionen Feinabstimmung und Erforschung durch andere Komponenten, wie zum Beispiel der Rekombination, durchgeführt werden. In diesem Fall ist es das Ziel der Mutation neue Diversität, in die Population zu bringen, beziehungsweise diese zu erhalten \cite{weicker2015evolutionare}. Denn wie bereits im vorherigen Kapitel beschrieben, ist vor allem bei der viel verwendeten Rekombination die Diversität sehr wichtig, allerdings wird diese meistens durch die Rekombination selbst verringert.
\\\\
Da die Umsetzung der Mutation sowohl von der Kodierung und dem Algorithmus abhängig ist, gibt es keine Empfehlungen, welche Implementierung besonders viele Vorteile bietet. Im Folgenden werden zwei mögliche Beispiele vorgestellt, wobei das erste für Individuen mit einer binären und das zweite für eine reellwertige Repräsentation angewendet werden kann \cite{weicker2015evolutionare}. Die einfachste Mutation ist die Binär-Mutation, welche für Genome mit einer binären Repräsentation verwendet werden kann. Bei der Mutation wird für jedes Bit eine Zufallszahl $u$ zwischen $0$ und $1$ gewürfelt. Ist diese kleiner als die festgelegte Mutationswahrscheinlichkeit $p_m$, wird das Bit invertiert. Sind die Individuen durch reellwertige Zahlen repräsentiert, ist die sogenannte Gauss-Mutation eine mögliche Umsetzung. Bei dieser wird für jedes Gen eine Zufallszahl basierend auf einer Gauss-Verteilung gewählt, wobei eine zuvor festgelegte Standardabweichung $\sigma$ die Verteilung beeinflusst. Die hierdurch erhaltene Zahl wird auf den bereits bestehenden Wert addiert \cite{weicker2015evolutionare}.

\subsection{Neuroevolution}
Wie im vorherigen Kapitel erläutert, sind \ac{EA} Verfahren, um möglichst gute Näherungslösungen für verschiedene Optimierungsprobleme zu finden. Für die in Kapitel \ref{sec:neuroal_networks} vorgestellten \ac{KNN} wird ein Verfahren benötigt, welches die verschiedenen anpassbaren Parameter optimiert. Es ist dementsprechend möglich, die evolutionären Prinzipien zur Optimierung von \ac{KNN} einzusetzen. Dies wird als Neuroevolution bezeichnet \cite{meisner2009neurostrategies}. Algorithmen dieser Art sind somit eine Alternative zu den klassischen Verfahren, wie zum Beispiel dem Backpropagation Algorithmus \cite{whitley1993genetic}. 
\\\\
Im Vergleich zu diesem haben neuroevolutionäre Verfahren sowohl Vor- als auch Nachteile, welche ausführlich in Kapitel (TODO Kapite) beschrieben werden. Dennoch soll ein großer Vorteil bereits hier genannt sein. Das Ziel der meisten neuroevolutionären Algorithmen ist das Optimieren von Verbindungsgewichten und Schwellwerten. Einige Verfahren versuchen, zusätzlich die Struktur bzw. Topologie des \ac{KNN} zu optimieren, sodass diese nicht mehr manuell durch einen Entwickler festgelegt werden muss. Wie in Kapitel \ref{subsec:network_structures} beschrieben, ist die Topologie ein entscheidender Faktor und kann das erfolgreiche Lösen maßgeblich beeinflussen. Diese Algorithmen werden als \ac{TWEANN} Verfahren bezeichnet \cite{stanley2002evolving}. 
\\\\
Auch der in Kapitel \ref{sec:neat} vorgestellte Algorithmus optimiert sowohl die Topologie als auch die Gewichte eines \ac{KNN}. Im Folgenden wird der Ablauf von neuroevolutionären Algorithmen vorgestellt und die Besonderheiten erläutert. Danach wird auf die Vor- und Nachteile eingegangen.

\subsubsection{Ablauf Neuroevolution}
Der grundsätzliche Ablauf von neuroevolutionären Algorithmen ist fast identisch zu den klassischen \ac{EA}. Auch bei diesen gibt es eine Population, welche aus verschiedenen Individuen besteht, die einen Genotyp und Phänotyp besitzen. Letzteres besteht bei der Neuroevolution aus einem \ac{KNN}, welches durch den Genotyp kodiert ist. Auch die Definition des Optimierungsproblems ist identisch zu der Erklärung in Kapitel \ref{subsub:optimzation_problem}. Ein Phänotyp, in diesem Fall ein \ac{KNN}, versucht, das Optimierungsproblem zu lösen und erhält hierdurch einen Fitnesswert, welcher angibt, wie gut oder schlecht die Lösung ist. Wenn dieser Wert für alle Mitglieder einer Population berechnet ist, beginnen die Phasen Selektion, Rekombination und Mutation. Hierdurch werden neue Individuen mit neuen Genotypen und Phänotypen erstellt, welche dann die vorherige Population ersetzen. Dieser Zyklus wird so oft wiederholt, bis eine Abbruchbedingung erreicht ist. Natürlich ist es möglich, dass die praktische Umsetzung je nach Algorithmus angepasst wird. Einige grundlegende Anpassungen werden in den folgenden Abschnitten erläutert. Wie die angesprochenen Punkte von dem in dieser Arbeit verwendeten Algorithmus umgesetzt werden, wird in Kapitel \ref{sec:neat} erläutert.


\subsubsection{Genotyp und Phänotyp}
Eine Komponente, die auf jeden Fall angepasst werden muss, ist der Genotyp. Dieser muss alle optimierbaren Parameter für den Phänotyp kodieren. Typischerweise umfasst dies die Struktur des Netzes, die Gewichte der Verbindungen sowie die Schwellwerte \cite{stanley2002evolving}. Die Propagierungs-, Aktivierungs- und Ausgabefunktion müssen nur enthalten sein, wenn diese ebenfalls durch den \ac{EA} angepasst werden. Hierdurch ergibt sich die Frage, wie diese Informationen im Genom zu Kodieren sind, sodass auch eine erfolgreiche Durchführung der Rekombinations- und Mutationsphase möglich ist. 
\\\\
%TODO Check Absatz
Grundsätzlich gibt es zwei verschiedene Kodierungansätze, die ein Algorithmus verwenden kann. Diese werden als direkte und indirekte Kodierung bezeichnet. Bei einer direkten Kodierung wird im Genom jede einzelne Verbindung und jedes Neuron explizit spezifiziert, sodass diese einfach im Phänotyp übernommen werden können. Diese Art der Kodierung wird sehr häufig verwendet, da sie einfach zu implementieren ist und auch die Rekombination und Mutation damit gut umsetzbar sind. Die Alternative ist die indirekte Kodierung. Diese spezifiziert Regeln, die angeben, wie aus einem Genom ein \ac{KNN} erstellt werden soll. Der Vorteil hiervon ist, dass nicht jede Verbindung und jedes Neuron einzeln kodiert werden muss, die Repräsentation dementsprechend kompakter ist und somit weniger Rechenkapazität zur Speicherung benötigt wird \cite{stanley2002evolving}. Nachteil von dieser Methode ist, dass die Rekombination und Mutation komplexer umzusetzen sind. Im Folgenden wird nur noch auf die direkte Kodierung Bezug genommen, da diese in dieser Arbeit verwendet wird.
\\\\
Theoretisch kann für eine direkte Kodierung des Genoms, wie bei klassischen \ac{EA}, eine binäre Repräsentation verwendet werden. Umsetzbar ist dies mit einer Matrix, welche für jede mögliche Verbindung angibt, ob diese besteht oder nicht. Allerdings hat eine solche Kodierung einige Nachteile, weswegen sie für diesen Anwendungsfall eher ungeeignet ist. Ein Grund ist der benötigte Speicherplatz für ein einzelnes Genom. Die Matrix enthält für ein \ac{KNN} mit $n$ Neuronen insgesamt $n^2$ Einträge für die möglichen Verbindungen \cite{stanley2002evolving}. Für große neuronale Netze skaliert dieser Ansatz schlecht.
\\\\
Alternativ ist hierzu eine Graphen-Kodierung, welche auch von vielen \ac{TWEANN} Algorithmen verwendet wird. Eine mögliche Umsetzung hiervon ist in der Arbeit \cite{pujol1998evolving} von \citeauthor{pujol1998evolving} vorgestellt. Bei diesen besteht die Kodierung aus zwei Teilen. Der erste Teil beschreibt die Struktur des Graphen beziehungsweise des \ac{KNN}, während der zweite Teil ein linearer Vektor ist, welcher die Neuronen und Verbindungen enthält. In dieser Arbeit wird eine weitere Variante verwendet, welche ausführlich in Kapitel \ref{subsec:neat_encoding} erläutert wird.

\subsubsection{Rekombination}
Chronologisch gesehen findet die Selektion vor der Rekombination statt. Da sich diese Phase nicht ändert, wird im Folgenden mit der Rekombination fortgefahren. Prinzipiell ist das Verfahren dasselbe wie in Kapitel \ref{subsubsec:ea_recombination} beschrieben. Die Selektion hat zwei Elterngenome ausgewählt und diese werden im Rahmen der Rekombination zu einem neuen Genom kombiniert. Typischerweise wird bei diesem Vorgang zufällig entschieden, welche Verbindung von welchem Elternteil übernommen werden soll. Das Ziel ist, ein \ac{KNN} zu erzeugen, welches in den meisten Fällen die positiven Eigenschaften der Eltern erbt und somit insgesamt besser wird. Eine Schwierigkeit, die hierbei im Bezug zu Neuroevolution entstehen kann wird als das \emph{Competing Conventions} Problem bezeichnet \cite{stanley2002evolving}.
\\\\ % TODO Comepting Conevntions ABbildung da
Der Begriff \emph{Competing Conventions} beschreibt ein Phänomen, bei dem mehrere \ac{KNN} dieselbe Lösung für ein Optimierungsproblem bieten, aber sich die Repräsentationen der Genome dennoch unterscheiden. Ein solches Beispiel ist in Abbildung (TODO Abbildung) dargestellt. Die beiden \ac{KNN} besitzen je drei verdeckte Neuronen (4, 5, 6) mit den dazugehörigen Verbindungen in den Farben blau (B), rot (R) und grün (G). Die tatsächlichen Gewichte sind hierbei nicht von Interesse und werden deshalb für eine bessere Übersichtlichkeit durch die Farben repräsentiert. Das erste \ac{KNN} kann beispielsweise durch den Vektor (B, R, G) und das zweite \ac{KNN} durch den Vektor  (G, R, B) kodiert werden. Es wird hierbei angenommen, dass in der Kodierung die einzelnen Gewichte für alle Verbindungen enthalten sind. \\\\
Wie aus der Abbildung zu erkennen ist, sind die beiden \ac{KNN} symmetrisch und produzieren infolgedessen für dieselbe Eingabe auch dasselbe Ergebnis. Dennoch unterscheiden sich die Genotypen bezüglich ihrer Kodierung. Werden diese beiden \ac{KNN} durch die Selektion ausgewählt um einen Nachkommen zu erzeugen, wird das \emph{Competing Conventions} Phänomen wahrscheinlich zu einem Problem führen. \\\\
Wie bei traditionellen \ac{EA} wird auch bei der Neuroevolution typischerweise zufällig entschieden, von welchem Elternteil welches Gen übernommen werden soll. Angenommen, es werden die ersten beiden Gene vom linken Elternteil und das letzte Gen vom rechten Elternteil übernommen, dann ist das daraus resultierende neue Genom kodiert mit (B, R, B). Es ist ersichtlich, dass bei diesem Vorgang ein Drittel der Informationen verloren gegangen sind beziehungsweise nicht vererbt wurden. Dies ist in den meisten Fällen ein großes Problem, da der fehlende Teil mit hoher Wahrscheinlichkeit einen notwendigen Beitrag für einen Lösungsansatz kodiert hat, der das Elterngenom erfolgreich gemacht hat. Aus diesem Grund wird das neu erstellte Individuum wahrscheinlich weniger erfolgreich sein als seine Elternindividuen, erhält einen dementsprechend niedrigeren Fitnesswert und wird letztendlich aussterben \cite{stanley2002evolving}. Tritt dieser Fall nur bei einem einzelnen Genom in einer Population auf, sind die Auswirkungen meistens vernachlässigbar. Allerdings gibt es für ein \ac{KNN} mit $x$ verdeckten Neuronen in einer Schicht $x!$ viele Kombinationsmöglichkeit, dieselbe Lösung durch unterschiedliche Genome zu repräsentieren \cite{stanley2002evolving}. Somit ist die Wahrscheinlichkeit relativ hoch, dass das \emph{Competing Conventions} Problem eintritt. Die Folge ist, dass entweder viel Rechenzeit für Genome verwendet wird, die mit hoher Wahrscheinlichkeit keine besseren Lösungen bereit stellen und dadurch das Optimierungsverfahren bedeutend länger dauert, oder dass das Verfahren scheitert, da keine ausreichend gute Lösung gefunden werden kann. 
% Viele fälle, mehr rechenzeit oder unmöglich 
\\\\
Bei den \ac{TWEANN} Algorithmen ist das \emph{Competing Conventions} Problem noch größer \cite{stanley2002evolving}. Wie bereits beschrieben, versuchen diese, auch die Struktur des \ac{KNN} zu optimieren und können im Zuge dessen neue Neuronen und Verbindungen hinzufügen. Im nächsten Kapitel wird hierauf genauer eingegangen. An dieser Stelle sei vorweggenommen, dass im Laufe des Optimierungsverfahrens eine Population mit unterschiedlichen Strukturen und Topologien entstehen kann. Hierbei stellt sich die Frage, wie unterschiedliche \ac{KNN} rekombiniert werden können, wenn die Genome unterschiedlich groß sind und nicht zuzuordnen ist, welche Gene der Eltern rekombiniert werden können. Dies ist die schwierigste Form des \emph{Competing Conventions} Problems \cite{stanley2002evolving}. Wie der in dieser Arbeit verwendete Algorithmus dieses Problem löst, ist in Kapitel \ref{sec:neat} erläutert.

\subsubsection{Mutation}
Neuroevolutionäre Algorithmen setzen in der Regel häufig die Mutation ein. Hierbei wird zwischen zwei Arten unterschieden. Bei der ersten Art werden nur die Verbindungsgewichte und Schwellwerte mutiert. Hierfür kann die bereits in Kapitel \ref{subsubsec:ea_mutation} vorgestellte Gauss-Mutation verwendet werden, wobei der erhaltene Zufallswert auf das Gewicht bzw. den Schwellwert addiert wird \cite{mcintyre_neatpython}. Die zweite Art verändert die Topologie und wird als strukturelle Mutation bezeichnet. Diese Art wird somit nur für die \ac{TWEANN} Verfahren benötigt, welche neue Neuronen und Verbindungen dem \ac{KNN} hinzuzufügen können \cite{stanley2002evolving}.
\\\\
Das eigentliche Hinzufügen von neuen Strukturen ist technisch einfach umzusetzen. Zum Beispiel kann eine neue Verbindung mit einem zufälligen Gewicht jederzeit zwei zuvor nicht verbundene Neuronen verknüpfen. Allerdings wird hierdurch der Fitnesswert in den meisten Fällen initial sinken, da es unwahrscheinlich ist, dass eine zufällige Struktur eine nützliche Funktionalität oder Teillösung bietet. Infolgedessen sinkt auch die Chance, dass das Genom bei der Selektion in der nächsten Generation als Elternteil ausgewählt und die neue Struktur an die Nachkommen vererbt wird. So kommt es häufig vor, dass die strukturellen Innovationen direkt in der nächsten Generation verloren gehen, auch wenn sie für eine erfolgreiche Lösung nötig wären. Die daraus resultierende Herausforderung für \ac{TWEANN} Verfahren ist, neue Innovationen am Anfang zu schützen, sodass der Algorithmus diese optimieren kann. Nur so ist es möglich, neue Strukturen langfristig in die Population zu integrieren \cite{stanley2002evolving}.
\\\\
Eine mögliche Lösung hierfür ist in der Arbeit von \citeauthor{angeline1994gnarl} vorgestellt. Hierbei werden neue Neuronen ohne jegliche Verbindungen in das \ac{KNN} eingefügt, während neue Verbindungen initial das Gewicht $0$ haben. Die so hinzugefügten Strukturen haben anfänglich keinen Effekt auf das \ac{KNN}. Ziel hiervon ist, dass der Fitnesswert nicht absinkt und sich die Strukturen im Laufe von mehreren Generationen selbstständig entwickeln \cite{angeline1994gnarl}. Diese Umsetzung ist nicht ideal, da die Strukturen unter Umständen nicht richtig in das \ac{KNN} integriert werden, aber dennoch die benötigte Rechenkapazität erhöhen \cite{stanley2002evolving}.
\\\\
Der in Kapitel \ref{sec:neat} vorgestellte Algorithmus verfolgt einen anderen Ansatz, bei dem ähnliche \ac{KNN} einer Spezies zugeordnet werden. Ein Individuum soll nicht mehr mit der ganzen Population konkurrieren, sondern nur mit denen seiner Spezies. Dies wird auch als \emph{niching} bezeichnet. Eine neue große strukturelle Mutation wird einer neuen Spezies zugeordnet und kann innerhalb dieser entwickelt und optimiert werden. Hierfür wird eine Kompatibilitätsfunktion benötigt, welche bestimmen kann, ob ein Genom einer Spezies zugehörig ist. Die Umsetzung von dieser Funktion wird durch das \emph{Competing Conventions} Problem erschwert \cite{stanley2002evolving}. In Kapitel \ref{subsec:neat_species} wird hierauf genauer eingegangen.
 
\subsubsection{Initiale Population}
Die initiale Population der ersten Generation enthält zufällig erstellte \ac{KNN}. Die hierfür benötigten Verbindungsgewichte und Schwellwerte werden häufig zufällig mithilfe einer Gauss-Verteilung gewählt \cite{mcintyre_neatpython}. Die Wahl der initialen Topologie kann sich aber stark unterscheiden. Bei den neuroevolutionären Algorithmen, welche nur die Verbindungsgewichte und Schwellwerte optimieren, wird diese zu Beginn einmalig für alle \ac{KNN} festgelegt und ändert sich auch nicht im Lauf des Verfahrens. 
\\\\
Bei den \ac{TWEANN} Algorithmen hingegen können verschiedene initiale Topologien verwendet werden, welche unter anderem die Laufzeit des Algorithmus stark beeinflussen können. Viele dieser Algorithmen erstellen zu Beginn verschiedene zufällig gewählte Topologien, mit dem Ziel, Diversität in die Population zu bringen. Ein Nachteil dieser Strategie ist, dass hierbei ungeeignete \ac{KNN} entstehen können, bei denen beispielsweise nicht alle Eingabeneuronen mit allen Ausgabeneuronen verbunden sind. Zudem ergibt sich in diesem Fall noch ein weiteres Problem \cite{stanley2002evolving}. Grundsätzlich ist es sinnvoll, die kleinst mögliche Struktur zu wählen, die dennoch einen mit größeren \ac{KNN} vergleichbaren Fitnesswert für ein Optimierungsproblem erzielt \cite{zhang1993evolving}. Diese hat im Vergleich zu größeren Strukturen weniger anpassbare Parameter, was generell die benötigte Optimierungszeit reduziert. Wenn die Topologien zufällig erstellt sind, werden hierbei viele unnötige Strukturen enthalten sein, was zu einem größeren Suchraum führt und die Laufzeit des Optimierungsverfahrens erhöht \cite{stanley2002evolving}. 
\\\\
In einem solchen Fall muss das Optimierungsverfahren versuchen, die Größe des \ac{KNN} aktiv zu minimieren. Ein Ansatz diesbezüglich ist in der Arbeit von \citeauthor{zhang1993evolving} beschrieben, in welcher die Größe des \ac{KNN} den Fitnesswert beeinflusst. In diesem Fall haben kleinere \ac{KNN} bei gleicher Performance hinsichtlich des Optimierungsproblems einen größeren Fitnesswert und dementsprechend eine größere Chance, bei der Selektion ausgewählt zu werden. Das endgültige Ziel hierbei ist, dass langfristig nur die benötigten Strukturen erhalten bleiben \cite{zhang1993evolving}. Auch wenn die zugrunde liegende Idee gut ist, 
kann in der Praxis die Entscheidung schwierig sein, wie viel Einfluss die Größe des \ac{KNN} tatsächlich auf den Fitnesswert haben soll \cite{stanley2002evolving}.
\\\\
Eine weiterer Lösungsansatz ist das Starten mit einer minimalen Struktur, sodass das \ac{KNN} zu Beginn keine verdeckten Neuronen besitzt. Neue Strukturen werden nur integriert, wenn sie einen höheren Fitnesswert ermöglichen. Der Vorteil dieser Strategie ist, dass keine Rechenzeit verwendet werden muss, um unnötige Strukturen zu entfernen und dass zusätzlich die Anzahl an anzupassenden Parametern gering ist \cite{stanley2002evolving}.

\subsection{Neuroevolution im Vergleich}
\label{subsec:comparision_neuroevoltion}
Grundsätzlich wächst das Interesse an neuroevolutionären Algorithmen und in vielen Anwendungsfällen sind bereits auch im Vergleich mit anderen Ansätzen gute Ergebnisse erzielt worden \cite{meisner2009neurostrategies}. Dennoch werden Algorithmen dieser Art oft mit Skepsis betrachtet \cite{meisner2009neurostrategies} und weniger eingesetzt als gradientenbasierte Verfahren beispielsweise der Backpropagation Algorithmus. Daher wird in vielen Arbeiten, wie zum Beispiel in \cite{rojas1996neural, meisner2009neurostrategies, such2017deep, whitley1993genetic}, ein Vergleich zwischen auf Gradienten basierenden Verfahren und neuroevolutionären Algorithmen gezogen. In diesem Kapitel werden einige Vor- und Nachteile vorgestellt, die häufig in diesem Zusammenhang genannt werden.
\\\\
Für einen aussagekräftigen Vergleich müssen neuroevolutionäre Algorithmen zuvor noch einer Art des Lernens zugeordnet werden, da sich die Aufgaben und Anwendungsfälle in diesen stark unterscheiden können. Die drei Arten, das überwachte, unüberwachte und bestärkende Lernen sind in Kapitel \ref{subsec:learning_in_neural_networks} vorgestellt. Neuroevolutionäre Algorithmen werden hierbei der letzten Art zugeordnet \cite{whitley1993genetic}. Häufig werden hierfür zwei Gründe genannt. Erstens ist es das Ziel des bestärkenden Lernens, den insgesamt erhaltenen \emph{reward} zu maximieren \cite{such2017deep}, was vergleichbar mit dem Fitnesswert bei neuroevolutionären Algorithmen ist. Zweitens haben \citeauthor{sutton2018reinforcement} bestärkendes Lernen in ihrer Arbeit als eine Methode beschrieben, welche \ac{MDP} Probleme lösen kann. Das \ac{MDP} Problem ist in Kapitel \ref{subsec:learning_in_neural_networks} vorgestellt und beschreibt die Interaktion zwischen einem Agenten und seiner Umgebung. Hierbei kann der Agent als ein Individuum von neuroevolutionären Algorithmen und die Umgebung als Optimierungsproblem betrachtet werden. 
\\\\
Ein grundsätzlicher Vorteil von neuroevolutionären Algorithmen ist, dass durch die vielen unterschiedlichen Individuen unterschiedliche Lösungsansätze überprüft werden können. Dies ermöglicht es den Algorithmen, lokale Optima zu überwinden und die Suche nach dem globalen Optimum weiter fortzuführen \cite{rojas1996neural}. Dies kann für gradientenbasierte Verfahren schwierig sein. Ein weiterer Vorteil ist, dass bei neuroevolutionären Algorithmen keine Gradienten berechnet werden müssen \cite{rojas1996neural}. Dies kann sehr aufwendig sein, wenn zum Beispiel das \ac{KNN} viele Rückkopplungen enthält oder unmöglich, wenn beispielsweise die binäre Schwellwertfunktion als Aktivierungsfunktion verwendet wird \cite{whitley1993genetic}. Für die neuroevolutionären Algorithmen wird die Fitnessfunktion benötigt. 
\\\\
Allerdings kann diese einfache Art der Evaluation zum Nachteil werden, wenn beispielsweise das Optimierungsproblem bzw. die Umwelt verschiedene Startzustände hat. So kann ein Individuum mit einem schlechten Lösungsansatz durch Zufall einen einfachen Startzustand erhalten und so unter Umständen einen höheren Fitnesswert erzielen als ein besserer Lösungsansatz eines anderen Individuums, welches einen ungünstigen Startzustand erhalten hat. Hierdurch werden einige gute Individuen verloren gehen, da diese aufgrund des geringen Fitnesswertes nicht bei der Selektion ausgewählt werden. Die Fitnessfunktion wird in einem solchen Fall als verrauscht oder \emph{noisy} bezeichnet. Ein möglicher Lösungsansatz ist, dass alle Individuen immer denselben Startzustand erhalten. Dies verhindert das vorgestellte Problem, es entsteht aber ein neues. Die Individuen lernen nur eine Lösung für den ausgewählten Startzustand und sind mit hoher Wahrscheinlichkeit in anderen, ungünstigeren Startzuständen unbrauchbar. Eine Alternative ist, dass jedes Individuum mehrmals mit verschiedenen Startzuständen getestet wird und der Fitnesswert von allen akkumuliert wird \cite{whitley1993genetic}. Nachteil dieses Ansatzes ist, dass sich die Laufzeit linear erhöht je mehr verschiedene Startzustände getestet werden.
\\\\
Ein weiteres Problem von neuroevolutionären Algorithmen ist die Laufzeit. Das Entwickeln von unterschiedlichen Lösungen durch verschiedene Individuen benötigt viel Rechenzeit \cite{rojas1996neural}. Für eine Population mit beispielsweise $1000$ Mitgliedern werden pro Generation $1000$ \ac{KNN} erstellt, von denen mit jedem versucht wird, das Optimierungsproblem zu lösen. Die hierfür benötigte Laufzeit ist oft höher als bei gradientenbasierten Verfahren, bei welchen nur ein \ac{KNN} evaluiert werden muss \cite{whitley1993genetic}. Gleichzeitig kann dies aber auch ein großer Vorteil für neuroevoltionäre Algorithmen sein, wie unter anderem in Quelle \cite{such2017deep} gezeigt ist. Da die einzelnen Individuen unabhängig voneinander sind, lässt sich die Evaluation von diesen gut parallelisieren \cite{rojas1996neural}. Der Vorteil hiervon ist, dass eine Reduzierung der Ausführungszeit unabhängig von Limitierungen einzelner Prozessoren möglich ist \cite{schleuter1991explicit}. Das bedeutet, dass im Gegensatz zu sequentiellen Programmen, bei denen die Ausführungszeit nur durch einen schnelleren Prozessor gesenkt werden kann, die Laufzeit von parallelisierbaren Algorithmen auch durch das Hinzufügen von weiteren Prozessoren verringert werden kann. Dies ist in vielen Fällen einfacher und kostengünstiger umzusetzen.
\\\\
Wie erfolgreich eine Parallelisierung sein kann, haben \citeauthor*{such2017deep} in ihrer Arbeit gezeigt. Hierbei wurde ein \ac{KNN} zum Lösen von Atari Spielen optimiert. Die hierfür benötigte Trainingszeit mit einem einfachen, parallelisierten neuroevolutionären Algorithmus hat ungefähr vier Stunden gedauert. Verglichen wurde das Ergebnis mit zwei gradientenbasierten Verfahren, welche für ein vergleichbares Ergebnis mehrere Tage Trainingszeit benötigt haben \cite{such2017deep}. Dies zeigt die Leistungsfähigkeit von parallelisierten neuroevolutionären Algorithmen.

% Struktur  
% 0 Vortgeil: TWEANN Algorithmen entwicklen Struktur
% 1 Vorteil, Suchen an vielen verschiedenen Punkten im Lösungsraum, Wahrscheinlich nicht stuck an lokalen Optimmum
% 2. Vorteil: Es werden keine Gradienten benötigt, welche teilweise schwer zu berechnen sind sondern nr die Fitnessfunktion
% 1. Nachtei: Verrasuchte Fitnessfunktino
% 2. Nachteil: Viele KNN benötigten viel Rechenzeit, EA eher langsam
% 3. Vorteil: Gut parallelisierbar


% Neuro Networks A Systematic Introduction
% •	Genetic algorithms can be used when no information is available about the gradient of the function at the evaluated points. The function itself does not need to be continuous or differentiable. Genetic algorithms can still achieve good results even in cases in which the function has several local minima or maxima
% •	These properties of genetic algorithms have their price: unlike traditional random search, the function is not examined at a single place, constructing a possible path to the local maximum or minimum, but many different places are considered simultaneously. The function must be calculated for all elements of the population.
% •	However, compared to other stochastic methods genetic algorithms have the advantage that they can be parallelized with little effort. Since the calculations of the function on all points of a population are independent from each other, they can be carried out in several processors
% •	advantage that they do not necessarily remain trapped in a suboptimal local maximum or minimum of the target function
% •	genetic algorithm can move away from a local maximum or minimum if the population finds better function values in other areas of the definition domain
% o	Genetic algorithms offer some interesting properties to offset their high computational cost. We can mention at least three of them: a) GAs explore the domain of definition of the target function at many points and can thus escape from local minima or maxima
% o	he function to be optimized does not need to be given in a closed analytic form – if the process being analyzed is too complex to describe in formulas, the elements of 
% o	) since evaluation of the target function is independent for each element of the population, the parallelization of the GA is quite straightforward. A population can be distributed on several processors and the selection process carried out in parallel
% •	The problem of symmetries (Competing Conventions Problem)
% •	One field in which GAs seem to be a very appropriate search method is game theory
% o	Mathematicians then ask what is the optimal strategy, that is, how can a player maximize his pay-off. In many cases the cumulative effect of the pay-off function cannot be expressed analytically and the only possibility is to actually play the game and compare the results using different strategies


% Deep Neuroevolution: Genetic Algorithms are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning
% •	Evolution strategies (ES) can rival backprop-based algorithms such as Q-learning and policy 
% •	At a high level, an RL problem challenges an agent to maximize some notion of cumulative reward (e.g. total, or discounted) without supervision as to how to accomplish that goal 
% •	hey found that this algorithm, which we will refer to simply as evolution strategies (ES), is competitive with DQN and A3C on difficult RL benchmark problems, with much faster training times (i.e. faster wall-clock time when many CPUs are available) due to better parallelization (Salimans et al., 2017). 
% •	One motivation for choosing ES versus Q-learning and policy gradient methods is its faster wall-clock time with distributed computation, owing to better parallelization 
%o	A reason GA might outperform gradient-based methods is if local optima are present, as it can jump over them in the parameter space, whereas a gradient method cannot


% Genetic Reinforcment Learning for Neurocontrol Problems
% Genetic Algorithms can produce roughly competetive results as the standard back prop ago
% Domains where EA can make uniqze contribution -> No Derivate function, Gradient not available or costly to obtain
% EA sind eine ARt des RL Learnings
% Resulting search time is signigicantly lower than back Prop
% One Problem Noisy fitness function?

% Neuroevolution strategies for episodic reinforcement learning
% Growing INterest in NeuroEvolution -> sind Reinforcment Learning Technik, Gute Performance im Vergleich zu anderen Alternativen


% -----------------------------------------------------------

% Evolutionäre ALgos mit Neuronalen Netzen, Prinzipien mit Phasne gleich


% ERgen immer mehr aufmerksam, Gute Ergebnisse
% One Problem, slower then backpropagation with lager NN, One problem symmetric representations
% Calculation of gradiant expensive in recurrent NM

%Can achive better wall clock time, Can be used if gradients are hard to calculate, ) GAs explore the domain of definition of the %target function at many points and can thus escape from local minima or maxima, einfache bewertung mit fitness funktion, 
%•	These properties of genetic algorithms have their price: unlike traditional random search, the function is not examined at a %single place, constructing a possible path to the local maximum or minimum, but many different places are considered %simultaneously. The function must be calculated for all elements of the population.
%•	However, compared to other stochastic methods genetic algorithms have the advantage that they can be parallelized with little %effort. Since the calculations of the function on all points of a population are independent from each other, they can be carried %out in several processors
%•	advantage that they do not necessarily remain trapped in a suboptimal local maximum or minimum of the target function
%•	genetic algorithm can move away from a local maximum or minimum if the population finds better function values in other areas %of the definition domain
% Probabilistische Strahlsuche ?
\subsection{TWEANN?}
\label{subsec:tweann}
\subsection{Competing Convention Problem}
\label{subsec:competing_convention_problem}

% Obwol Diversität gut und wichtig für Entdecken des Suchrausm, oft Problem da Unvollstände NAchkommen erzeugt werden