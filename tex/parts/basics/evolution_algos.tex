% !TeX spellcheck = de_DE
\section{Evolutionäre Algorithmen}
Für die Optimierung von \ac{KNN} können verschiedene Algorithmen eingesetzt werden. Der in Kapitel (TODO KApitel) vorstellte Backpropagation Algorithmus, ist hierbei nur ein einzelnes Beispiel. In dieser Arbeit wird ein Verfahren eingesetzt, welches in Kapitel \ref{sec:neat} vorgestellt wird und zur Gruppe der \ac{EA} gehört. Auch wenn \ac{EA} eine Vielzahl von unterschiedlichen Verfahren umfassen, haben diese einige gemeinsame Grundprinzipien. Ziel von diesen Algorithmen ist, eine möglichst gute Näherungslösung für ein Optimierungsproblem zu finden. Umgesetzt wird dies mit einer simulierten Evolution, welche durch das biolgische Pendant inspiriert ist \cite{weicker2015evolutionare}.
\\\\
Im Folgenden .. 

% Use : Neural Networks - a Systematic Introduction P 437 and following
\subsection{Biologische Evolutionäre Konzepte}
\label{subsec:biological_evolution}
Einer der bedeutendsten Wissenschaftler im Bezug auf die Evolutionstheorie ist Charles Darwin, welcher 1859 mit seiner Arbeit \emph{On the Origin of Species by Means of Natural Selection} einen wichtigen Grundbaustein gelegt hat \cite{russell2013kunstliche}. Theoretisch wird bei Betrachtung der Evolution zwischen unbelebten Systemen, sowie lebenden Organismen unterschieden \cite{weicker2015evolutionare}. Da die \ac{EA} von Letzterem inspiriert sind, wird im Weiteren Verlauf dieser Arbeit nur auf diese Bezug genommen.
\\\\
Die später vorgestellten \ac{EA} übernehmen aus der Biologie verschiedene Begriffe wie zum Beispiel Population, Individuum, Genotyp, Phänotyp, Selektion, Rekombination und Mutation. Deshalb werden diese im Folgenden anhand des biologischen Vorbilds eingeführt. Die Erklärungen in dieser Arbeit sind stark vereinfacht und es werden auch nur die konzeptionellen Prinzipien betrachtet. Der genaue biologische Ablauf ist für diese Arbeit nicht interessant.\\
Eine Population setzt sich aus vielen unterschiedlichen und unabhängigen Individuen zusammen, welche alle zur selben Art gehören. Eine Art ist hierbei so definiert, dass sich die einzelnen Individuen einen gemeinsamen Genpool teilen und sich miteinander paaren können. Jedes Individuum besitzt ein Genom, welches das genetische Erbgut enthält. Dieses besteht mehreren aus Chromosomen, die wiederum mehrere Gene besitzen \cite{weicker2015evolutionare}. Hierbei kann ein Gen, welches zum Beispiel für die Fell- bzw. Haarfarbe des Individuums verantwortlich ist, verschieden Werte annehmen. Jede dieser Ausprägungen, in diesem Fall schwarze und braune Haare, werden als Allel bezeichnet \cite{weicker2015evolutionare}. Somit ist das Genom der Bauplan für ein Individuum und bestimmt maßgeblich dessen Erscheinungsbild \cite{kirschbaum2008biopsychologie}. Der Phänotyp wird durch das Genom beeinflusst und beschreibt die tatsächlichen, äußerlich feststellbare Ausprägungen der einzelnen Gene \cite{weicker2015evolutionare}. Allerdings kann der Phänotyp auch durch die Umwelt beeinflusst werden \cite{kirschbaum2008biopsychologie}. Die Kombination aus Genom und Phänotyp bilden das bereits vorgestellte Individuum. 
\\\\
Nachdem im vorherigen Absatz die grundlegenden Begriffe bezüglich einzelner Individuen erläutert wurden, soll jetzt mit Bezug auf die Evolution die Population als ganzes betrachtet werden. Die heute existierende Vielfalt von verschiedenen Tier- und Pflanzenarten hat sich über viele Millionen Jahren entwickelt. Der genaue Ursprung, wie die ersten Lebewesen mit Stoffwechselprozessen entstanden sind, ist dennoch unbekannt. Bezüglich der Evolution ergibt sich die Frage, wie das genetische Material sich im Laufe der Zeit ändern kann. Hierfür sind fünf Faktoren zu nennen \cite{weicker2015evolutionare}.
\begin{enumerate}
	\item Der erste und wichtigste Faktor sind zufällige Mutationen. Hierbei werden beim Vervielfältigen des genetischen Erbguts, zum Beispiel bei der Fortpflanzung, Fehler gemacht die zu zufälligen Änderungen führen. Hierdurch kann beispielsweise ein neues Allel entstehen, welches zu einer neuen nicht vorhandene Haar- bzw. Fellfarbe führt \cite{weicker2015evolutionare}. 
	
	\item Der zweite Faktor betrifft die Selektion. Das verschiedene Allele langfristig ähnlich häufig in der Population vorkommen müssen mehrere Faktoren zutreffen. Dies betrifft unter anderem die Überlebenschance der unterschiedlichen Individuen in der Umwelt, bei der sogenannten Umweltselektion \cite{weicker2015evolutionare}. Zum Beispiel kann eine auffällige Fellfarbe einen Nachteil sein, da diese von den natürlichen Feinden leichter entdeckt wird. Da diese Individuen häufiger gefressen werden haben sie eine geringere Chance sich Fortzupflanzen und es ist möglich, dass das genetische Material verloren geht. Doch nicht nur die Umweltselektion hat einen Einfluss auf die Anzahl der Nachkommen. Hierfür sind ebenfalls die erfolgreiche Partnersuche sowie Fortpflanzungsrate verantwortlich \cite{weicker2015evolutionare}.
	
	\item Besonders in kleinen Populationen kann der Tod einzelner Individuen große Auswirkungen auf das Verhältnis der unterschiedlichen Allele haben. Hierbei können durch Zufall einzelne Allele komplett verloren gehen und die nachfolgenden Generationen stark beeinflussen. In diesem Fall spricht man von Gendrift. Der Effekt hiervon ist bei größeren Populationen vernachlässigbar \cite{weicker2015evolutionare}.
	
	\item Wie bereits beschrieben, sollen sich Individuen einer Art fortpflanzen können. Doch es kommt auch vor, dass Individuen einer Art Abwandern und sich an zwei räumlich getrennten Orten weiterentwickeln. Kommt es zu einem späteren Zeitpunkt wieder zu einer Zuwanderung können die neu entwickelten Gene die Population maßgeblich verändern. Dieser Effekt wird auch Genfluss genannt \cite{weicker2015evolutionare}.
	
	\item Der letzte Faktor ist die Rekombination. Bezüglich der biologischen Evolution beschreibt dies den Vorgang der sexuelle Paarung von zwei Individuen, sodass ein oder mehrere Nachkommen erzeugt werden. Dabei wird das Ergbut für diese aus einer Kombination der Elterngenome erstellt. Somit handelt es sich aus Sicht der klassischen Evolutionslehre nicht um einen Evaluationsfaktor, da nur bekanntes neu kombiniert wird und keine neuen Gene oder Allele entstehen. Trotzdem wird die Rekombination heute meistens als Evaluationsfaktor genannt. Grund hierfür ist, dass die einzelnen Gene nicht, wie lange in der Populationsgenetik angenommen, komplett unabhängig voneinander sind sondern stattdessen stark vernetzt sind und viel Einfluss aufeinander haben. So können auch bei der Kombination von bekannten Genotypen neue phänotypischen Eigenschaften entstehen \cite{weicker2015evolutionare}.
\end{enumerate}

Durch die vorgestellten Arten der Evolution kann eine Population sich verschiedensten Umweltsituationen anzupassen und sich gegenüber konkurrierenden Arten behaupten. Beispiel hierfür sind Bakterien, welche Resistenzen gegen bestimmte Antibiotika entwickeln. Während so anfänglich nur wenige Individuen geschützt sind, wird die Resistenz durch die hohe Verbreitung von Bakterien schnell an Nachkommen weitergegeben und ist nach kurzer Zeit in der ganzen Population vorhanden.
 
\subsection{Evolutionäre Algorithmen}
\label{subsec:evolutionary_algorithm}
Im vorherigen Kapitel ist die biologische Evolution vorgestellt, mit der eine Vielzahl von unterschiedlichen Lebensformen entstanden ist, die sich sehr gut an ihre jeweilige Umwelt angepasst haben. Da dieses Vorgehen in der Biologie sehr erfolgreich ist, wurden schon im Jahr 1950 erste Versuche durchgeführt, dieses Vorgehen auf Computersysteme zu übertragen. Hierbei wird eine bedeutend vereinfachte künstliche Evolution simuliert mit dem Ziel ein Optimierungsproblem zu lösen \cite{weicker2015evolutionare}. Heute gibt es ein Vielzahl von verschiedenen Algorithmen, die unterschiedliche Aspekte der Evolution imitieren. Im folgenden werden die Grundkomponenten eingeführt und verschiedene Umsetzungsmöglichkeiten für diese gegeben.

\subsubsection{Genotyp und Phänotyp}
Wie bei der biologischen Evolution auch, gibt es bei den \ac{EA} Individuen, welche durch ein Genom und einen Phänotyp definiert sind \cite{weicker2015evolutionare}. Das Genom enthält alle Informationen die nötig sind, um den Phänotypen des Individuums zu erstellen. Die eigentliche Form des Phänotypen ist abhängig von dem gegebenen Optimierungsproblem und kann je nach Einsatzszenario unterschiedlich umgesetzt sein \cite{rothlauf2006representation}. Die Repräsentation des Genoms ist in vielen klassischen Algorithmen binär. In diesen Fällen wird das Genom durch einen Vektor $x$ von der Länge $l$ repräsentiert, welcher nur aus den Werten $0$ und $1$ besteht, somit gilt $x= (x_1, x_2, ..., x_l) \in \{0, 1\}^l$ \cite{rothlauf2006representation}. Allerdings kann diese Art der Kodierung nicht ausreichend sein. In diesen Fällen kann der Vektor auch natürliche, ganze oder rationale Zahlen enthalten \cite{rothlauf2006representation}. Grundsätzlich sind diese Arten der Repräsentationen nur als Beispiele zu verstehen. Jeder Algorithmus kann die Repräsentation der Genome anpassen, sodass es für das Verfahren zuträglich ist. In Kapitel \ref{subsec:neat_encoding} wird die in dieser Arbeit verwendete Art der Kodierung vorgestellt. 

\subsubsection{Optimierungsproblem}
\label{subsub:optimzation_problem}
Wie bereits beschrieben, ist es das Ziel von \ac{EA} Optimierungsprobleme zu lösen. Diese können aus vielen unterschiedlichen Bereichen wie Forschung, Wirtschaft sowie Industrie kommen \cite{weicker2015evolutionare} und unterschiedliche Anforderungen haben. Grundsätzlich muss jedes Optimierungsprobleme aus einem dreier Tupel $(\Omega, f, \succ)$ bestehen \cite{weicker2015evolutionare}. Die Variable $\Omega$ repräsentiert dabei den Suchraum, also jeden verschiedenen Lösungsansatz. Dieser wird typischerweise mit einem Individuum und dessen Genom bzw. Phänotyp getestet. Die Funktion $f$ ist definiert als $f: \Omega \rightarrow \mathbb{R}$ und bewertet jeden Lösungsansatz aus dem Suchraum und weißt diesem einen reellen Wert zu \cite{weicker2015evolutionare}. Dieser wird auch als Güte- bzw. Fitnesswert bezeichnet. Der letzte Teil des Optimierungsproblems ist eine Vergleichsrelation $\succ \in \{<, >\}$, welche angibt ob es das Ziel ist ein Minimum oder Maximum in der Fitnessfunktion zu finden \cite{weicker2015evolutionare}. Im Kontext von \ac{EA} wird meistens das Maximum gesucht, so auch in dieser Arbeit. Daher wird im weiteren immer angenommen, dass das Ziel ist, den erreichten Fitnesswert zu maximieren.\\
Bei allen Optimierungsproblemen ist die Fitnessfunktion ein elementarer Bestandteil. Nur diese Funktion gibt dem Algorithmus ein Feedback wie gut oder schlecht eine Lösung ist. Mithilfe dieser Funktion muss jeder \ac{EA} ableiten, in welche Richtung eine Optimierung sich entwickeln soll um möglichst effizient eine Lösung zu finden \cite{weicker2015evolutionare}. Aus diesem Grund ist die erste Anforderungen an eine solche Funktion, dass sie keine absolute sondern eine graduelle Bewertung der verschiedenen Lösungsansätze bietet \cite{weicker2015evolutionare}. Beispiel für eine absolute Bewertung ist, wenn die Fitnessfunktion für eine Lösung den Wert $1$ liefert, wenn das Optimierungsproblem gelöst ist und andernfalls $0$. In diesem Fall kann nicht festgestellt werden welche Änderungen der Suchparameter Erfolgs versprechend sind und somit es auch nicht möglich, diese gezielt zu ändern. Infolgedessen müssen mehr Lösungsansätze aus dem Suchraums getestet werden, was den Rechenaufwand und die benötigte Zeit erhöht. Des weiteren muss die Fitnessfunktion möglichst vollständig die Ziele des Optimierungsproblems abbilden. Andernfalls kann zwar durch den Algorithmus das Ergebnis der Fitnessfunktion maximiert werden, aber die hierdurch gefundene Lösung enthält nicht die vom Anwender gewünschten Eigenschaften \cite{weicker2015evolutionare}.

\subsubsection{Ablauf evolutionärer Algorithmen}
Aus den vorherigen Kapiteln ist ersichtlich, dass Individuen aus einem Genotyp sowie Phänotyp bestehen und dass diese Versuchen ein Optimierungsproblem zu lösen. Die Aufgabe eines evolutionären Algorithmus ist es, die Individuen langfristig so anzupassen, dass sie bessere Fitnesswerte in dem Optimierungsproblem erzielen und dementsprechend eine gute Lösung finden. Hierzu werden die aus der Natur bekannten Verfahren Selektion, Rekombination und Mutation eingesetzt. Doch bevor in den weiteren Kapitel verschiedene Beispielumsetzungen vorgestellt werden, wird in diesem Abschnitt der grundlegende Ablauf von \ac{EA} eingeführt.
\\\\
Abbildung (TODO ABBILDUNG) zeigt den beispielhaften Ablauf, wobei die Phasen Evaluation, Selektion, Mutation und Rekombination die größte Bedeutung haben. Doch bevor der eigentliche Programmablauf startet kann, muss eine erste initiale Population erzeugt werden. Wie bereits in der biologischen Evolution, besteht diese auch in diesem Fall aus mehreren unabhängigen Individuen \cite{rothlauf2006representation}. Im Gegensatz zum biologischen Vorbild verwenden bei den meisten Algorithmen ein feste Populationsgröße, da ansonsten die später benötigte Evaluationszeit und der damit verbundene Rechenaufwand stark ansteigen würde \cite{rothlauf2006representation}. Die für die Individuen benötigten Genome werden zufällig erstellt \cite{weicker2015evolutionare}, wobei je nach Algorithmus verschiedene Zufallsverteilungen genutzt werden können.
\\\\
Danach beginnt die Evaluationsphase mit der initialen Population \cite{rothlauf2006representation}. Hierfür wird der Phänotyp für jedes Individuum mit dem entsprechendem Genom gebildet. Jeder von diesen stellt eine mögliche Lösung für das gegebene Optimierungsproblem dar. Wie im vorherigen Kapitel beschrieben, muss dieses eine Fitnessfunktion enthalten, mit welcher jeder Phänotyp bewertet wird. An dieser Stelle soll nochmals hervorgehoben werden, dass die Gesamtheit der aller Gene den Phänotyp bestimmen und daher keine Bewertung der einzelnen Gene möglich ist \cite{rothlauf2006representation}. Die Evaluationsphase endet, wenn für alle Phänotypen ein Fitnesswert ermittelt ist. Der nächste Schritt ist die Überprüfung einer Abbruchbedingung. Trifft diese zu, wird die Ausführung des Algorithmus abgebrochen und das Genome des besten Individuums als Ergebnis zurück gegeben \cite{weicker2015evolutionare}. Je nach Umsetzung der Abbruchbedingung kann zum Beispiel überprüft werden, ob ein gewisser Fitnesswert überschritten und somit eine Lösung mit der gewünschte Genauigkeit bzw. Korrektheit gefunden wurde oder ob eine vorher definierte maximale Ausführungszeit überschritten ist
\\\\
Die Abbruchbedingung wird zu Beginn mit sehr großer Wehrscheinlicht nicht erfüllt sein, da die Genome nur zufällig erstellt sind und bisher kein Lernprozess durchgeführt wurde. Daher werden im Folgenden die Phasen Selektion, Rekombination und Mutation durchgeführt \cite{rothlauf2006representation}. Diese werden in den Folgenden Kapiteln ausführlich erläutert daher wird im Zuge von diesem Abschnitt nur ein kurzer Überblick gegeben. In der ersten Phase, der Selektion, wird auf Basis des erhaltenes Fitnesswertes für jedes Individuum festgelegt ob und wenn ja wie viele Nachkommen dieses erzeugen darf \cite{weicker2015evolutionare}. Bei der Rekombination werden die tatsächlichen Nachkommen erzeugt. Typischerweise werden zwei, in machen Fällen auch mehr, Individuen als Elterngenome ausgewählt und gekreuzt. Bei diesem Vorgang wird das genetische Material, welches in den Genomen der Eltern-Individuen enthalten ist, gemischt und an das neu erstellte Kind-Individuum übertragen. Das Ziel von dieser Operation ist, dass das Kind immer einen Teil der Gene von beiden Eltern erhält und somit auch Eigenschaft von beeiden vereint. Langfristig sollen sich durch ein solches Verfahren nur die besten Gene durchsetzen \cite{weicker2015evolutionare}. 
Die letzte Phase ist die Mutation. In diesem Schritt besteht für jedes neu erstellte Individuum die Wahrscheinlichkeit, dass ein kleiner Teil des Genoms zufällig abgeändert wird \cite{rojas1996neural}. Die Art der Mutation ist hierbei abhängig von der Umsetzung des Genotypen und dem Algorithmus. Bezüglich der drei Phasen muss verdeutlicht werden, dass die Selektion auf Basis des Phänotypen mit dem Fitnesswert geschieht, die Rekombination und Mutation hingegen auf Basis des Genotypen. Somit können keine Eigenschaften, die im Phänotyp gespeichert sind auf die Nachkommen übertragen werden \cite{rothlauf2006representation}.
\\\\
Sind diese drei Phasen abgeschlossen, sind die neuen Individuen fertig erstellt. Da, wie bereits in diesem Kapitel beschrieben, die Populationsgröße meistens begrenzt ist, wird an dieser Stelle typischerweise die Elterngeneration komplett entfernt und durch die dieselbe Anzahl an Nachkommen ersetzt \cite{weicker2015evolutionare}. Allerdings gibt es auch andere Ansätze, bei denen nicht so viele neue Individuen gleichzeitig erstellt werden und diese dann direkt in die bestehende Population integriert werden können \cite{stanley2005real}. Die neue Population mit den neuen Individuen durchläuft dieselben Schritte wie die vorherigen Population. Ein kompletter Durchlauf von dem vorgestellten Zyklus wird als Generation bezeichnet \cite{weicker2015evolutionare}. Häufig wird die neu erstellte Population daher auch als neue Generation bezeichnet. 

\subsubsection{Selektion}
Bei \ac{EA} werden viele Individuen eingesetzt um verschiedene Lösungsansätze gleichzeitig zu betrachten. In der Phase der Selektion wird bestimmt, welche Individuen als Elternteil für die nächste Generation ausgewählt werden und wie viele Nachkommen ihnen zustehen. Bei einem solchen Auswahlverfahren ist zwischen zwei Grundlegenden Umsetzungen zu unterscheiden. Einerseits kann allen Individuen einer Generation dieselbe Menge an Nachkommen zugewiesen werden oder die Anzahl ist abhängig von dem erreichten Fitnesswert. Typischerweise wird die zweite Variante in \ac{EA} verwendet, welche auch als fitnessproportionale Selektion bezeichnet wird. Die erste erzeugt keinen Selektionsdruck, da die Individuen unabhängig von ihrer Leistung Nachkommen zugewiesen bekommen. Bei der zweiten Variante werden Individuen mit höheren Fitnesswerten bevorzugt, mit dem Ziel, dass sich die positiven Eigenschaften der erfolgreichen Individuen durchsetzen und schlechte aussterben. Trotzdem ist es nicht das Ziel, nur die allerbesten Genome als Elternteile auszuwählen. Wäre dies der Fall, würde die Population sehr schnell konvergieren, ihre Vielfalt verlieren und nur noch ähnliche Lösungsansätze bieten. Somit wird es unwahrscheinlich, dass neue unbekannte aber eventuell bessere Lösungsstrategien gefunden werden \cite{weicker2015evolutionare}. 
\\\\
Der genaue Selektionsvorgang wie er in dem Algorithmus dieser Arbeit umgesetzt ist, wird in Kapitel \ref{subsec:neat_species} erläutert. Im Folgenden werden zwei verschiedene Varianten der fitnessproportionalen Verfahren vorgestellt die in anderen Algorithmen als Selektionsfunktion verwendet werden. Bei diesen wird die Anzahl an Nachkommen durch den jeweils erreichten Fitnesswert beeinflusst \cite{weicker2015evolutionare}.

\begin{enumerate}
	\item \textbf{Probabilistische Selektion}:\\
	Einer der bekanntesten Umsetzungen ist die probabilistische Selektion, welche grundsätzlich einfach zu implementieren ist. In einem ersten Schritt werden die erreichten Fitnesswerte $f$ der einzelnen Individuen $i$ in der Population $P$ aufsummiert. Im zweiten Schritt wird für jedes Individuum $j$ die Wahrscheinlichkeit $Pr[j]$ berechnet, welche Angibt wie groß die Chance ist, dass dieses als Elternteil ausgewählt wird. Hierzu muss der erhaltene Fitnesswert durch die bereits berechnete Summe geteilt werden. Somit ergibt sich die Formel $Pr[j]=\frac{f_j}{\sum_{i \in P}f_i}$. Diese Art der Selektion ist in vielen Anwendungsfällen sehr erfolgreich. Allerdings kann es passieren, dass zum Beispiel bei sehr hohen Fitnesswerten, die prozentualen Unterschiede zwischen guten und schlechten Individuen sehr gering sind und in Folge dessen der Selektionsvorteil für gute Lösungen niedrig ist. Ein möglicher Lösungsansatz besteht in der Skalierung der Fitnesswerte, sodass auch bei hohen Durchschnittswerten kleine Steigerungen einen evolutionären Vorteil bieten \cite{weicker2015evolutionare}. Ein weiterer Lösung ist die Verwendung der rangbasierten Selektion, welche im Folgenden vorgestellt ist.
	
	\item  \textbf{Rangbasierte Selektion}:\\
	Bei der rangbasierten Selektion ist der tatsächlich erhaltene Fitnesswert nicht von Bedeutung. Die Individuen werden bezüglich ihrer Fitness geordnet und das beste Individuum erhält die größte und das schlechteste die geringste Wahrscheinlichkeit als Elternteil ausgewählt zu werden \cite{weicker2015evolutionare}. 
\end{enumerate}
% TODO ABBILDUNG
Sind die Wahrscheinlichkeiten für alle Individuen berechnet, ist im letzten Schritt festzulegen, welche Genome tatsächlich als Elternteile ausgewählt werden und wie viele Nachkommen diese erzeugen. Bei der fitnessproportionalen Selektion wird hierfür ein Zufallsgenerator benötigt, welcher basierend auf den Wahrscheinlichkeiten die Elterngenome auswählt. Dies wird häufig mit einem Roulette-Rad veranschaulicht. Die Felder am Rand ensprechend den verschiedenen Individuen und die Größe ist proportional zu der berechneten Wahrscheinlichkeit. Für jedes auszuwählende Elternindividuum wird der Zeiger zufällig gedreht und das Individuum  entsprechend zu dem gewählten Feld wird verwendet (TODO ABBILDUNG). Dieses Verfahren kann einen Nachteil haben: Obwohl das beste Individuum die höchste Wahrscheinlichkeit hat als Elternteil ausgewählt zu werden, kann es auf Basis des Zufalls dazu kommen, dass dieses nicht verwendet wird. Da typischerweise die Population am Ende des Evolutionszyklus ersetzt wird, würde das genetische Material dieses Individuums verloren gehen \cite{weicker2015evolutionare}. 
\\\\
Um einen solchen Verlust zu verhindern, kann bei der Selektion zusätzlich ein sogenannter Elitismus verwendet werden. Hierbei wird typischerweise der Genotyp den bestes Individuums ausgewählt, kopiert und unverändert wieder in die nächste Generation eingesetzt \cite{such2017deep}. Zu Beachten ist hierbei, dass im weiteren Verlauf ein Nachkomme weniger produziert wird um eine konstante Populationsgröße zu garantieren. 

\subsubsection{Rekombination}
\label{subsubsec:ea_recombination}
Die Phase der Rekombination wird auch als \emph{Crossover} bezeichnet und findet nach der Selektion statt. Die Aufgabe von dieser ist, die ausgewählten Elternindividuen zu nutzen um neue Nachkommen zu erstellen. Typischerweise werden zwei, in einigen Fällen noch mehr, Elternteile kombiniert um mindestens ein Kind-Individuum zu erzeugen \cite{weicker2015evolutionare}. Die Rekombination gilt als eine der wichtigsten Phasen, da die Nachkommen tendenziell bessere Ergebnisse erzielen sollen als die Elternteile \cite{russell2013kunstliche}. Wie bereits bei anderen Phasen der \ac{EA} gibt es auch in diesem Fall verschiedene Umsetzungen, die als kombinierende, interpolierende und extrapolierende Selektion bezeichnet werden \cite{weicker2015evolutionare}. Der bekannteste Vertreter dieser drei Varianten ist die kombinierende Selektion, welche sowohl in dieser Arbeit als auch in vielen anderen Algorithmen verwendet wird. Die beiden Alternativen werden bedeutend seltener gewählt und sind auch in der Literatur oft nicht erwähnt. Trotzdem werden im Folgenden alle Varianten kurz vorgestellt.
\\\\
Die kombinierende Rekombination ist stark von der Biologie inspiriert. Bei diesem Vorgang werden die Genome der Elternteile zuerst nebeneinander aufgereiht. In einem zweiten Schritt wird zufällig entschieden, welcher Abschnitt von welchem Elternteil für das Genom des Nachkommen verwendet werden sollen \cite{weicker2015evolutionare}. Der Vorteil dieses Verfahrens ist, dass große Informationsblöcke, welche unabhängig voneinander optimiert wurden und sinnvolle Funktionen realisieren, von den Elternteilen geerbt werden können \cite{russell2013kunstliche}. Der aus der Rekombination entstehenden Nachkomme kann hierdurch einen Vorteil bei der Evaluation besitzen und letztendlich eine bessere Lösung für das Optimierungsproblem bieten. Da diese Art der Rekombination keine neuen Gene erstellt bzw. bestehende modifiziert, ist der Erfolg abhängig davon, ob die Population eine gewisse Diversität bietet, sodass bei der Rekombination tatsächlich verschiedene Gene kombiniert werden können \cite{weicker2015evolutionare}. Bei einer praktischen Umsetzung muss zuletzt noch entschieden werden, an welchen Stellen eine Rekombination möglich ist \cite{rojas1996neural}. Bei der uniformen Rekombination wird  für jedes einzelne Gen unabhängig zufällig entschieden, von welchem Elternteil es übernommen wird \cite{weicker2015evolutionare}. Allerdings gibt es auch andere Umsetzungen, bei denen die Gene in Gruppen eingeteilt werden und dann zwischen diesen zufällig entschieden wird.
\\\\
Bei der interpolierenden Rekombination, werden die einzelnen Gene nicht direkt von einem Elternteil übernommen, stattdessen werden sie gemischt, sodass ein neuer Wert entsteht, der sich zwischen den Werten der Elternteile befindet. Im Gegensatz zur kombinierenden Selektion, welche versucht die Diversität zu erhalten, wird diese hierbei deutlich verringert. Aus diesem Grund ist es notwendig, dass zu Beginn eine Population mit einer großen Diversität vorhanden ist, sodass der Suchraum  des Optimierungsproblems ausgiebig überprüft wird. Ein Beispiel für eine solche technische Umsetzung ist die sogenannte Arithmetische-Rekombination, welche für reellwertig repräsentierte Genome verwendet werden kann. Angenommen die Werte $A_i$ und $B_i$ repräsentieren die Gene der Eltern $A$ und $B$, dann wird für jedes Gen $i$ eine Zufallszahl $u$ zwischen $0$ und $1$ gewürfelt. Das Gen $C_i$ des Nachkommen $C$ wird dann berechnet mit $C_i=u \cdot A_i + (1-u) \cdot B_i$ \cite{weicker2015evolutionare}.
\\\\
Die letzte Variante ist die extrapolierende Rekombination, welche mit mehreren Elternteilen versucht eine Prognose abzugeben, wo im Lösungsraum eine Steigerungen des Fitnesswertes möglich ist und dementsprechend versucht die Genome der Nachkommen zu ändern. Somit kann diese Art der Rekombination auch neue Gene erstellen. Ein solches Verfahren hat allerdings zwei Nachteile: Um eine Prognose abzugeben, ist es erstens nötig ein Grundwissen über den Lösungsraum zu haben und zweitens besteht die Gefahr, dass die vorgegeben Richtung nicht korrekt und die Funktion dann nicht fähig ist, eine systematische Suche durchzuführen \cite{weicker2015evolutionare}.   

\subsubsection{Mutation}
\label{subsubsec:ea_mutation}
Der letzte Schritt bevor die bestehende Population durch die neu erstellten Individuen ersetzt wird ist typischerweise die Mutation. Allerdings ist die Funktionsweise und Relevanz von dieser Phase stark abhängig von der verwendeten Kodierung und dem eigentlichen Algorithmus \cite{weicker2015evolutionare}. Zum Beispiel wird in Quelle \cite{such2017deep} gar keine Reproduktion verwendet und die Optimierung wird nur mithilfe der Mutation umgesetzt während in anderen Quellen, wie zum Beispiel in \cite{zoller2007kunstliche}, diese Phase als untergeordnet beschrieben wird welche nur selten eingesetzt werden sollte.
\\\\
Wird die Mutation häufig verwendet erfüllt sie zwei Aufgaben. Das erste Ziel ist die Feinabstimmung der einzelnen Individuen, sodass das tatsächliche Optimum so genau wie möglich erreicht wird. Das zweite Ziel ist die Erforschung des Suchraums, welche stichprobenartig durchgeführt wird und das Ziel hat, ein besseres Optimum zu finden \cite{weicker2015evolutionare}.  Wird die Mutation selten eingesetzt, müssen die Funktionen Feinabstimmung und Erforschung durch andere Komponenten, wie zum Beispiel der Rekombination, durchgeführt werden. In diesem Fall ist es das Ziel der Mutation neue Diversität in die Population zu bringen beziehungsweise diese zu erhalten \cite{weicker2015evolutionare}. Denn wie bereits im vorherigen Kapitel beschrieben, ist vor allem bei der viel verwendeten kombinieren Rekombination, die Diversität sehr wichtig, allerdings wird diese meistens durch die Rekombination selbst verringert.
\\\\
Da die Umsetzung der Mutation sowohl von der Kodierung und dem Algorithmus abhängt, gibt es keine Empfehlungen, welche Implementierung besonders viele Vorteile bietet. Im Folgenden werden zwei mögliche Beispiele vorgestellt, wobei das erste für Individuen mit einer binären und das zweite für reellwertigen Repräsentation angewendet werden kann \cite{weicker2015evolutionare}. Die einfachste Mutation ist die Binäre-Mutation, welche für Genome mit einer binären Repräsentation verwendet werden kann. Bei der Mutation wird für jedes Bit eine Zufallszahl $u$ zwischen $0$ und $1$ gewürfelt. Ist diese kleiner als die festgelegte Mutationswahrscheinlichkeit $p_m$, dann wird das Bit invertiert. Sind die Individuen durch reellwertige Zahlen repräsentiert ist die sogenannte Gauss-Mutation eine mögliche Umsetzung. Bei dieser wird für jedes Gen eine Zufallszahl basierend auf einer Gauss-Verteilung gewählt, wobei eine zuvor festgelegte Standardabweichung $\sigma$ die Verteilung beeinflusst. Die hierdurch erhaltene Zahl wird dann auf den bereits bestehenden Wert addiert \cite{weicker2015evolutionare}.

\subsection{Neuroevolution}
Wie im vorherigen Kapitel erläutert, sind \ac{EA} Verfahren um möglichst gute Näherungslösungen für verschiedene Optimierungsprobleme zu finden. Für die in Kapitel \ref{sec:neuroal_networks} vorgestellten \ac{KNN} wird ein Verfahren benötigt, welches die verschiedenen anpassbaren Parameter optimiert. Es ist dementsprechend möglich, die evolutionären Prinzipien zur Optimierung von \ac{KNN} einzusetzen. Dies wird als Neuroevolution bezeichnet \cite{meisner2009neurostrategies}. Algorithmen dieser Art sind somit eine Alternative zu den klassischen Verfahren wie zum Beispiel dem Backpropagation Algorithmus \cite{whitley1993genetic}. 
\\\\
Im Vergleich zu diesem haben neuroevolutionäre Verfahren sowohl Vor- als Nachteile, welche ausführlich in Kapitel (TODO Kapite) beschrieben werden. Trotzdem soll ein großer Vorteil bereits hier genannt sein. Das Ziel von den meisten neuroevolutionären Algorithmen ist das Optimieren von Verbindungsgewichten und Schwellwerten. Einige Verfahren versuchen zusätzlich die Struktur bzw. Topologie des \ac{KNN} zu optimieren, sodass diese nicht mehr manuell durch einen Entwickler festgelegt werden muss. Wie in Kapitel \ref{subsec:network_structures} beschrieben, ist die Topologie ein entscheidener Faktor und kann das erfolgreiche Lösen maßgeblich beeinflussen. Diese Algorithmen werden als \ac{TWEANN} Verfahren bezeichnet \cite{stanley2002evolving} . 
\\\\
Auch der in Kapitel \ref{sec:neat} vorgestellte Algorithmus optimiert sowohl die Topologie als auch die Gewichte eines \ac{KNN}. Im Folgenden wird der Ablauf von neuroevolutionären Algorithmen vorgestellt und die Besonderheiten erläutert. Danach wird auf die Vor- und Nachteile eingegangen.

\subsubsection{Ablauf Neuroevolution}
Der Grundsätzlich Ablauf von neuroevolutionären Algorithmen ist fast identisch zu den klassischen \ac{EA}. Auch bei diesen gibt es eine Population, welche aus verschiedenen Individuen bestehen, die einen Genotyp und Phänotyp besitzen. Letzteres besteht bei der Neuroevolution aus einem \ac{KNN}, welches durch den Genotyp kodiert ist. Auch die Definition des Optimierungsproblems ist identisch zu der Erklärung in Kapitel \ref{subsub:optimzation_problem}. Ein Phänotyp, in diesem Fall ein \ac{KNN}, versucht das Optimierungsproblem zu lösen und erhält hierdurch einen Fitnesswert, welcher angibt wie gut oder schlecht die Lösung ist. Wenn dieser Wert für alle Mitglieder einer Population berechnet ist, beginnen die Phasen Selektion, Rekombination und Mutation. Hierdurch werden neue Individuen mit neuen Genotypen und Phänotypen erstellt welche dann die vorherige Population ersetzen. Dieser Zyklus wird solange wiederholt, bis eine Abbruchbedingung erreicht ist. Natürlich ist es möglich, dass die praktische Umsetzung je nach Algorithmus angepasst wird. Einige grundlegende Anpassungen werden in den Folgenden Abschnitten erläutert. Wie die angesprochenen Punkte von dem in dieser Arbeit verwendeten Algorithmus umgesetzt werden, wird in Kapitel \ref{sec:neat} erläutert.


\subsubsection{Genotyp und Phänotyp}
Eine Komponente die auf jeden Fall angepasst werden muss, ist der Genotyp. Dieser muss alle optimierbaren Parameter für den Phänotyp kodieren. Typischerweise umfasst dies die Struktur des Netzes, die Gewichte der Verbindungen sowie die Schwellwerte \cite{stanley2002evolving}. Die Propagierungs-, Aktivierungs- und Ausgabefunktion müssen nur enthalten sein, wenn diese ebenfalls durch den \ac{EA} angepasst werden. Hierdurch ergibt sich die Frage, wie diese Informationen im Genom kodiert werden sollen, sodass auch eine erfolgreiche Durchführung der Rekombinations- und Mutationsphase möglich ist. 
\\\\
%TODO Check Absatz
Grundsätzlich gibt es zwei verschiedene Kodierungansätze, die ein Algorithmus verwenden kann. Diese werden als direkte und indirekte Kodierung bezeichnet. Bei einer direkten Kodierung wird im Genom jede einzelne Verbindung und jedes Neuron explizit spezifiziert, sodass diese einfach im Phänotyp übernommen werden können. Diese Art der Kodierung wird sehr häufig verwendet, da sie einfach zu implementieren ist und auch die Rekombination und Mutation damit gut umsetzbar sind. Die Alternative ist die indirekte Kodierung. Diese spezifiziert Regeln, die angeben wie aus einem Genom ein \ac{KNN} erstellt werden soll. Der Vorteil hiervon ist, dass nicht jede Verbindung und jedes Neuron einzeln kodiert werden müssen und die Repräsentation dementsprechend kompakter ist und somit weniger Rechenkapazität zur Speicherung benötigt wird \cite{stanley2002evolving}. Nachteil von dieser Methode ist, dass die Rekombination und Mutation komplexer umzusetzen sind. Im Folgenden wird nur noch auf die direkte Kodierung Bezug genommen, da diese in dieser Arbeit verwendet wird.
\\\\
Theoretisch kann für eine direkte Kodierung des Genoms, wie bei klassischen \ac{EA}, eine binäre Repräsentation verwendet werden. Umsetzbar wäre dies mit einer Matrix, welche für jede mögliche Verbindung angibt ob diese besteht oder nicht. Allerdings hat eine solche Kodierung einige Nachteile, weswegen sie für diesen Anwendungsfall eher ungeeignet ist. Ein Grund ist der benötigte Speicherplatz für ein einzelnes Genom. Die Matrix enthält für ein \ac{KNN} mit $n$ Neuronen insgesamt $n^2$ Einträge für die möglichen Verbindungen \cite{stanley2002evolving}. Für große neuronale Netze skaliert dieser Ansatz schlecht.
\\\\
Alternativ ist hierzu eine Graphen-Kodierung, welche auch von vielen \ac{TWEANN} Algorithmen verwendet wird. Eine mögliche Umsetzung hiervon ist in der Arbeit \cite{pujol1998evolving} von \citeauthor{pujol1998evolving} vorgestellt. Bei diesen besteht die Kodierung aus zwei Teilen. Der erste Teil beschreibt die Struktur des Graphen beziehungsweise des \ac{KNN} während der zweite Teil ein linearer Vektor ist, welcher die Neuronen und Verbindungen enthält. In dieser Arbeit wird eine weitere Variante verwendet, welche ausführlich in Kapitel \ref{subsec:neat_encoding} erläutert wird.

\subsubsection{Rekombination}
Chronologisch gesehen, findet die Selektion vor der Rekombination statt und würde an dieser vorgestellt werden. Da sich diese Phase nicht ändert, wird im Folgenden direkt mit der Rekombination fortgefahren. Prinzipiell ist das Verfahren dasselbe wie in Kapitel \ref{subsubsec:ea_recombination}. Die Selektion hat zwei Elterngenome ausgewählt und diese werden im Rahmen der Rekombination zu einem neuen Genom kombiniert. Typischerweise würde bei diesem Vorgang zufällig entschieden, welche Verbindung von welchem Elternteil übernommen werden soll. Das Ziel ist, einen \ac{KNN} zu erzeugen, welches in den meisten Fällen die positiven Eigenschaften der Eltern erbt und somit insgesamt besser wird. Eine Schwierigkeit die hierbei, im Bezug zu Neuroevolution entstehen kann wird als das \emph{Competing Conventions} Problem bezeichnet \cite{stanley2002evolving}.
\\\\ % TODO Comepting Conevntions ABbildung da
Der Begriff \emph{Competing Conventions} beschreibt ein Phänomen, bei dem mehrere \ac{KNN} dieselbe Lösung für ein Optimierungsproblem bieten, aber sich die Repräsentationen der Genome trotzdem unterscheiden. Ein solches Beispiel ist in Abbildung (TODO Abbildung) dargestellt. Die beiden \ac{KNN} besitzen je drei verdeckte Neuronen (4, 5, 6) mit den dazugehörigen Verbindungen in den Farben blau (B), rot (R) und grün (G). Die tatsächlichen Gewichte sind hierbei nicht von Interesse und werden deshalb für eine bessere Übersichtlichkeit durch die Farben repräsentiert. Das erste \ac{KNN} kann beispielsweise durch den Vektor (B, R, G) und das zweite durch (G, R, B) kodiert werden. Es wird hierbei angenommen, dass in der Kodierung die einzelnen Gewichte für alle Verbindungen enthalten sind. \\\\
Wie aus der Abbildung zu Erkennen ist, sind die beiden \ac{KNN} symmetrisch und produzieren in Folge dessen für dieselbe Eingabe auch dasselbe Ergebnis. Dennoch unterscheiden sich die Genotypen bezüglich ihrer Kodierung. Werden diese beiden \ac{KNN} durch die Selektion ausgewählt um einen Nachkommen zu erzeugen, wird das \emph{Competing Conventions} Phänomen wahrscheinlich zu einem Problem führen. \\\\
Wie bei traditionellen \ac{EA} wird auch bei der Neuroevolution typischerweise zufällig entschieden, von welchem Elternteil welches Gen übernommen werden soll. Angenommen, es werden die ersten beiden Gene von dem linken Elternteil übernommen und das letzte vom rechten, dann wäre das daraus resultierende neue Genom kodiert mit (B, R, B). Es ist ersichtlich, dass bei diesem Vorgang $1/3$ der Informationen verloren gegangen sind beziehungsweise nicht vererbt wurde. Dies ist in den meisten Fällen ein großes Problem, da der fehlende Teil mit hoher Wahrscheinlichkeit einen notwendigen Beitrag für eine Lösungsansatz kodiert hat, der das Elterngenom erfolgreich gemacht hat. Aus diesem Grund wird das neu erstellte Individuum wahrscheinlich weniger erfolgreich sein als seine Elternindividuen sein, erhält einen dementsprechend niedrigeren Fitnesswert und wird letztendlich aussterben \cite{stanley2002evolving}. Tritt dieser Fall nur bei einem einzelnen Genom in einer Population auf, sind die Auswirkungen in vielen Fällen vernachlässigbar. Allerdings gibt es für ein \ac{KNN} mit $x$ verdeckten Neuronen in einer Schicht $x!$ viele Kombinationsmöglichkeit dieselbe Lösung durch unterschiedliche Genome zu repräsentieren \cite{stanley2002evolving}. Somit ist die Wahrscheinlichkeit, dass das \emph{Competing Conventions} Problem eintritt relativ hoch. Die Folgen sind, dass entweder viel Rechenzeit für Genome verwendet wird, die mit hoher Wahrscheinlichkeit keine besseren Lösungen bereit stellen und dadurch das Optimierungsverfahren bedeutend länger benötigt, oder dass das Verfahren scheitert, da keine ausreichend gute Lösung gefunden werden kann. 
% Viele fälle, mehr rechenzeit oder unmöglich 
\\\\
Bei den \ac{TWEANN} Algorithmen ist das \emph{Competing Conventions} Problem noch größer \cite{stanley2002evolving}. Wie bereits beschrieben, versuchen diese auch die Struktur des \ac{KNN} zu optimieren und können im Zuge dessen neue Neuronen und Verbindungen hinzufügen. Im nächsten Kapitel wird hierauf genauer eingegangen. An dieser Stelle sei vorweg genommen, dass im Laufe des Optimierungsverfahrens eine Population mit unterschiedlichen Strukturen und Topologien entstehen kann. Hierbei stellt sich die Frage, wie unterschiedliche \ac{KNN} rekombiniert werden können, wenn die Genome unterschiedlich groß sind und nicht zuzuordnen ist, welche Gene der Eltern rekombiniert werden können. Dies ist die schwierigste Form des \emph{Competing Conventions} Problems \cite{stanley2002evolving}. Wie der in dieser Arbeit verwendete Algorithmus dieses Problem löst, ist in Kapitel \ref{sec:neat} erläutert.

\subsubsection{Mutation}
Neuroevolutionäre Algorithmen setzen in der Regel die Mutation häufig ein. Hierbei wird zwischen zwei Arten unterschieden. Bei der ersten Art werden nur die Verbindungsgewichte und Schwellwerte mutiert. Hierfür kann die bereits in Kapitel \ref{subsubsec:ea_mutation} vorgestellte Gauss-Mutation verwendet werden, wobei der erhaltene Zufallswert auf das Gewicht bzw. den Schwellwert addiert wird \cite{mcintyre_neatpython}. Die zweite Art verändert die Topologie und wird als strukturelle Mutation bezeichnet. Diese Art wird somit nur für die \ac{TWEANN} Verfahren benötigt, welche neue Neuronen und Verbindungen dem \ac{KNN} hinzuzufügen können \cite{stanley2002evolving}.
\\\\
Das eigentliche Hinzufügen von neuen Strukturen ist technisch einfach umzusetzen. Zum Beispiel kann eine neue Verbindung mit einem zufälligen Gewicht jederzeit zwei zuvor nicht verbundene Neuronen verknüpfen. Allerdings wird hierdurch der Fitnesswert in den meisten Fällen initial sinken, da es unwahrscheinlich ist, dass eine zufällige Struktur eine nützliche Funktionalität oder Teillösung bietet. In Folge dessen sinkt auch die Chance, dass das Genom bei der Selektion in der nächsten Generation als Elternteil ausgewählt wird und die neue Struktur an die Nachkommen vererbt wird. So kommt es häufig vor, dass die strukturellen Innovationen direkt in den nächsten Generation verloren gehen, auch wenn sie für eine erfolgreiche Lösung nötig wären. Die daraus resultierende Herausforderung für \ac{TWEANN} Verfahren ist, neue Innovationen am Anfang zu schützen, sodass der Algorithmus diese optimieren kann. Nur so ist es möglich, neue Strukturen langfristig in die Population zu integrieren \cite{stanley2002evolving}.
\\\\
Eine mögliche Lösung hierfür ist in der Arbeit von \citeauthor{angeline1994gnarl} vorgestellt. Hierbei werden neue Neuronen ohne jegliche Verbindungen in das \ac{KNN} eingefügt, während neue Verbindungen initial das Gewicht $0$ haben. Die so hinzugefügten Strukturen haben anfänglich keinen Effekt auf das \ac{KNN}. Ziel hiervon ist, dass der Fitnesswert nicht absinkt und sich die Strukturen im Laufe von mehreren Generation selbstständig entwickeln \cite{angeline1994gnarl}. Diese Umsetzung ist nicht ideal, da die Strukturen unter Umständen nicht richtig in das \ac{KNN} integriert werden aber trotzdem die benötigte Rechenkapazität erhöhen \cite{stanley2002evolving}.
\\\\
Der in Kapitel \ref{sec:neat} vorgestellte Algorithmus verfolgt einen anderen Ansatz, bei dem ähnliche \ac{KNN} einer Spezies zugeordnet werden. Ein Individuum soll nicht mehr mit der ganzen Population konkurrieren, sondern nur mit denen seiner Spezies. Dies wird auch als \emph{niching} bezeichnet. Eine neue große strukturelle Mutation würde einer neuen Spezies zugeordnet und kann innerhalb dieser entwickelt und optimiert werden. Hierfür wird eine Kompatibilitätsfunktion benötigt, welche bestimmen kann, ob ein Genom einer Spezies zugehörig ist. Die Umsetzung von dieser Funktion, wird durch das \emph{Competing Conventions} Problem erschwert \cite{stanley2002evolving}. In Kapitel \ref{subsec:neat_species} wird hierauf genauer eingegangen.
 
\subsubsection{Initiale Population}
Die initiale Population der ersten Generation enthält zufällig erstellte \ac{KNN}. Die hierfür benötigten Verbindungsgewichte und Schwellwerte werden häufig zufällig mithilfe einer Gauss-Verteilung gewählt \cite{mcintyre_neatpython}. Die Wahl der initialen Topologie kann sich aber stark unterscheiden. Bei den neuroevolutionären Algorithmen, welche nur die Verbindungsgewichte und Schwellwerte optimieren, wird diese zu Beginn einmalig für alle \ac{KNN} festgelegt und ändert sich auch nicht im Lauf des Verfahrens. 
\\\\
Bei den \ac{TWEANN} Algorithmen hingegen, können verschiedene initiale Topologien verwendet werden, welche unter anderem die Laufzeit des Algorithmus stark beeinflussen können. Viele dieser Algorithmen erstellen zu Beginn verschiedene zufällig gewählte Topologien, mit dem Ziel Diversität in die Population zu bringen. Ein Nachteil dieser Strategie ist, dass hierbei ungeeignete \ac{KNN} entstehen können, bei denen beispielsweise nicht alle Eingabeneuronen mit allen Ausgabeneuronen verbunden sind. Zudem ergibt sich in diesem Fall noch ein weiteres Problem \cite{stanley2002evolving}. Grundsätzlich ist es sinnvoll, die kleinst mögliche Struktur zu wählen, die trotzdem einen mit größeren \ac{KNN} vergleichbaren Fitnesswert für ein Optimierungsproblem erzielt \cite{zhang1993evolving}. Diese hat, im Vergleich zu größeren Strukturen, weniger anpassbare Parameter, was generell die benötigte Optimierungszeit reduziert. Wenn die Topologien zufällig erstellt sind, werden hierbei viele unnötige Strukturen enthalten sein, was zu einem größeren Suchraum führt und die Laufzeit des Optimierungsverfahrens erhöht \cite{stanley2002evolving}. 
\\\\
In einem solchen Fall muss das Optimierungsverfahren versuchen die Größe des \ac{KNN} aktiv zu minimieren. Ein Ansatz hiervon ist in der Arbeit von \citeauthor{zhang1993evolving} beschrieben, in welcher die Größe des \ac{KNN} den Fitnesswert beeinflusst. In diesem Fall haben kleinere \ac{KNN} bei gleicher Performance im Optimierungsproblem einen größeren Fitnesswert und dementsprechend eine größere Chance bei der Selektion ausgewählt zu werden. Das endgültige Ziel hiervon ist, dass langfristig nur die benötigten Strukturen enthalten sind \cite{zhang1993evolving}. Auch wenn die zugrunde liegende Idee gut ist, kann es in der Praxis schwierig sein zu entscheiden, wie viel Einfluss die Größe des \ac{KNN} tatsächlich auf den Fitnesswert haben soll \cite{stanley2002evolving}.
\\\\
Eine weiterer Lösungsansatz ist das Starten mit einer minimalen Struktur, sodass das \ac{KNN} zu Beginn gar keine verdeckten Neuronen besitzt. Neue Strukturen werden nur integriert, wenn sie einen höheren Fitnesswert ermöglichen. Der Vorteil von dieser Strategie ist, dass keine Rechenzeit verwendet werden muss um unnötige Strukturen zu entfernen und zusätzlich die Anzahl an anpassbaren Parametern gering ist \cite{stanley2002evolving}.

%Kann markov task lösen, Kategorie des RL Leanring
% Population, Seleciton, Rekombinatino and Mutation the same, 

\subsection{Neuroevolution im Vergleich}
Evolutionäre ALgos mit Neuronalen Netzen, Prinzipien mit Phasne gleich

%

% ERgen immer mehr aufmerksam, Gute Ergebnisse
% One Problem, slower then backpropagation with lager NN, One problem symmetric representations
% Calculation of gradiant expensive in recurrent NM

%Can achive better wall clock time, Can be used if gradients are hard to calculate, ) GAs explore the domain of definition of the %target function at many points and can thus escape from local minima or maxima, einfache bewertung mit fitness funktion, 
%•	These properties of genetic algorithms have their price: unlike traditional random search, the function is not examined at a %single place, constructing a possible path to the local maximum or minimum, but many different places are considered %simultaneously. The function must be calculated for all elements of the population.
%•	However, compared to other stochastic methods genetic algorithms have the advantage that they can be parallelized with little %effort. Since the calculations of the function on all points of a population are independent from each other, they can be carried %out in several processors
%•	advantage that they do not necessarily remain trapped in a suboptimal local maximum or minimum of the target function
%•	genetic algorithm can move away from a local maximum or minimum if the population finds better function values in other areas %of the definition domain
% Probabilistische Strahlsuche ?
\subsection{TWEANN?}
\label{subsec:tweann}
\subsection{Competing Convention Problem}
\label{subsec:competing_convention_problem}

% Obwol Diversität gut und wichtig für Entdecken des Suchrausm, oft Problem da Unvollstände NAchkommen erzeugt werden