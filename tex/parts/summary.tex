% !TeX spellcheck = de_DE
\chapter{Zusammenfassung und Ausblick}
In dieser Arbeit ist das Verfahren \ac{NEAT} analysiert und für ein verteiltes System parallelisiert worden. Die Ergebnisse der vorherigen Kapitel werden im Folgenden zusammengefasst. Zusätzlich sind einige Vorschläge für zukünftige Weiterentwicklungen gegeben, die nicht im Rahmen dieser Arbeit umgesetzt sind.  

\section{Ergebnis}
Die erste Anforderung an diese Arbeit ist die Implementierung des sequenziellen Verfahrens. Hierfür ist die Sprache Python gewählt worden, da sie im Bereich maschinelles Lernen weit verbreitet ist und viele Bibliotheken bietet. Eine hiervon ist das OpenAI Gym, welches bei der Analyse und Evaluation genutzt wird. Die generelle Softwarearchitektur ist in Kapitel \ref{chap:software_architecture} beschrieben. Sie ist darauf ausgelegt, eine einfach zu nutzende Schnittstelle zu bieten. Dadurch können verschiedene Optimierungsprobleme schnell und effizient implementiert werden. Ein weiterer wichtiger Aspekt ist, dass das Ergebnis des Verfahrens durch einen \emph{Seed} beeinflusst wird. Dadurch ist das Wiederholen und Vergleichen von Testergebnisse mit der später erstellten parallelisierten Implementierung möglich. Zuletzt ist bei der Softwarearchitektur zu verdeutlichen, dass das optimierte \ac{KNN} und die Testergebnisse gespeichert und visualisiert werden können. Dies ist unter anderem notwendig, wenn das \ac{KNN} in einer produktiven Umgebung eingesetzt werden soll.
\\\\
Kapitel \ref{chap:analysis} beschreibt die Analyse des sequenziellen Verfahrens. Dies entspricht der zweiten Anforderung an diese Arbeit. Zuerst wird die korrekte Funktionalität des implementierten Algorithmus mit dem XOR-Problem überprüft. Mit der Konfiguration aus der originalen Publikation werden ähnliche Ergebnisse erzielt, wie sie von den Autoren beschrieben sind. Inspiriert durch das Paket \emph{neat-python} werden die Konfiguration und das Verfahren modifiziert. Dadurch sinkt die Anzahl der benötigten Generationen zum Lösen des XOR-Problems beträchtlich. Im nächsten Schritt der Analyse wird die Ausführungszeit des sequenziellen Verfahrens in verschiedenen Beispielen erfasst. Das XOR-Problem wird wegen einer zu geringen Komplexität hierfür nicht verwendet. Es werden die \emph{CartPole}, \emph{MountainCar} und \emph{Pendulum} Umgebung des OpenAI Gym ausgewählt. Bei allen drei Umgebungen kann die Fitnessfunktion mit den zur Verfügung gestellten \emph{rewards} implementiert werden. Die Testdurchläufe zeigen, dass die initiale Generation die \emph{CartPole} Umgebung bereits lösen kann und sie daher für die weiteren Tests ungeeignet ist. Bei den anderen beiden Umgebungen werden die Ausführungszeiten gemessen. Hierbei wird zwischen der \emph{Evaluation Time}, \emph{Reproduction Time} oder \emph{Compose Offspring Time} unterschieden. Die \emph{Evaluation Time} misst die benötigte Zeit zum Evaluieren aller Agenten. Diese macht in beiden Testumgebungen mit Abstand den größten Anteil an der gesamten Laufzeit des Algorithmus aus.
\\\\
Die letzte Anforderung an diese Arbeit ist die Optimierung, welche in Kapitel \ref{chap:optimization} beschrieben ist. Hierbei wird der Fokus auf die Parallelisierung der \emph{Evaluation Time} gelegt, da hierbei die größte Zeiteinsparung möglich ist. Es wird eine \emph{Master-Slave} Architektur mit \ac{MPI} implementiert. Der \emph{Master} verteilt Arbeitspakete, die je einen Agenten enthalten und von den \emph{Slaves} evaluiert werden. Der Vorteil von diesem Ansatz ist, dass sowohl das \ac{KNN} als auch das Optimierungsproblem parallelisiert ausgeführt werden. Der dabei entstehende Kommunikationsaufwand ist sehr gering und ermöglicht insgesamt eine gute Parallelisierung. Zusätzlich kann die bereits vorhandene Struktur einfach erweitert werden, sodass auch die Parallelisierung der \emph{Reproduction Time} oder \emph{Compose Offspring Time} möglich ist. Das Verfahren wird auf einem verteilten System ausgeführt. Hierfür wird ein Beowulf-Cluster aus zehn Raspberry Pis erstellt. Neben geringen Kosten und einer platzsparenden Unterbringung bietet dies den Vorteil, dass alle Geräte identisch konfiguriert sind. Das vereinfacht den Vergleich zwischen der sequenziellen und parallelisierten Implementierung. Um die Effizienz der Parallelisierung zu messen, werden die zuvor durchgeführten Tests wiederholt und die Ausführungszeit erfasst. Auf jedem beteiligten Raspberry Pi wird hierzu ein Proezss ausgeführt. Bei Verwendung von zwei oder mehr \emph{Slaves} wird die Ausführungszeit stark reduziert. Für eine Bewertung der Parallelisierung sind der \emph{SpeedUp} und Effizienzwert berechnet worden. Die erhaltenen Ergebnisse entsprechen nahezu den idealen Werten, die mit \emph{Amdahl's Law} berechnet sind. Werden nur die \emph{Slaves} betrachtet, ist die \emph{Evaluation Time} mit einer Effizienz von $97\%$ parallelisiert. Dies ist ein sehr gutes Ergebnis und wird unter anderem durch die effiziente Kommunikation ermöglicht. Für ein Population mit $n$ Mitgliedern müssen nur $2 \cdot n$ Nachrichten versendet werden. Zusätzlich ist in Kapitel \ref{chap:optimization} demonstriert, dass mit \ac{MPI} das \ac{GIL} von Python umgegangen werden kann. Es können alle $40$ Prozessoren des erstellten Beowulf-Clusters vollständig ausgelastet werden. Allerdings sind die dabei entstehenden \emph{SpeedUp} Werte niedriger als durch die vorherigen Tests angenommen. Der Grund ist, dass sich mehrere Prozesse auf einem Gerät sich gegenseitig blockieren bzw. behindern. Die genaue Ursache hiervon kann im Rahmen dieser Arbeit nicht untersucht werden. Die Tests zeigen jedoch, dass dies nicht primär durch das implementierte Verfahren entsteht sondern unter anderem durch das OpenAI Gym.
\\\\
Insgesamt haben die erzielten \emph{SpeedUp} und Effizienzwerte die Erwartungen übertroffen. Durch eine gute Parallelisierung können neuroevolutionäre Algorithmen einen entscheidenden Vorteil gegenüber dem Backpropagation Algorithmus und seinen Derivaten bieten. Der große Vorteil ist, dass sowohl das \ac{KNN} als auch das Optimierungsproblem parallelisierbar sind. Durch die erfassten Ergebnisse ist zu schließen, dass mit steigender Anzahl an Prozessoren die Ausführungszeit weiter sinken wird. Die zuletzt vorgestellte \emph{Lunar Lander} Umgebung verdeutlicht nochmals, wie groß die tatsächliche Einsparung ist. Verfahren die auf einem Raspberry Pi 4 mehrere Tage dauern, können auf zehn Geräten in wenigen Stunden beendet werden. Für eine vollständige Bewertung ist auch zwei Nachteile zu nennen. Gibt es mehr Prozesse als Agenten in einer Generation, kann nicht jedem ein Arbeitspaket zugewiesen werden. In diesem Fall kann durch Hinzufügen von weiteren Rechenressourcen keine Reduzierung der Ausführungszeit erreicht werden. Jedoch ist es in einer solchen Situation möglich die Populationsgröße entsprechend anzupassen. Mit einer größeren Population können mehr Lösungsansätze gleichzeitig evaluiert werden was indirekt schneller zu einer Lösung führen kann. Der zweite Nachteil betrifft \ac{NEAT} direkt. Grundsätzlich werden mit diesem Algorithmus beeindruckende Ergebnisse erzielt. Jedoch können die vorgestellten Arten der strukturellen Mutation nicht ausreichend sein um große \ac{KNN} in einer kurzen Zeit zu entwickeln. In diesem Fall kann das HyperNEAT Verfahren aus Quelle \cite{stanley2009hyperneat} verwendet werden. Dieses basiert auf \ac{NEAT} und ermöglicht die Entwicklung von größeren \ac{KNN}. Die in dieser Arbeit vorstellten Parallelisierungsstrategie bezieht sich vor allem auf die Evaluationsphase und kann daher auf verschiedene neuroevolutionäre Algorithmen angewendet werden.

\section{Weiterentwicklung}
\label{sec:future_work}
Das implementierte Projekt bietet die Grundlage für verschiedene Erweiterungen. In Kapitel \ref{sec:parallel_strategies} ist bereits die Integration von Bibliotheken wie Tensorflow und PyTorch vorgestellt. Mit diesen kann die Aktivierungszeit von \ac{KNN} stark reduziert werden und auch die Nutzung von \acp{GPU} wird ermöglicht. Für einen noch besseren \emph{SpeedUp} müssen die Funktionen der  \emph{Reproduction Time} und \emph{Compose Offspring Time} ebenfalls parallelisiert werden. Denn durch \emph{Amdahl's Law} ist erkennbar, dass die Phasen zwar beim sequenziellen Verfahren nur einen geringen Prozentsatz der Ausführungszeit benötigen, aber bei steigender Parallelisierung zunehmend zum limitierenden Faktor werden. Prinzipiell ist es mit der \emph{Master-Slave} Architektur möglich beliebig viele weitere Funktionen mit geringem Aufwand zu parallelisieren. 
Die Funktionen für die Mutation der Gewichte und die Rekombination zum Erzeugen von Nachkommen bieten sich für eine Parallelisierung an. Für letzteres kann der \emph{Master} Arbeitspakete mit je zwei Agenten erstellen. Die \emph{Slaves} führen für diese die Rekombination aus und geben den neu erstellten Agenten als Ergebnis zurück. Selbes Prinzip kann auf die Mutation der Gewichte angewendet werden. Andere Funktionen hingegen können nur schlecht oder teilweise parallelisiert werden. Ein Grund hierfür können globale Variablen sein, wie es im Fall der strukturellen Mutationen mit den Innovationsnummern ist. Die Funktion zum sortieren der Agenten in die Spezies kann teilweise parallelisiert werden. Die Zuweisung der Agenten in die bestehenden Spezies kann parallel geschehen, das Erzeugen von neuen Spezies hingegen muss sequenziell durchgeführt werden. Insgesamt ist der Aufwand für die Parallelisierung dieser Phasen bedeutend höher und wird wahrscheinlich dieselben \emph{SpeedUp} Ergebnisse liefern wie die \emph{Evaluation Time}. Daher ist die Parallelisierung dieser Phasen häufig erst sinnvoll, wenn durch hinzufügen von weiteren Prozessen die Ausführungszeit der \emph{Evaluation Time} nicht weiter reduziert werden kann. 


%Da die Ausführungszeit des Algorithmus für das XOR-Problem nicht repräsentativ ist, werden drei andere Optimierungsprobleme aus dem OpenAI Gym für die Analyse verwendet. Dabei ist darauf zu achten, dass die Umgebungen nicht zu komplex sind, da die Implementierung auf einem Raspberry Pi 4 ausgeführt wird, der selbst nur eine vergleichsweise geringe Rechenleistung bietet. Aus diesen Gründen werden die Standardumgebungen \emph{CartPole}, \emph{MountainCar} und \emph{Pendulum} ausgewählt. Bei den Tests zeigt sich, dass nur die zwei letzteren geeignet sind. 
%\\\\
%Die \emph{CartPole} Umgebung kann mit zufällig erstellten \ac{KNN} sind bereits in der initialen Generation \ac{KNN} vorhanden, die das Optimierungsproblem lösen. Für die \emph{MountainCar} und \emph{Pendulum} Umgebung werden dem \ac{KNN} einige strukturelle Innovationen hinzugefügt, bis das Optimierungsproblem gelöst wird.  



% Struktur
% Stellvertretend NEAT für Neuroevolutionäre Algorithmen analysisiert
% Implementierung des sequenziellen Verfahrens als Bibliothek. Viele Funktionen extern, sodass in beiden beiden Implementierungen wiederverwendet werden können Ist in Kapitel So und So beschrieben. Wichtige Eigenschafte, Seed basiert, Einfach für verschiedene Probleme anzupassen, Unterteilung der Laufzeit in 3 Bereiche. Speichern und Laden von Ergebnissen möglich, Sprache Python ausgewählt für schnelle Entwicklung, viele Pakete möglich

% Analyse
% Laufzeit von sequenziellem Verfahren erfassen. Zuvor korrekte Implementierung von NEAT überprüfen mit XOR, Dabei anfänglich etwas schlechtere Ergebnisse als orginale Publukation, danach aber bedeutend besser. 
% 3 Testumgebungen inital durchgeführt aus dem OpenAI Gymfür gute Vergleichbarkeit. Pole Balancing, zu einfach, zufälliges KNN kann das Problem lösen, Mountain Car schwieriger, KNN mit Hidden Neuronen wird entwickelt, Laufzeit zeigt, dass Evaluation der größte Faktor ist. Umfasst KNN und Umgebung, Phasen des NEAT algorithmus eher weniger großen Einfluss. Gleiches zeigt sich in Pendulum. 

% Optimierung
% Es soll hauptsächlich die Evaluation Time parallelisiert werden, da das mit abstand der gröte Faktor ist. Prinzipiell verschiedene Optimierugnsstrategien, in dieser Arbeit soll Cide parallelisiert werden. Ziel ist die Ausführung auf einem Cluster zu ermöglichen, wie beispielsweise im HPC Computing. Architektur wird Master Slave gewählt, für einface Kommunikaktion und Erweiterbarkeit. Für die Testumgebung ist ein Raspberry Pi beowulf cluster erstellt worden, Vorteil: Alle exakt dieselbe Hardware, theoretisch mit 10 Geräten 10 Fache Rechenleistung. Vergleich einfach möglich. 
% Durchführen der Mountain Car und Pendulum Umgebung. Wichtige Erkenntnis, beide Verfahren erzegen exakt dieselebn lösungen, somit auch dieselebn Rechenschritte. Vergleich sinvoll. Tests mit einem Prozess pro Pi durchgeführt, Sehr gut eErgebnisse. SpeedUp und Effizienz entsprechen erwarteten Werten. Auswertung Evaluation Time ergibt, und nur Slaves, $97%$ eEffitienz. Ergebnis nahezu ideal.
%Allerdings, zeigen sich auch Grenzen der Parallelisierung.
% Irgendwann ist Reduzierung der Ausführungszeit nicht mehr Lohnenswert. Da Zeiteinsparung immer geringer wird, aber benötigte prozessoren stark ansteigen.  Grund: Sequenzieller Anteil. Müsste auch parallelisiert werden.  Ansätze hierzu in Kaputel SO und SO

% MPI erlaut umgehen von GIL, Mit der Implementierung auch möglich. Alle 40 Prozesse genutzt. Problem, Prozesse auf demselben Gerät behindern sich gegenseitig. Ergebnis in dem TestSetup: Verfahrne insgesamt schneller, also definitiv Vorteil: Rechenkapazität ist vorhandne, kann aber sonst nicht genutzt werden. Aber nicht so gut wie erwartet. Daher weitere Untersuchungen notwendig

% Lunar Lander als letztes zeigt ENtwicklung von generellen Lösung. In vielen Fällen wir dEvaluation dadurch noch aufwändiger, aber Code profiziert noch mehr von PArallelisierung. Daher Wahl der Evaluation Time prinzipiell gut und wicthig

% Grenze der Parallelisierung: Prozesse = Größe der Generation: Jeder Prozess arbeitet einen Agenten ab. Danach keine Aufteilung möglich. Eine Option in diesem Fall: Populationsgröße vergrößeren. Ähnlich zu Gustafsons Law, wird dadurch dem System höhere Arbeitslast gegeben. Dadurch kann schneller Lösung gefunden werden, da größerer Suchraum abgetastet wird, Aber!! Kann auch nichts bringen, wenn Bsp: neue Struturen benötigt werden. Die müssen erst entwickelt werden.

% Übertragen der Ergebnisse auf andere Algorithmen absolut möglich, jeder NE wird eine Evaluationsphase haben. Häufig wird diese ebenfalls der aufwändigste Faktor sein. Ergebnisse decken sich mit Quelle so und so. Eventuell mögliche Erweiterung für HyperNEat: Dies kann größere KNN entwickeln als andere Verfahren. Eventuell Größe irgendwann ein PRoblem? Bei Übertragung mit MPU

% Weiterentwicklung:
%Trotz guter Ergebnisse, einige Grenzen. Das erste Ergebnis ist die Reproduction and Compose OffSpring Time. Sind limiterender Faktor bei der Prallelisierung. Werden diese auch Parallelisiert, können laut Amhdals law bedeutend bessere Ergebnisse erzieltz werden. Nachteil ist, diese Phasen brauchen globale Variablen, bzw. Aktionen die nacheinander ausgefüht werden müssen, Parallelisierung schwieriger, aufwändiger?  nicht effizienz. Einige Ideen: Mutation: prinzipiell einfach, aber bei den Anforderungen in dieser Arbeit zusätzliche Schwierigkeit wegen Seed basiertem Verfahren. Jeder Prozess muss denselben Seed verweden, da sich sonst Ergebnisse unterscheiden. Ist keine Vergleich möglich, gut umsetzbar und mit Master Slave Architektur leicht integrierbar
% Reproduction Schwieriger: Innovationsnnummern benötigen gloabelen Counter. Bei jeder strukturellen Mutation muss dieser synchronisiert werden, sehr zeitaufwändig. Ein Ansatz: Innovationsnsummern werden nicht als Zahl benötigt, sondern als eindeutige ID: Eventuell nutzen von HashFunktion? Eingabe so und so, Bestimmt Innoationsnummer von Verbindungen / Neuron. VOrteil: keine Synchronsiation udn dieselben Mutationen bekommen denselben Wert zugewiesen.+
% Umseten der Rekombination ist wie Mutation theoretisch möglich, Zwei Elternteile an Slaves verteilen, bringen neuen Agent zurück, idealerweise mutiert.
% Problem: Soriteren der Agenten in Spezies. Aufwändiger Teil gewesen: Problem: Neue Spezies erstellen, muss global synchronsiert sein. Nur teilwesie Parallelisierung möglich. Agenten werdne wenn möglichj in Spezies soritert. Agenten für die keine Spezies gefunden wird, ignorieren und erst am Ende Sequenziell zuweisen. Dadurch teil Parallelisierung.

% Problem bei all diesen Parallelisierungen ist, sehr speziell für NEAT. Parallelisierung der Evaluatino kann hingegen leicht auf andere angewendet werden. Tatsächlich Zeitersparnis fragwürdig? Zumindest inital liegt fokus mehr auf der Evaluation TIme.

% Weitere Erweiterung Tensorflow oder PyTorch: Könnne mit INterface NN implementiert werden, schnellere AKtivierung von KNN. In diesem Fall auch Integratoin von GPUs sinvoll, da auf diesen KNN Aktivierung noch schneller berechnet werden kann. A


