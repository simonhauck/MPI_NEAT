% !TeX spellcheck = de_DE
\section{Ergebnisse}
\label{sec:results_optimziation}
Auf Basis der Analyse ist das parallelisierte Verfahren implementiert und getestet worden. Die hierbei erhaltenen Ergebnisse sind im Folgenden zusammengefasst. Der größte Einfluss bezüglich der Ausführungszeit ist die \emph{Evaluation Time}, deren Anteil in beiden Verfahren über $90\%$ beträgt. Somit kann durch eine Parallelisierung dieser Phase die größte Zeitersparnis erzielt werden. \emph{Amdahl's Law} zeigt, dass durch den sequenziellen Anteil des Programmcodes trotz unendlich vieler Prozesse ein maximaler \emph{SpeedUp} von $50$ für die \emph{Moutain Car} Umgebung und von $11.\overline{1}$ für die \emph{Pendulum} Umgebung möglich ist. Diese Werte werden für einen Vergleich mit den tatsächlich erhaltenen Ergebnissen genutzt.
\\\\ % TODO CHECK bei bei
Für eine maximale Zeitersparnis wird die Evaluation der Agenten als Ganzes parallelisiert. Ein Vorteil ist, dass sowohl das Optimierungsproblem als auch die Funktionalität des \ac{KNN} parallel ausgeführt werden. Zusätzlich ist bei dieser Umsetzung der entstehende Kommunikationsaufwand gering und das nachträgliche Integrieren von Bibliotheken wie Tensorflow und PyTorch möglich. Für die eigentliche Implementierung sind verschiedene Anforderungen definiert, die vollständig umgesetzt sind. Es wird eine \emph{Master-Slave} Architektur für die Kommunikation verwendet. Diese ist einfach zu implementieren, vermeidet \emph{Deadlocks} und ermöglicht eine dynamische Lastenverteilung. Letzteres ist insbesondere wichtig, wenn das parallelisierte Verfahren auf unterschiedlich leistungsfähigen Geräten ausgeführt wird oder die Evaluationszeit von Agenten variiert. Ein Nachteil dieser Umsetzung ist, dass der \emph{Master} nur die Koordination der Kommunikation übernimmt und nicht die \emph{Slaves} bei der Evaluation unterstützt. Mit einer geringen Anzahl an Prozessen macht dieser Umstand bei der Effizienzberechnung einen großen Unterschied aus. In größeren Systemen mit hunderten Prozessen ist der Einfluss hingegen vernachlässigbar gering und daher nicht relevant. Bei der Implementierung des parallelisierten Verfahrens werden die Komponenten des sequenziellen Verfahrens überwiegend wiederverwendet. Hierdurch ist eine schnelle und effiziente Entwicklung möglich. Entscheidend ist, dass beide Verfahren einfach untereinander austauschbar sind und ein direkter Vergleich möglich ist. Um Letzteres zu gewährleisten, basiert auch das parallelisierte Verfahren auf einem \emph{Seed}. Ist dieser identisch mit dem des sequenziellen Verfahrens, werden dieselben Ergebnisse berechnet. Für die Kommunikation wird der Standard \ac{MPI} eingesetzt, da dieser im Bereich \ac{HPC} weit verbreitet ist und zusätzlich das Umgehen des \acp{GIL} von Python ermöglicht.
\\\\
Für die Tests wird ein Beowulf-Cluster bestehend aus zehn Raspberry Pis erstellt. Auf diesem wird das parallelisierte Verfahren durchgeführt und mit den Laufzeiten des sequenziellen Verfahrens verglichen. Zu Anfang wird das Verfahren mit jeweils einem Prozess pro Raspberry Pi durchgeführt. Insgesamt sind die hierbei erhaltenen Werte für den \emph{SpeedUp} und die Effizienz nur geringfügig niedriger als die Vorhersage nach \emph{Amdahl's Law}. Mit zehn Prozessen wird für das gesamte Verfahren ein \emph{SpeedUp} für die \emph{Mountain Car} und \emph{Pendulum} Umgebung von $7.6$ bzw. $5.1$ erzielt. Da diese Werte durch den sequenziellen Anteil des Algorithmus beeinflusst sind, wird die parallelisierte \emph{Evaluation Time} gesondert bewertet. Mit zehn Prozessen liegen die erzielten \emph{SpeedUp} Werte bei $8.5$ und $8.7$. Werden ausschließlich die \emph{Slaves} bei der Berechnung der Effizienz berücksichtigt, beträgt diese in jedem Testdurchlauf mindestens $97\%$. Dies verdeutlicht die Effizienz der Kommunikation und den Erfolg der Parallelisierung.
\\\\
Mit \ac{MPI} ist es möglich, das \ac{GIL} von Python zu umgehen. Damit kann das parallelisierte Verfahren alle $40$ Prozessoren des erstellten Beowulf-Clusters vollständig auslasten. Zwar ist das Verfahren grundsätzlich schneller als mit zehn Prozessen, allerdings skaliert der \emph{SpeedUp} in diesem Fall nicht so gut wie erwartet. Verschiedene Tests belegen, dass nicht die höhere Anzahl der beteiligten Prozesse hierfür ursächlich ist. Diese Erkenntnis ist entscheidend für die Ausführung des Algorithmus in größeren und leistungsfähigeren Clustern. Auf Basis der durchgeführten Tests ist stattdessen zu schlussfolgern, dass mehrere Prozesse auf demselben Raspberry Pi sich gegenseitig blockieren. Dieses Phänomen ist unabhängig von der Anzahl der beteiligten Prozesse. Zur Feststellung der exakten Ursache sind weitere Tests erforderlich, die nicht Teil dieser Arbeit sind. Ein Ressourcenengpass kann möglicherweise beim Zugriff auf Systemressourcen wie dem \ac{RAM} entstehen. Ist die hierfür bereitgestellte Bandbreite nicht für alle vier Prozessoren gleichzeitig ausreichend, kommt es zu Verzögerungen und somit niedrigeren \emph{SpeedUp} Werten. 
\\\\
Die zuletzt vorgestellte \emph{Lunar Lander} Umgebung dient als Beispiel für die Entwicklung einer generellen Lösungsstrategie. Im Vergleich zu den vorherigen Umgebungen verwendet diese zufällige Startzustände und das \ac{KNN} muss lernen, auf diese zu reagieren. Dies ist anspruchsvoller als die Entwicklung einer Lösung für einen einzelnen Startzustand. Hierbei ist ein grundsätzliches Problem, dass die Fitnessfunktion nicht alle Startzustände miteinbezieht. Schlechte \ac{KNN} mit einfachen Startzuständen können gute Fitnesswerte erzielen, vielversprechende \ac{KNN} in schwierigen Umgebungen hingegen nur niedrige Fitnesswerte. Die Gefahr hierbei ist, dass vielversprechende Lösungsansätze aufgrund niedriger Fitnesswerte bei der Selektion nicht ausgewählt werden und verloren gehen. Um dies zu verhindern und einen aussagekräftigen Fitnesswert zu erhalten, wird in diesem Beispiel die Umgebung zehnmal nacheinander mit unterschiedlichen Startzuständen evaluiert. Das Verfahren wird erst dann beendet, wenn für jeden Durchlauf eine gültige Lösung gefunden ist. Wie das Beispiel zeigt, ist dieses Vorgehen erfolgreich. Ein großer Nachteil besteht darin, dass die Evaluationszeit stark erhöht wird. Hier zeigt sich der große Vorteil der Parallelisierung. Mit den zuvor gemessenen \emph{SpeedUp} Werten wird angenommen, dass die Ausführungszeit mit dem sequenziellen Verfahren zwischen $62.1$ und $68.7$ Stunden liegt. In der parallelisierten Umgebung wird das Verfahren hingegen bereits nach $3.5$ Stunden beendet. Es ist davon auszugehen, dass durch Hinzufügen von weiteren Prozessoren die Ausführungszeit entsprechend \emph{Amdahl's Law} weiter gesenkt werden kann. Dieses Beispielproblem verdeutlicht erneut den Erfolg der Parallelisierung.
