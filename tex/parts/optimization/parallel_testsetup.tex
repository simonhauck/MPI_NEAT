% !TeX spellcheck = de_DE
\section{Testumgebung}
\label{sec:test_env_parallel}
Das nächste Kapitel befasst sich mit der Evaluation des parallelisierten Verfahrens und führt einen Vergleich mit der sequenziellen Implementierung durch. Zuvor wird in diesem Kapitel auf die verwendete Testumgebung sowie die Installation der notwendigen Software eingegangen. 
\\\\
Der größte Unterschied dieser Testumgebung im Vergleich zu der des sequenziellen Verfahrens besteht darin, dass das parallelisierte Verfahren nicht auf einem Raspberry Pi 4, sondern auf einem Beowulf-Cluster ausgeführt wird. Insgesamt stehen zehn identisch konfigurierte Raspberry Pi 4 \emph{Nodes} zur Verfügung. Die Hardware von diesen entspricht der Beschreibung in Kapitel \ref{sec:analysis_testsetup}. Somit besitzt der entstehende Cluster die zehnfache Rechenleistung im Vergleich zu der Testumgebung des sequenziellen Verfahrens.
\\\\
Entsprechend  der in Kapitel \ref{subsubsec:beowulf_cluster} definierten Anforderungen an einen Beowulf-Cluster ist jeder Raspberry Pi durch eine Ethernet Verbindung mit einem Netzwerkswitch verbunden. Die maximale Bandbreite für jeden Raspberry Pi beträgt ein Gigabit. Hinsichtlich der Software wird das bisher verwendete Betriebssystem sowie alle Softwarepakete von der sequenziellen Testumgebung übernommen. Allerdings werden für die Kommunikation im Beowulf-Cluster noch weitere Softwarekomponenten benötigt. Zuerst wird das \emph{MPICH} installiert. Wie in Kapitel \ref{subsec:mpi} beschrieben, ist dies eine weit verbreitete \emph{Open-Source}-Implementierung des \ac{MPI} Standards. Zusätzlich wird in der Python Umgebung das bereits vorgestellte Paket \emph{mpi4py} installiert, welches den Zugriff auf \ac{MPI} Funktionen aus Python ermöglicht. Ab diesem Zeitpunkt kann die Implementierung lokal getestet werden. Dennoch kann das Verfahren noch nicht auf dem gesamten Beowulf-Cluster ausgeführt werden, da die einzelnen \emph{Nodes} noch nicht miteinander kommunizieren können. Hierfür wird zusätzlich das \ac{SSH} Protokoll benötigt. Beim Beginn der Ausführung eines \ac{MPI} Programms wird eine \ac{SSH} Verbindung von jedem teilnehmenden Prozess zu allen anderen erstellt, über welche dann die spätere \ac{MPI} Kommunikation erfolgt. Für die Authentifizierung im \ac{SSH} Protokoll wird in diesem Fall ein asymmetrischer kryptographischer Schlüssel benötigt. Auf jedem Raspberry Pi wird hiervon einer erzeugt, welcher aus einem öffentlichen und privaten Teil besteht. Von jedem Raspberry Pi wird der öffentliche Teil des Schlüssels auf den anderen Geräten des Clusters hinterlegt, sodass eine Authentifizierung ohne Passworteingabe möglich ist.
\\\\
Nach Konfiguration des \ac{SSH} Protokolls kann das Optimierungsverfahren gestartet werden, sobald der Programmcode auf allen beteiligten Geräten vorliegt. Prinzipiell kann dieser manuell an jede einzelne \emph{Node} verteilt werden. Dies ist zeitaufwendig und nicht für die aktive Entwicklung geeignet, daher wird in dieser Testumgebung eine automatisierte Lösung angestrebt. Wie in Kapitel \ref{subsubsec:beowulf_cluster} beschrieben, kann die \emph{Master Node} eines Beowulf-Clusters verschiedene organisatorische Aufgaben übernehmen. In diesem Projekt gehört hierzu unter anderem eine Schnittstelle zu den externen Umgebungen, über welche das Optimierungsverfahren gestartet werden kann. Zusätzlich wird für die automatisierte Verteilung des Programmcodes ein Ordner im Netzwerk des Beowulf-Clusters freigegeben. Dieser kann von den \emph{Slaves} lokal hinzufügt werden. Der Programmcode bzw. die benötigten Dateien müssen auf dem \emph{Master} im freigegebenen Ordner vorhanden sein. Mit entsprechender Standardsoftware kann eine automatisierte Verteilung und Synchronisation der Dateien umgesetzt werden. Änderungen sind direkt auf allen \emph{Slaves} verfügbar und fehlende oder inkonsistente Dateien werden vermieden.
