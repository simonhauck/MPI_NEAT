% !TeX spellcheck = de_DE
\section{Strategien zur Parallelisierung}
Es gibt mehrere Möglichkeiten eine Parallelisierung umzusetzen sowie verschiedene Schwerpunkte, auf welche sich diese beziehen kann. Die Analyse der sequenziellen Implementierung hat gezeigt, dass die \emph{Evaluation Time} den größten Einfluss auf die Ausführungszeit hat.  Dementsprechend kann bei einer erfolgreicher Parallelisierung dieser Phase die größte Reduktion der Ausführungszeit erzielt werden. Aus diesem Grund wird sich im Folgenden hierauf fokussiert. 
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.5\textwidth]{./img/ahmdals_law_mountain_pendulum.pdf} 
	\caption{Durch \emph{Amdahl's Law} berechnete theoretische \emph{SpeedUp} für das \emph{Mountain Car} und \emph{Pendulum} Problem in Abhängigkeit der Anzahl an Prozessen}
	\label{fig:amdahls_law_mountain_pendulum}
\end{figure}
Mit \emph{Amdahl's Law}, welches in Kapitel \ref{subsec:basics_performance} vorstellt ist, kann der theoretisch erreichbare \emph{SpeedUp} in Abhängigkeit von $P$ Prozessoren berechnet werden. Dies ist in Abbildung \ref{fig:amdahls_law_mountain_pendulum} dargestellt, wobei entsprechend der Analyseergebnisse angenommen wird, dass die \emph{Mountain Car} Umgebung zu $98\%$ und die \emph{Pendulum} Umgebung zu $91\%$ parallelisiert werden können. Durch die Abbildung ist ersichtlich, dass beide Probleme anfänglich mit steigender Anzahl an Prozessen sehr gute \emph{SpeedUp} Werte erzielen. Allerdings ist das Hinzufügen von weiterer Rechenleistung ab einem gewissen Punkt nicht mehr effektiv, da der Anstieg des \emph{SpeedUps} zunehmend geringer wird und letztendlich gegen einen gewissen Wert konvergiert. Für $P \rightarrow \infty$ ist der maximale \emph{SpeedUp} für die \emph{Mountain Car} Umgebung der Faktor $50$ und für die \emph{Pendulum} Umgebung der Faktor $11.\overline{1}$. Auch wenn diese Ergebnisse eine ungefähre Richtlinie bieten, ist das Erreichen von diesen Vorgaben in einer praktischen Umsetzung unwahrscheinlich. Durch eine hohe Anzahl an beteiligten Prozessen entsteht in der Regel ein hoher Kommunikationsaufwand, was sich negativ auf \emph{SpeedUp} Wert auswirkt. Im Folgenden wird auf verschiedene Strategien eingegangen, mit denen eine möglichst effiziente Parallelisierung umgesetzt werden soll. Hierzu werden verschiedene Vor- und Nachteile gegeneinander abgewogen.
\\\\
Vor dem auswählen einer geeigneten Strategie sollen die zu parallelisierenden Funktionen der \emph{Evaluation Time} analysiert werden. Im sequenziellen Verfahren wird in dieser Phase über eine Liste mit allen Agenten iteriert. Für jeden von diesen wird die Umgebung einmal zurück gesetzt und ein \ac{KNN} aus dem Genom des Agenten gebildet. Danach wird die Umgebung simuliert. Bei diesem Vorgang können beliebige viele Simulationsschritte und Aktivierungen des \ac{KNN} ausgeführt werden. 
\\\\
Ein möglicher Ansatz ist, die Berechnungen in einem \ac{KNN} selbst zu parallelisieren. Dies ist eine valide Strategie, welche unter anderem von Bibliotheken wie Tensorflow und Pytorch genutzt wird. Beispielsweise können die einzelnen Neuronen einer Schicht unabhängig voneinander aktiviert und somit auch parallelisiert werden. Zusätzlich kann eine solche Parallelisierung nicht nur mithilfe von \acp{CPU} sondern auch auf \acp{GPU} umgesetzt werden. Diese haben im Regelfall mehr unabhängige Prozessoren als eine normale \ac{CPU}, womit in vielen Fällen eine bessere Parallelisierung ermöglicht wird. Allerdings sprechen zwei Gründe gegen den Einsatz einer solchen Parallelisierungsstrategie in dieser Arbeit. Die vorgestellten Bibliotheken implementieren diese Funktionalitäten bereits, sind weit verbreitet und für verschiedene Plattformen optimiert. Zusätzlich ist es im Rahmen einer zukünftigen Erweiterung möglich, diese einfach in dieses Projekt zu integrieren. Daher ist es nicht sinnvoll, Ressourcen für die Implementierung derselben Funktionalität zu verwenden. Der zweite Grund der gegen diese Art der Parallelisierung spricht, ist dass zwar die Aktivierungszeit des \ac{KNN} verkürzt wird, nicht aber die Simulationszeit der Umgebung. Diese kann je nach Komplexität des Problems sehr viel Rechenzeit in Anspruch nehmen. 
\\\\
Hier können neuroevolutionäre Algorithmen einen Vorteil bieten, da sowohl das \ac{KNN} als auch die Umgebung parallelisierbar sind. Die Idee ist, dass jeder beteiligte Prozess eine Kopie des Optimierungsproblems initialisiert. Während des Verfahrens wird jeder Agent einem Prozess zugewiesen. Dieser kann dann unabhängig von anderen Prozessen ein \ac{KNN} aus dem Genom erzeugen und mit diesem die gesamte Evaluation in der lokalen Umgebung durchführen. Am Ende muss nur der Fitnesswert als Ergebnis übertragen werden. Dieses Vorgehen bietet mehrere Vorteile. Mit dieser Strategie werden alle Funktionen der \emph{Evaluation Time} parallelisiert, inklusive des Optimierungsproblems und den Berechnungen im \ac{KNN}. In einer zukünftigen Erweiterung kann zusätzlich eine Bibliothek wie Tensorflow integriert werden, welche die benötigte Zeit zum Berechnen des \ac{KNN} reduziert und somit einen noch größeren \emph{SpeedUp} ermöglicht. Ein weiterer Vorteil ist die geringe Anzahl an benötigten Nachrichten. Mit $n$ Agenten müssen theoretisch nur $2 \cdot n$ Nachrichten pro Generation für die Parallelisierung der \emph{Evaluation Time} ausgetauscht werden. Hiervon  wird die erste Hälfte zum verteilten der Agenten und die zweite Hälfte zum sammeln der berechneten Fitnesswerte am Ende der Evaluation benötigt. 

 



% Client Server can prevent deadlocks
% Eventually calculate ahmdals law?