% !TeX spellcheck = de_DE
\section{Implementierung}
\label{sec:parallel_implementation}
In diesem Kapitel wird die Implementierung der zuvor vorgestellten Parallelisierungsstrategie vorgestellt. Das Ziel ist, dass die Ausführungszeit des Verfahrens in einem verteilten System durch hinzufügen von weiteren Prozessoren reduziert wird. Bei der Umsetzung sind drei Anforderungen zu beachten. Erstens muss es mit geringem Aufwand möglich sein die sequenzielle durch die parallelisierte Implementierung auszutauschen und umgekehrt. Die zweite Anforderung ist, dass ein direkter Vergleich zwischen beiden Implementierungen möglich sein muss um die Effizienz der Parallelisierung bewerten zu können. Die dritte und letzte Anforderung ist, dass der Standard \ac{MPI} für die Kommunikation verwendet wird.
\\\\
Für die parallelisierte Implementierung wird eine neue Klasse angelegt, die von dem in Kapitel \ref{subsubsec:library_interface} vorgestellten Interface \emph{NeatOptimizer} erbt. Auch die sequenzielle Implementierung verwendet dieses und somit ist die erste Anforderung bereits erfüllt. Beide Klassen stellen dieselben Funktionen zur Verfügung und können so jederzeit miteinander ausgetauscht werden. Wie in Kapitel \ref{subsubsec:library_interface} erläutert, ist die \emph{evaluate()} Funktion in diesem Interface der Einstiegspunkt für die Bibliothek und das ganze Trainingsverfahren wird in dieser implementiert. 
\\\\
Um die zweite Anforderung zu erfüllen ist der grundsätzliche Ablauf der \emph{evaluate()} Funktion identisch zum sequenziellen Verfahren, sodass sich nur der parallelisierte Teil des Programms unterscheidet. Zu Beginn des Trainingsverfahrens wird eine initiale Population generiert. Danach beginnt eine Schleife, in welcher die Funktionen \emph{build\_new\_generation()} und \emph{evaluate\_generation()} abwechselnd aufgerufen werden bis die Abbruchbedingung erfüllt ist. Da primär die Evaluationsphase parallelisiert wird, kann die \emph{build\_new\_generation()} Funktion vom sequenziellen Verfahren unverändert übernommen werden. In dieser sind die Phasen Selektion, Rekombination und Mutation implementiert. Die Funktion \emph{evaluate\_generation()} umfasst die Evaluation der Agenten. Da die Analyse zeigt, dass sowohl in der \emph{Mountain Car} als auch in der \emph{Pendulum} Umgebung diese Funktion den größten Einfluss auf die benötigte Rechenzeit hat, wird sie im Rahmen der Parallelisierung neu implementiert.
\\\\
Im sequenziellen Verfahren wird bei der Evaluation über die Liste mit allen Agenten iteriert und für jeden nacheinander die Evaluation durchgeführt. Wie bereits in Kapitel \ref{sec:sequential_implementation} beschrieben, wird hierzu vor jedem neuen Agenten die Umgebung einmalig zurück gesetzt, das \ac{KNN} gebildet und letztendlich die eigentliche Evaluation durchgeführt mit dem Ziel einen Fitnesswert am Ende zurückzugeben. Bei der parallelisierten Implementierung sollen die Agenten an alle beteiligten Prozesse verteilt werden, welche dann die Evaluation unabhängig voneinander durchführen können. 
\\\\
Daher muss im nächsten Schritt die Art der Kommunikation und Verteilung der Agenten festgelegt werden. In Kapitel \ref{subsec:mpi} sind die \emph{Scatter} und \emph{Gather} Funktion vorgestellt, welche sich prinzipiell für dieses Szenario anbieten. Die \emph{Scatter} Funktion verteilt die Agenten gleichmäßig auf die Prozesse und die \emph{Gather} Funktion sammelt die Ergebnisse. Zwar ist dies effizient zu implementieren aber es ergibt sich ein großer Nachteil. Die \emph{Scatter} Funktion erlaubt keine dynamische Verteilungen von Lasten, welche in diesem Projekt aus zwei Gründen sinnvoll ist. Der erste betrifft die Evaluationszeiten und der zweite die Struktur des Clusters. Die Evaluationszeiten von Agenten unterscheiden sich in vielen Fällen. Gründe hierfür können einerseits unterschiedlich große \ac{KNN} sein deren Berechnungszeit bzw. Aktivierungszeit variiert aber auch unterschiedliche Fortschritte im Optimierungsproblem. In der vorgestellten \emph{Mountain Car} Umgebung wird beispielsweise die Evaluation beendet, wenn der Agent das Ziel erreicht. In anderen Optimierungsproblemen kann die Evaluation frühzeitig abgebrochen werden, weil ein Agent eine gewisse Fehlentscheidung getroffen hat. Die Folge in beiden Szenarien ist, dass im Vergleich zu anderen Prozessen weniger Rechenaufwand für die Evaluation des Agenten benötigt wird. Hierdurch entsteht ein Ungleichgewicht in der Lastenverteilung. Die Folge ist, dass am Ende einer Evaluationsphase die Prozesse aufeinander warten. Somit sinkt die Effizienz und auch der erreichte \emph{SpeedUp} Wert der Parallelisierung. Selbst wenn alle Agenten dieselbe Rechenlast erzeugen und diese gleichmäßig auf alle Prozesse verteilt ist, kann es in einem Beowulf Cluster zu Wartezeiten kommen. Grund hierfür ist, dass sich die Konfiguration der Hardware bei den einzelnen Geräten des Clusters und somit auch deren Leistung unterscheiden kann. Für eine gute Performance des parallelisierten Verfahren, müssen die Prozessoren bzw. Geräte des Clusters welche mehr Rechenleistung bieten, auch proportional mehr Rechenlast zugewiesen bekommen. Dies ist mit der \emph{Scatter} Funktion nicht möglich.
\\\\
Stattdessen soll in dieser Arbeit die \emph{Point-to-Point} Kommunikation verwendet, mit welcher ein dynamisches Zuteilen möglich ist. Um mögliche \emph{Deadlocks} zu vermeiden wird eine \emph{Master-Slave} Architektur gewählt. Zu Beginn der Evaluationsphase erstellt der \emph{Master} Prozess verschiedene Arbeitspakete, welche jeweils einen zu evaluierenden Agenten enthalten. Initial wird an jeden \emph{Slave} Prozess ein Paket asynchron gesendet, welche hierauf warten. Ist dieses vollständigen Empfangen, wird der darin enthaltene Agent im lokalen Optimierungsproblem evaluiert und der berechnete Fitnesswert als Ergebnis zurück an den \emph{Master} Prozess gesendet. Dieser ist für die Speicherung verantwortlich. Danach wird überprüft ob noch weitere Arbeitspakete zur Abarbeitung ausstehen. Ist dies der Fall, wird ein neues Pakt an den \emph{Slave} übermittelt. Erst wenn alle Pakete abgearbeitet sind, endet die Evaluation der Generation. Danach führt der \emph{Master} Prozess die nötigten Operationen zum Erzeugen der nächsten Generation aus. Dabei werden die gespeicherten Ergebnisse der \emph{Slaves} verwendet. Mit der neuen Generation beginnt dann erneut die Evaluation. Ein großer Vorteil dieses Verfahrens ist, dass Prozesse automatisch mehr Arbeitspakete zugeteilt bekommen wenn sie entweder leistungsfähiger sind oder die Agenten kürzere Evaluationszeiten haben. Zusätzlich ist die Kommunikationsstruktur streng geregelt, sodass das Auftreten von \emph{Deadlocks} unwahrscheinlich ist.
\\\\
Für die praktische Umsetzung muss der Implementierung noch eine Klasse \emph{Slave} hinzugefügt werden, welche die notwendigen Operationen enthält. Dies umfasst eine Funktion \emph{setup()}, die zum Erstellen des Optimierungsproblems bzw. der Umgebung benötigt wird und die Funktion \emph{evaluate\_agent()}. Als Parameter wird dieser Funktion ein Agent übergeben, der dann evaluiert wird. Im Rahmen dessen wird die Umgebung auf den Startzustand gesetzt, ein \ac{KNN} mit dem Genom des Agenten erzeugt und dann die eigentliche Evaluation in der lokalen Umgebung durchgeführt. Die Funktion gibt am Ende den Fitnesswert sowie optionale Zusatzinformationen der Umgebung zurück. Insgesamt entspricht diese Funktionalität der des sequenziellen Verfahrens. Die \emph{setup()} Funktion erstellt die Umgebung, benötigt aber einen anderen Implementierungsansatz als die \emph{evaluate\_agent()} Funktion. Der Grund hierfür ist der Parameter. Ein Agent enthält nur Daten und keine Funktionalität. Aus diesem Grund kann er einfach mit \ac{MPI} serialisiert und versendet werden. Ein Optimierungsproblem hingegen kann eine komplexe Klasse mit unterschiedlichen Funktionen sein, die unter Umständen nicht serialisiert werden können. Zusätzlich hat die implementierte Bibliothek keine Informationen über die enthaltenen Funktionalitäten, die Architektur und den internen Zustand der Umgebung. Grund hierfür ist, dass neue Optimierungsprobleme von Nutzern jederzeit hinzugefügt werden können es für diese keine Einschränkungen geben soll. Daher kann das Optimierungsproblem nicht mit \ac{MPI} serialisiert werden. Stattdessen wird der Umstand genutzt, dass der Programmcode auf jedem beteiligten Gerät bzw. Prozessor vorliegen muss. Beim Starten einer \ac{MPI} Anwendung wird auf jedem beteiligten Prozess eine Kopie des Programms ausgeführt. Hierbei kann jeder Prozess auf Basis des zugewiesenen Rangs entscheiden ob er der \emph{Master} oder ein \emph{Slave} ist. Der \emph{Master} führt die notwendigen Operationen zum Erstellen der initialen Generation durch und startet den Optimierungsprozess. Die \emph{Slaves} hingegen können auf das im Programmcode vorliegende Optimierungsproblem zugreifen und es initialisieren. Bei einem solchen Vorgehen muss das Optimierungsproblem nicht serialisiert und versendet werden.
\\\\
Der letzte hier vorgestellt Implementierungsaspekt bezieht sich auf die Umsetzung der \emph{Point-to-Point} Kommunikation. Hierfür wird das Paket \emph{mpi4py} verwendet, welches eine Python Schnittstelle zum Nutzen von \ac{MPI} Funktionen bietet. Das Paket selbst ist \emph{open source} und im Vergleich zu anderen Implementierungen weit verbreitet. Zusätzlich bietet es eine gute Performance, welche in Quelle \cite{dalcin2008mpi} gemessen wurde und nur geringfügig langsamer ist als eine Implementierung in der Programmiersprache C. Ein letzter entscheidender Vorteil sind verschiedene in der Bibliothek implementierte high-level Funktionen. Diese ermöglichen unter anderem das einfache Umsetzen einer \emph{Master-Slave} Kommunikation, wie sie oben beschrieben ist. Diese Funktionen werden in dieser Arbeit für die Kommunikation verwendet.
