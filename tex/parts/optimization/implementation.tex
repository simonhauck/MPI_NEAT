% !TeX spellcheck = de_DE
\section{Implementierung}
\label{sec:parallel_implementation}
Dieses Kapitel befasst sich mit der Implementierung der bereits vorgestellten Parallelisierungsstrategie. Das Ziel ist, die Ausführungszeit des Verfahrens in einem verteilten System durch Hinzufügen von weiteren Prozessoren zu reduzieren. Bei der Umsetzung sind drei Anforderungen zu beachten. Erstens muss es mit geringem Aufwand möglich sein, die sequenzielle Implementierung durch die parallelisierte auszutauschen und umgekehrt. Zweitens muss für eine Bewertung der Effizienz der Parallelisierung ein direkter Vergleich zwischen beiden Implementierungen möglich sein. Drittens ist der Standard \ac{MPI} für die Kommunikation zu verwenden
\\\\
Für die parallelisierte Implementierung wird eine neue Klasse angelegt, die von dem in Kapitel \ref{subsubsec:library_interface} vorgestellten Interface \emph{NeatOptimizer} erbt. Da die sequenzielle Implementierung dasselbe Interface verwendet, ist die erste Anforderung bereits erfüllt. Beide Klassen stellen dieselben Funktionen zur Verfügung und können somit jederzeit gegeneinander ausgetauscht werden. Wie in Kapitel \ref{subsubsec:library_interface} erläutert, ist die \emph{evaluate()} Funktion in diesem Interface der Einstiegspunkt für die Bibliothek und das gesamte Trainingsverfahren ist in dieser implementiert. 
\\\\
Um die zweite Anforderung zu erfüllen, ist der grundsätzliche Ablauf der \emph{evaluate()} Funktion identisch zum sequenziellen Verfahren, sodass sich nur der parallelisierte Teil des Programms unterscheidet. Zu Beginn des Trainingsverfahrens wird eine initiale Population generiert. Danach beginnt eine Schleife, in welcher die Funktionen \emph{build\_new\_generation()} und \emph{evaluate\_generation()} abwechselnd aufgerufen werden bis die Abbruchbedingung erfüllt ist. Da primär die Evaluationsphase parallelisiert wird, kann die \emph{build\_new\_generation()} Funktion vom sequenziellen Verfahren unverändert übernommen werden. In dieser sind die Phasen Selektion, Rekombination und Mutation implementiert. Die Funktion \emph{evaluate\_generation()} umfasst die Evaluation der Agenten. Da die Analyse zeigt, dass sowohl in der \emph{Mountain Car} als auch in der \emph{Pendulum} Umgebung diese Funktion den größten Einfluss auf die benötigte Rechenzeit hat, wird sie im Rahmen der Parallelisierung neu implementiert.
\\\\
Im sequenziellen Verfahren wird bei der Evaluationsphase über die Liste mit allen Agenten iteriert und für jeden nacheinander die Evaluation durchgeführt. Wie bereits in Kapitel \ref{sec:sequential_implementation} beschrieben, wird für jeden neuen Agenten die Umgebung einmalig zurückgesetzt, das \ac{KNN} gebildet und die eigentliche Evaluation mit dem Ziel durchgeführt, am Ende einen Fitnesswert zurückzugeben. Bei der parallelisierten Implementierung werden die Agenten an alle beteiligten Prozesse verteilt, welche dann die Evaluation unabhängig voneinander durchführen. 
\\\\
Dafür muss im nächsten Schritt die Art der Kommunikation und Verteilung der Agenten festgelegt werden. In Kapitel \ref{subsec:mpi} sind die \emph{Scatter} und \emph{Gather} Funktionen vorgestellt, welche sich prinzipiell für dieses Szenario anbieten. Die \emph{Scatter} Funktion verteilt die Agenten gleichmäßig auf die Prozesse und die \emph{Gather} Funktion sammelt die Ergebnisse. Zwar ist die Implementierung effizient, es ergibt sich aber ein gewichtiger Nachteil. Die \emph{Scatter} Funktion erlaubt keine dynamische Verteilung von Lasten, was in diesem Projekt jedoch aus zwei Gründen sinnvoll ist. Der erste Grund betrifft die Evaluationszeiten, der zweite die Struktur des Clusters. Die Evaluationszeiten der Agenten unterscheiden sich in vielen Fällen. Gründe hierfür können zum einen unterschiedlich große \ac{KNN} sein, deren Berechnungszeit bzw. Aktivierungszeit variiert, zum anderen unterschiedliche Fortschritte im Optimierungsproblem. In der vorgestellten \emph{Mountain Car} Umgebung wird beispielsweise die Evaluation beendet, wenn der Agent das Ziel erreicht. In anderen Optimierungsproblemen kann die Evaluation frühzeitig abgebrochen werden, wenn ein Agent eine bestimmte Fehlentscheidung getroffen hat. Die Folge in beiden Szenarien ist, dass im Vergleich zu anderen Prozessen weniger Rechenaufwand für die Evaluation des Agenten benötigt wird. Hierdurch entsteht ein Ungleichgewicht in der Lastenverteilung. Die Folge ist, dass am Ende einer Evaluationsphase die Prozesse aufeinander warten. Somit sinkt die Effizienz und auch der erreichte \emph{SpeedUp} Wert der Parallelisierung. Auch wenn alle Agenten dieselbe Rechenlast erzeugen und diese gleichmäßig auf alle Prozesse verteilt ist, kann es in einem Beowulf Cluster zu Wartezeiten kommen. Grund hierfür ist, dass sich die Konfiguration der Hardware bei den einzelnen Geräten des Clusters und somit auch deren Leistung unterscheiden kann. Für eine gute Performance des parallelisierten Verfahrens müssen die Prozessoren bzw. Geräte des Clusters, welche mehr Rechenleistung bieten, auch proportional mehr Rechenlast zugewiesen bekommen. Dies ist mit der \emph{Scatter} Funktion nicht möglich.
\\\\
Daher soll in dieser Arbeit die \emph{Point-to-Point} Kommunikation verwendet werden, mit welcher ein dynamisches Zuteilen möglich ist. Um mögliche \emph{Deadlocks} zu vermeiden, wird eine \emph{Master-Slave} Architektur gewählt. Zu Beginn der Evaluationsphase erstellt der \emph{Master} Prozess verschiedene Arbeitspakete, welche jeweils einen zu evaluierenden Agenten enthalten. Initial wird an jeden \emph{Slave} Prozess asynchron ein Paket gesendet, welche hierauf warten. Ist dieses vollständig empfangen, wird der darin enthaltene Agent im lokalen Optimierungsproblem evaluiert und der berechnete Fitnesswert als Ergebnis an den \emph{Master} Prozess zurückgesendet. Dieser ist für die Speicherung zuständig. Danach wird überprüft, ob noch weitere Arbeitspakete zur Abarbeitung ausstehen. Ist dies der Fall, wird ein neues Paket an den \emph{Slave} übermittelt. Erst wenn alle Pakete abgearbeitet sind, endet die Evaluation der Generation. Danach führt der \emph{Master} Prozess die erforderlichen Operationen zum Erzeugen der nächsten Generation aus. Dabei werden die gespeicherten Ergebnisse der \emph{Slaves} verwendet. Mit der neuen Generation beginnt die Evaluation erneut. Ein großer Vorteil dieses Verfahrens ist, dass Prozesse automatisch mehr Arbeitspakete zugeteilt bekommen, wenn sie entweder leistungsfähiger oder die Evaluationszeiten der Agenten kürzer sind. Zusätzlich ist die Kommunikationsstruktur strikt geregelt, sodass das Auftreten von \emph{Deadlocks} unwahrscheinlich ist.
\\\\
Für die praktische Umsetzung muss der Implementierung noch die Klasse \emph{Slave} hinzugefügt werden, welche die notwendigen Operationen enthält. Dies umfasst die Funktion \emph{setup()}, welche zum Erstellen des Optimierungsproblems bzw. der Umgebung benötigt wird und die Funktion \emph{evaluate\_agent()}. Als Parameter wird dieser Funktion ein Agent übergeben, der dann evaluiert wird. Im Rahmen dessen wird die Umgebung auf den Startzustand gesetzt, ein \ac{KNN} mit dem Genom des Agenten erzeugt und die eigentliche Evaluation in der lokalen Umgebung durchgeführt. Die Funktion gibt am Ende den Fitnesswert sowie optionale Zusatzinformationen der Umgebung zurück. Insgesamt entspricht diese Funktionalität der des sequenziellen Verfahrens. Die \emph{setup()} Funktion erstellt die Umgebung, benötigt aber einen anderen Implementierungsansatz als die \emph{evaluate\_agent()} Funktion. Der Grund hierfür ist der Parameter. Ein Agent enthält nur Daten, aber keine Funktionalität. Aus diesem Grund kann er einfach mit \ac{MPI} serialisiert und versendet werden. Ein Optimierungsproblem hingegen kann eine komplexe Klasse mit unterschiedlichen Funktionen sein, die unter Umständen nicht serialisiert werden können. Zusätzlich sind in der implementierten Bibliothek keine Informationen über die Funktionalitäten, Architektur und den internen Zustand der Umgebung enthalten. Grund hierfür ist, dass neue Optimierungsprobleme von Nutzern jederzeit hinzugefügt werden können und es diesbezüglich keine Einschränkungen geben soll. Daher kann das Optimierungsproblem nicht mit \ac{MPI} serialisiert werden. Stattdessen wird der Umstand genutzt, dass der Programmcode auf jedem beteiligten Gerät bzw. Prozessor vorliegen muss. Beim Starten einer \ac{MPI} Anwendung wird auf jedem beteiligten Prozess eine Kopie des Programms ausgeführt. Hierbei kann jeder Prozess auf Basis des zugewiesenen Rangs entscheiden, ob er die Funktion eines \emph{Masters} oder \emph{Slaves} einnimmt. Der \emph{Master} führt die notwendigen Operationen zum Erstellen der initialen Generation durch und startet den Optimierungsprozess. Die \emph{Slaves} greifen auf das im Programmcode vorliegende Optimierungsproblem zu und initialisieren es. Bei einem solchen Vorgehen ist es nicht erforderlich, das Optimierungsproblem zu serialisieren und zu versenden.
\\\\
Der letzte hier vorgestellte Implementierungsaspekt bezieht sich auf die Umsetzung der \emph{Point-to-Point} Kommunikation. Hierfür wird das Paket \emph{mpi4py} verwendet, welches eine Python Schnittstelle zum Nutzen von \ac{MPI} Funktionen bietet. Das Paket selbst ist \emph{open source} verfügbar und im Vergleich zu anderen Implementierungen weit verbreitet. Zusätzlich bietet es eine gute Performance welche in Quelle \cite{dalcin2008mpi} gemessen wurde und als nur geringfügig langsamer als eine Implementierung in der Programmiersprache C beschrieben ist. Ein letzter entscheidender Vorteil sind verschiedene in der Bibliothek implementierte \emph{high-level} Funktionen. Diese ermöglichen unter anderem das einfache Umsetzen der oben beschriebenen \emph{Master-Slave} Kommunikation. Diese Funktionen werden in dieser Arbeit für die Kommunikation verwendet.
