% !TeX spellcheck = de_DE
\section{Erkenntnisse}
\label{sec:analysis_results}
Nach Beendigung der vorherigen Optimierungsprobleme werden die Ergebnisse in diesem Kapitel zusammengefasst. Alle vorgestellten Optimierungsverfahren konnten durch die einfache Schnittstelle der Bibliothek schnell und einfach implementiert werden. Dies trifft sowohl auf individuell erstellte Optimierungsprobleme aber auch auf die Standardprobleme aus dem OpenAI Gym zu. Auch die restlichen Anforderungen aus dem Kapitel \ref{sec:requirements} sind vollständig implementiert. Der ganze Ablauf des Algorithmus kann mithilfe eines spezifizierten \emph{Seeds} beeinflusst und wiederholt werden. Durch die verschiedenen Abbildungen im vorherigen Kapitel ist bewiesen, dass die Testergebnisse der Trainingsverfahren gemessen, visualisiert und gespeichert werden können, sodass ein späterer Vergleich mit der parallelisierten Implementierung möglich ist.
\\\\
Die Funktionalität des Algorithmus, neue Strukturen zu entwickeln und zu optimieren, ist mit dem XOR-Problem bewiesen. Mit derselben Konfiguration werden ähnliche Ergebnisse im Vergleich zur originalen Implementierung gemessen. Durch einige Anpassungen konnten bei nachfolgenden Versuchen sogar bedeutend bessere Ergebnisse erzielt werden. Bei Betrachtung der Ausführungszeit ist bei diesem Beispiel, die Zeit zum Erstellen und Mutieren von Nachkommen der größte Faktor. Aber da das XOR-Problem insgesamt sehr einfach ist und somit aufwändigere Probleme nicht richtig repräsentiert, werden die Ergebnisse im weiteren Verlauf nicht beachtet.
\\\\
Im nächsten Schritt wurden daher die \emph{Cartpole}, \emph{Mountain Car} und \emph{Pendulum} Umgebung des OpenAI Gyms implementiert, welche aufwändiger zu lösen sein sollten als das XOR-Problem. Bei den Tests hat sich ergeben, dass die erste Umgebung ungeeignet ist, da bereits die zufällig erstellten \ac{KNN} der ersten Generation das Optimierungsproblem lösen können. Dies gilt nicht für die zwei anderen Umgebungen. Im vorgestellten Szenario wurden für die erste Umgebung $105$ und für die zweite Umgebung $125$ Minuten zur erfolgreichen Optimierung benötigt. Zwar hat \ac{NEAT} beide Probleme erfolgreich gelöst, dennoch werden die Grenzen des Algorithmus aufgezeigt. Vor allem auf dem Raspberry Pi sind die benötigten Optimierungszeiten für verhältnismäßig kleine Probleme sehr hoch. Große Optimierungsprobleme, bei denen die Eingabevektoren aus mehreren tausend Werten bestehen, können aufgrund der begrenzten Rechenleistung nicht oder nur unter sehr hohem Zeitaufwand optimiert werden. Da der Fokus dieser Arbeit auf dem Vergleich zwischen einer sequenziellen und parallelisierten Implementierung liegt ist dieser Umstand zu vernachlässigen.
\\\\
Bei Betrachtung der Ausführungszeiten ist sowohl für das \emph{Mountain Car} und \emph{Pendulum} Problem ersichtlich, dass der größte Faktor die Evaluationsphase ist. In der ersten Umgebung wurden $98\%$ und in der zweiten $91\%$ der Ausführungszeit für das Erstellen und Evaluieren von \ac{KNN} verwendet. Da im Falle einer erfolgreichen Parallelisierung in dieser Phase die meiste Ausführungszeit eingespart werden kann, wird sich im folgenden Kapitel primär hierauf konzentriert. Für die eigentliche Parallelisierung ist wichtig, dass nicht nur die Berechnungen des \ac{KNN} optimiert werden. Im Rahmen der \emph{Evaluation Time} wird neben der benötigten Zeit zum Erstellen und Aktivieren eines \ac{KNN} wird auch die benötigte Zeit zum Simulieren der Umgebung gemessen. Diese kann einen großen Einfluss auf das Gesamtergebnis haben. An zweiter und dritter Stelle der Priorisierung stehen die Parallelisierungen der Funktionen in den Phasen \emph{Compose Offspring Time} und \emph{Reproduction Time}. Beide haben einen bedeutend geringeren Anteil an der gesamten Ausführungszeit und dementsprechend weniger Zeit kann eingespart werden. Ob und wie diese implementiert werden können, wird in den Kapiteln (TODO erläutert!). % TODO Kapitel
\\\\
Zuletzt soll hervorgehoben sein, dass bei den vorstellten Optimierungsproblemen keine generelle Lösungsstrategie entwickelt wird. Hierfür müssten verschiedene Startsituationen in der Evaluationsphase getestet werden, indem beispielsweise jeder Agent in $x$ verschiedenen Umgebungen getestet wird und der mittlere Fitnesswert verwendet werden. Dies würde die Evaluationszeit um den Faktor $x$ erhöhen, was in dem gegebenen Anwendungsszenario eine Analyse bedeutend aufwändiger machen würde. Mit der parallelisierten Version in Kapitel (TODO KAPITEL) kann ein solches Verfahren umgesetzt und ein entsprechendes \ac{KNN} schneller entwickelt werden.

