% !TeX spellcheck = de_DE
\section{Erkenntnisse}
\label{sec:analysis_results}
Nach Beendigung der vorherigen Optimierungsprobleme werden die Ergebnisse in diesem Kapitel zusammengefasst. Alle vorgestellten Optimierungsverfahren konnten durch die einfache Schnittstelle der Bibliothek schnell und einfach implementiert werden. Dies trifft sowohl auf individuell erstellte Optimierungsprobleme aber auch auf die Standardprobleme aus dem OpenAI Gym zu. Auch die restlichen Anforderungen aus Kapitel \ref{sec:requirements} sind vollständig implementiert. Der ganze Ablauf des Algorithmus kann mithilfe eines spezifizierten \emph{Seeds} beeinflusst und wiederholt werden. Durch die verschiedenen Abbildungen im vorherigen Kapitel ist bewiesen, dass die Testergebnisse der Trainingsverfahren gemessen, visualisiert und gespeichert werden können, sodass ein späterer Vergleich mit der parallelisierten Implementierung möglich ist.
\\\\
Die Funktionalität des Algorithmus neue Strukturen zu entwickeln und zu optimieren ist mit dem XOR-Problem bewiesen. Mit derselben Konfiguration werden ähnliche Ergebnisse im Vergleich zur originalen Implementierung gemessen. Durch das Anpassen der Konfiguration konnten bei weiteren Versuchen bedeutend bessere Ergebnisse erzielt werden. Bei Betrachtung der Ausführungszeit ist bei diesem Beispiel die Zeit zum Erstellen und Mutieren von nach Nachkommen der größte Faktor. Da das XOR-Problem insgesamt sehr einfach ist, werden die Ergebnisse im weiteren Verlauf nicht beachtet. Der Grund hierfür ist, dass die Ergebnisse nicht repräsentativ sind und aufwändigere Probleme betrachtet werden müssen.
\\\\
Hierfür sollten die \emph{Cartpole}, \emph{Mountain Car} und \emph{Pendulum} Umgebung des OpenAI Gyms genutzt werden. Bei den Tests hat sich ergeben, dass die erste Umgebung ungeeignet ist, da bereits die zufällig erstellten \ac{KNN} der ersten Generation das Optimierungsproblem lösen konnten. Dies gilt nicht für die zwei anderen Umgebungen. Im vorgestellten Szenario wurden für die erste Umgebung $105$ und für die zweite Umgebung $125$ Minuten zur erfolgreichen Optimierung benötigt. Zwar hat \ac{NEAT} beide Probleme erfolgreich gelöst, aber trotzdem werden die Grenzen des Algorithmus aufgezeigt. Vor allem auf dem Raspberry Pi sind die benötigten Optimierungszeiten für verhältnismäßig kleine Probleme sehr hoch. Große Optimierungsprobleme, bei denen die Eingabevektoren aus mehreren tausend Werten bestehen, können aufgrund der mangelnden Rechenleistung nicht oder nur unter sehr hohem Zeitaufwand optimiert werden. Aber da der Fokus dieser Arbeit auf dem Vergleich zwischen einer sequenziellen und parallelisierten Implementierung liegt ist dieser Umstand zu vernachlässigen.
\\\\
Bei Betrachtung der Ausführungszeiten ist sowohl für das \emph{Mountain Car} und \emph{Pendulum} Problem ersichtlich, dass der größte Faktor die Evaluationsphase ist. In der ersten Umgebung wurden $98\%$ und in der zweiten $91\%$ der Ausführungszeit für das Erstellen und Evaluieren von \ac{KNN} verwendet. Da im Falle einer erfolgreichen Parallelisierung in dieser Phase die meiste Ausführungszeit eingespart werden kann, wird sich im folgenden Kapitel primär hierauf konzentriert. Bei der Parallelisierung sollte aber nicht nur eine schnellere und effizientere Implementierung das \ac{KNN} in Betracht gezogen werden. Im Rahmen der \emph{Evaluation Time} wird nicht nur die benötigte Zeit zum erstellen und aktivieren eines \ac{KNN} gemessen sondern auch die benötigte Zeit um die Umgebung zu simulieren. Dies kann einen sehr großen Einfluss auf das Gesamtergebnis haben. An zweiter und dritter Stelle der Priorisierung für die parallelisierte Implementierung stehen die \emph{Compose Offspring Time} und \emph{Reproduction Time}. Beide haben einen bedeutend geringeren Anteil an der gesamten Ausführungszeit und dementsprechend kann weniger Zeit eingespart werden. 
\\\\
Zuletzt soll hervorgehoben sein, dass bei den vorstellten Optimierungsproblemen keine generelle Lösungsstrategie entwickelt wird. Hierfür müssten verschiedene Startsituationen in der Evaluationsphase getestet werden, indem beispielsweise jeder Agent in $x$ verschiedenen Umgebungen getestet wird und der mittlere Fitnesswert verwendet werden. Dies würde die Evaluationszeit um den Faktor $x$ erhöhen, was in dem gegebenen Anwendungsszenario eine Analyse bedeutend aufwändiger machen würde. Mit der parallelisierten Version in Kapitel (TODO KAPITEL) kann ein solches Verfahren umgesetzt und ein entsprechendes \ac{KNN} schneller entwickelt werden.


% Library einfach zu nutzen,
% Verschieden Probleme können abgebildet werden
% XOr Funktinoalität bewiesen
% Cartpole unnötig
% Pendulum und MOuntain Car zeigen, dass Evaluationszeit besonders hoch ist
% Keine Generalistische Lösung, da ansonssten Zeit bedeutend länger wäre

