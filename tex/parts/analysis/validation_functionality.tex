% !TeX spellcheck = de_DE
\section{Verifizierung der Funktionalität}
\label{sec:analysis_valdation_functionality}
Bevor die Analyse von aufwändigen Optimierungsproblemen durchgeführt wird, soll die korrekte Funktionalität der sequenziellen Implementierung mit einem einfachen Beispiel getestet werden. Hierfür liegt der Fokus vor allem auf den strukturellen Mutation, welche essenziell für größere Probleme sind. Durch eine fehlerhafte Implementierung kann beispielsweise das langfristige Integrieren von neuen erforderlichen Strukturen fehlschlagen. Alternativ kann es vorkommen, dass ein lokales Maximum durch einen Agenten gefunden wird, dessen Genom dann die restliche Population dominiert, mit der Folge, dass keine neuen Lösungsansätze entwickelt werden können.
\\\\
Um solche Fehler zu entdecken und die korrekte Funktionalität des Algorithmus zu verifizieren bietet sich das XOR-Problem besonders gut an. Zusätzlich kann ein Vergleich zwischen den erhaltenen Ergebnissen und der originalen Implementierung durchgeführt werden, da auch die Funktionalität von dieser mit dem XOR-Problem verifiziert wurde und die Ergebnisse in Quelle \cite{stanley2002evolving} veröffentlicht sind. Die klassische XOR-Funktion erhält zwei binäre Eingabewerte und erzeugt einen Ausgabewert. Dieser nimmt den Wert $1$ an, wenn genau einer der beiden Eingabewerte $1$ ist. Andernfalls gibt die Funktion den Wert $0$ zurück. Die Abbildung (TODO ABBILDUNG) zeigt links alle möglichen Kombinationen mit zwei Eingabewerten sowie die dazugehörigen Ergebnisse. Rechts in der Abbildung sind die Eingabe- und Ausgabewerte zweidimensional dargestellt. Ziel des XOR-Problems ist, dass ein neuronales Netz für jedes mögliche Paar der Eingabewerte den richtigen Ausgabewert berechnet bzw. den Klassen $0$ und $1$ zuordnet. Durch die Abbildung (TODO ABBILDUNG) ist erkennbar, dass das Unterteilen der Ausgabewerte in die zwei Klassen $0$ und $1$ nicht mit einer linearen Funktion möglich ist. Diese Eigenschaft macht die XOR-Funktion für die Verifizierung der Funktionalität von \ac{NEAT} besonders geeignet. Wie in Kapitel \ref{subsec:network_structures} beschrieben, kann ein \ac{KNN} ohne \emph{Hidden}-Neuronen nur eine lineare Funktion abbilden und ist somit nicht in der Lage das XOR-Problem zu lösen. Dies trifft auch auf die \ac{KNN} der initiale Population von \ac{NEAT} zu, welche mit einer minimalen Struktur beginnen, die nur aus \emph{Input}- und \emph{Output}-Neuronen besteht. Somit müssen für das erfolgreiche Lösen des XOR-Problems neue Neuronen und Verbindungen erfolgreich in die Population integriert und optimiert werden. 

\subsection{Implementierung}
\begin{figure}
	\begin{python}
		class OptimizationProblemXOR(OptimizationProblem):
		
		xor_tuples = [[0, 0, 0], [1, 0, 1], [0, 1, 1], [1, 1, 0]]
		
		def evaluate(self, neural_network) -> (float, Dict[str, object]):
		fitness_val = 4.0
		
		for xor_input in ChallengeXOR.xor_tuples:
		inputs = [xor_input[0], xor_input[1]]
		result_array = neural_network.activate(inputs)
		result = result_array[0]
		
		fitness_val -= (abs(xor_input[2] - result))
		
		
		# Square remaining fitness
		fitness_val = fitness_val ** 2
		
		return fitness_val, None
	\end{python}
	\label{fig:xor_implementation problem}
	\caption{Implementierung des XOR-Problems in Python}
\end{figure} 
In Abbildung \ref{fig:xor_implementation problem} ist die Implementierung dieses Optimierungsproblems abgebildet, welche im folgenden genauer erläutert wird. Zu erkennen ist, dass die Implementierung nur wenige Zeilen Programmcode benötigt, was die einfache Nutzung der Bibliothek für verschiedene Optimierungsprobleme verdeutlicht. Zu Beginn des Optimierungsproblems ist eine Liste definiert, welche die verschiedenen Kombinationen der Ein- und Ausgabewerte des XOR-Problems enthält. Danach ist die \emph{evaluate()} Funktion implementiert, welche als Parameter ein initialisiertes \ac{KNN} übergeben bekommt und mit diesem versucht das XOR-Problem zu lösen. Das \ac{KNN} besitzt entsprechend der später vorgestellten Konfiguration zwei Eingabewerte und einen Ausgabewert. Zum Lösen des Optimierungsproblems wird über die verschiedenen Kombination von Eingabewerten iteriert und für jeden Eintrag das \ac{KNN} einmal aktiviert. Das Ergebnis der Aktivierung ist eine Liste, welche in diesem Fall entsprechend der Anzahl aus Ausgabeneuronen nur einen Wert enthält, das Ergebnis des \ac{KNN} für die XOR-Funktion. Bei dieser Art der Implementierung wird davon ausgegangen, dass eine Sigmoidfunktion für die Neuronen verwendet wird, sodass das Ergebnis zwischen $0$ und $1$ liegen wird. Der Ausgabewert allein ist nicht ausreichend, da wie in den vorherigen Kapiteln beschrieben die \emph{evaluate()} Funktion den Fitnesswert berechnen und diesen als Ergebnis zurückgeben muss. Somit muss im nächsten Schritt die Fitnessfunktion entwickelt werden, welche in diesem Beispiel der Funktion aus der Quelle \cite{stanley2002evolving} entspricht. Zu Beginn wird der Fitnesswert, entsprechend der Anzahl an Berechnungen, auf $4$ initialisiert. Nach jeder Aktivierung wird die Differenz zwischen dem erwarteten und tatsächlich erhaltenem Ergebnis berechnet und anschließend von dem Fitnesswert subtrahiert. Da die Differenz aufgrund der Aktivierungsfunktion und der Ausgabewerte zwischen $0$ und $1$ liegen muss, ist der Fitnesswert am Ende der Schleife mindestens $0$ und maximal $4$. Der verbleibende Wert wird noch quadriert, sodass ein besserer Agent einen proportional höheren Fitnesswert erhält \cite{stanley2002evolving}. Am Ende wird dies als Ergebnis der Funktion zurück gegeben. Wie aus der Funktionssignatur zu entnehmen ist, kann optional zusätzlich ein \emph{Dict} übergeben werden, welches Zusatzinformationen enthält. In diesem könnte beispielsweise ein \emph{boolean} Wert enthalten sein, welcher anzeigt ob das \ac{KNN} für alle Eingaben den korrekten Wert berechnet hat. Dieser Wert kann dann beispielsweise für die Abbruchbedingung verwendet werden.


\subsection{Parametrisierung und Ergebnisse}
Die grundsätzliche Implementierung des Optimierungsproblems für das XOR-Problem ist im vorherigen Kapitel beschrieben. Bevor das Verfahren durchgeführt wird sind noch einige grundlegende Parameter zu bestimmen, welche sich bei diesem Beispiel an Quelle \cite{stanley2002evolving} orientieren. Wie bereits beschrieben besitzen jedes \ac{KNN} entsprechend dem Optimierungsproblem zwei Input-Neuronen und ein Output-Neuron. Zusätzlich verwenden alle Neuronen als Aktivierungsfunktion eine modifizierte Sigmoidfunktion deren Ausgabewert mit $f_{act}(net_j)=\frac{1}{1+e^{-4.9\cdot net_j}}$ berechnet wird. Des weiteren ist die Abbruchbedingung zu bestimmen. Das Optimierungsverfahren wird beendet, wenn ein \ac{KNN} für alle vier Eingabekombinationen den richtigen Ausgabewert erzeugt. Hierbei wird das Ergebnis als korrekt gewertet, wenn der Ausgabewert $o$ für alle Kombinationen die $1$ ergeben sollen $o \geq 0.5$ ist. Dementsprechend muss für alle Kombinationen die $0$ ergeben sollen, $o < 0.5$ zutreffen. Zusätzlich wird in diesem Durchlauf eine Populationsgröße von $150$ Agenten angenommen. Die Koeffizienten für die in Kapitel \ref{subsec:neat_species} vorgestellte Kompatibilitätsfunktion sind $c_1=1.0$, $c_2=1.0$ und $c_3=0.4$. Ein Genom wird einer Spezies zugeordnet, wenn die berechnete Kompatibilität kleiner als der Schwellwert $\delta_t=3.0$ ist. Auch in dieser Arbeit wird ein Elitismus implementiert, welcher in Kapitel \ref{subsubsec:ea_selection} vorgestellt ist. Der beste Agenten jeder Spezies, welche mehr als $5$ Mitglieder besitzt, wird unverändert in die nächste Generation kopiert. Des weiteren erhält eine Spezies nur Nachkommen zugewiesen, wenn in den letzten $15$ Generationen eine Steigerung des maximal erreichten Fitnesswertes erzielt wurde. Zuletzt sind noch die Wahrscheinlichkeiten für die Mutation und Rekombination zu bestimmen. Es Besteht für jedes Verbindungsgewicht eine Chance von $80\%$, dass dieses mutiert wird. In diesem Fall wird es mit einer Wahrscheinlichkeit von $10\%$ zufällig neu gewählt, andernfalls wird eine Gauss-Mutation durchgeführt, bei welcher ein Zufallswert auf das Gewicht addiert wird. Zusätzlich besteht für jedes Genom eine Chacnce von $3\%$, dass ein neues Neuron hinzugefügt wird. Die Chance für eine neue Verbindung liegt bei  $5\%$. Bezüglich der Rekombination besteht eine Chance von $25\%$, dass eine Verbindung, welche in beiden Elternteilen deaktiviert ist, im Nachkommen wieder aktiviert wird. 
\\\\
Mit diesen Parametern wird das XOR-Problem $100$ mal nacheinander durchgeführt und die Anzahl an Generationen gemessen, welche zum Lösen des Problems benötigt werden. Die Ergebnisse zeigen, dass im Schnitt nach $\approx 38$ Generationen ein \ac{KNN} das Optimierungsproblem erfolgreich lösen kann. Im besten Durchlauf wurden nur $5$ Generationen und im längsten Durchlauf $98$ Generationen benötigt. Wie zu erkennen ist, können die Werte sich sehr unterscheiden, dennoch sind in allen $100$ Durchläufen gültige Lösungen gefunden worden und zumindest im Rahmen von diesem Test ist die korrekte Funktionalität bewiesen. Zudem sind die erhaltenen Werte ähnlich zu denen aus der originalen Publikation in Quelle \cite{stanley2002evolving}, bei welchem durchschnittlich $32$ Generationen und die längste Durchlauf $90$ Generationen zum Lösen des Optimierungsproblems benötigt hat. Zwar sind die erhaltenen Werte in dieser Arbeit etwas schlechter, aber die Unterschiede sind minimal und durch die hohe Varianz der Ergebnisse vernachlässigbar.
\\\\
Das Python Paket mit dem Namen neat-python aus Quelle \cite{mcintyre_neatpython}, welches eine weit verbreitete Implementierung des \ac{NEAT} Algorithmus ist, verwendet eine andere Konfiguration für das XOR-Problem. Zusätzlich sind in dieser Implementierung einige Anapssungen durchgeführt worden, welche eine bessere Performanz bieten sollen. Beispielsweise wird bei der Berechnung des Kompatibilitätswertes die Anzahl an \emph{excess genes} und \emph{disjoint genes} durch den Wert $N$ dividiert. Bei kleinen \ac{KNN} ist dieser Wert $1$ und andernfalls die Größe des \ac{KNN}. Bei der neat-python Implementierung hingegen wird immer durch die Größe des \ac{KNN} dividiert. Zusätzlich verwendet diese Implementierung bedeutend höhere Wahrscheinlichkeiten für die strukturellen Mutationen. Diese Anpassungen werden für die Implementierung dieser Arbeit übernommen und das XOR-Problem erneut getestet. Die Wahrscheinlichkeit, dass eine neue Verbindung hinzugefügt wird liegt bei $50\%$ anstelle der $5\%$ aus der originalen Publikation. Ein neues Neuron wird mit einer Wahrscheinlichkeit von $20\%$ hinzugefügt. Zuletzt wird der Faktor $c_3$ der Kompatibilitätsfunktion auf $0.5$ erhöht. Zuletzt wird auch die Aktivierungsfunktion geändert, hierbei wurden die besten Ergebnisse mit der \ac{tanh} Funktion erzielt. Das Problem wurde erneut $100$ mal nacheinander evaluiert und die Anzahl an Generationen zur Lösung gemessen. Mit der vorgestellten Konfiguration wurden durchschnittlich $\approx 18$ Generationen benötigt, bis ein Agent das XOR-Problem erfolgreich gelöst hat. Im besten Durchlauf hat ein Agent bereits nach $4$ Generationen eine Lösung gefunden, beim schlechtesten Durchlauf wurde ein Ergebnis erst nach Generation $49$ gefunden. Diese Ergebnisse sind im Vergleich zur originalen Implementierung schneller gewesen und daher werden die Änderungen beibehalten und für die nachfolgenden Verfahren angewendet.
\begin{figure}[!h]
	\centering
	\begin{minipage}[b]{0.49\textwidth}
		\includegraphics[width=1.0\textwidth]{./img/xor_single_core/xor_neural_network.png} 
		%\caption{Lösung für das XOR-Problem mit einem \emph{Hidden}-Neuron}
		%\label{fig:xor_solution_minimal}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.49\textwidth}
		\includegraphics[width=1.0\textwidth]{./img/xor_single_core/xor_fitness_.png} 
		%\caption{Lösung für das XOR-Problem mit einem \emph{Hidden}-Neuron}
	\end{minipage}
	\caption{Links die Lösung für das XOR-Problem mit einem \emph{Hidden}-Neuron, rechts die dazugehörigen Fitnesswerte pro Generation}
	\label{fig:xor_solution_minimal}
\end{figure}
\\\\
Zuletzt soll die tatsächlich erhaltene Lösung genauer betrachtet werden. Im Schnitt hat \ac{NEAT} Lösungen mit 2 oder 3 \emph{Hidden}-Neuronen entwickelt. Allerdings sind auch einige \ac{KNN} entstanden, welche hiervon nur eines und somit die minimale Struktur besitzen, welche zum Lösen des XOR-Problems benötigt wird. Eine solches \ac{KNN}, welches am Ende einer Evaluation entstanden ist, ist in Abbildung \ref{fig:xor_solution_minimal} links dargestellt. Die eigentliche Darstellung ist mithilfe der implementierten Visualisierung  erstellt worden, welche die Pakete NetworkX und Matplotlib nutzt. Bei solchen Darstellungen ist zu beachten, dass die Organgen Neuronen vom Typ \emph{Input}, die grünen vom Typ \emph{Hidden} und die blauen vom Typ \emph{Output} sind. Die Zahlen auf den Neuronen repräsentieren die jeweilige ID während die Pfeile die Verbindungen zwischen den Neuronen darstellen. Für eine bessere Übersichtlichkeit wird in der Darstellung auf die Gewichte verzichtet. Prinzipiell kann eine solche Darstellung auch gestrichelte Verbindungen enthalten. Diese sind dann im Genom deaktiviert und werden nicht für die Berechnungen verwendet. Rechts in der Abbildung ist der Verlauf des maximalen, minimalen und durchschnittlichen Fitnesswertes für jede Generation dargestellt. Auch diese Abbildung wird mit Matplotlib im Rahmen des implementierten \emph{FitnessReporters} automatisch erstellt und zeigt einige interessante Eigenschaften. Der durchschnittliche Fitnesswert steigt trotz einiger Einbrüche relativ kontinuierlich an. Hieraus lässt sich schließen, dass auch die Population im ganzen Fortschritte erzielt. Der maximale Fitnesswert hingegen, stagniert für einige Generationen am Wert $9$. Der Grund hierfür liegt in der Fitnessfunktion. Ein einfaches \ac{KNN} ohne \emph{Hidden}-Neuronen kann drei Werte des XOR-Problems richtig bestimmen. Ist dies der Fall, ergibt die Fitnessfunktion den Wert $9$. Ab diesem Zeitpunkt wird kein Fortschritt des Fitnesswertes erzielt, bis das neue Neuron erfolgreich in die Struktur integriert ist. Der minimale Fitnesswert ist im gesamten Verlauf sehr gering. Der Grund hierfür ist, dass durch unpassende Mutationen oder Rekombinationen Genome entstehen können, bei denen die negativen Eigenschaften überwiegen. 
\begin{figure}[!h]
	\centering
	\includegraphics[width=0.5\textwidth]{./img/xor_single_core/xor_time.png} 
	\caption{Ausführungszeiten des XOR-Problems auf einem Raspberry Pi 4 mit einem Prozess}
	\label{fig:xor_single_core_performance}
	% TODO Eventuell Pfeile bei reduce hinzufügen?
\end{figure}
\\\\
Abbildung \ref{fig:xor_single_core_performance} zeigt die Ausführungszeit des Verfahrens in Sekunden für jede Generation an. Auch dieser Graph wird wie die anderen zuvor automatisch mit dem Paket Matplotlib generiert und zeigt drei verschiedene Phasen an. Der blaue Bereich zeigt \emph{Evaluation Time } an, welche die benötigte Evaluationszeit für alle Agenten darstellt. Der grüne Balken repräsentiert die \emph{Compose Offspring Time}, welche die Zeit für die Rekombination und Mutation aller Agenten umfasst. Die verbleibenden Aktionen bezüglich \ac{NEAT}, wie zum Beispiel das Sortieren der Agenten in die verschiedenen Spezies wird im Rahmen der \emph{Reproduction Time} erfasst, welche mit dem grünen Balken repräsentiert wird. Somit wird die Zeit, welche beispielsweise zum Speichern der Zwischenergebnisse benötigt wird nicht erfasst, da diese das Ergebnis verfälschen würde. Insgesamt ist bezüglich des XOR-Problems zu erkennen, dass die Ausführungszeit tendenziell mit zunehmenden Generationen ansteigt. Dies kann durch den erhöhten Rechenaufwand erklärt werden, welcher durch größere \ac{KNN} entsteht. Des weiteren ist auffällig, dass für die letzte Generation keine \emph{Reproduction Time} oder \emph{Compose Offspring Time} erfasst wurde. Der Grund hierfür ist, dass nach der evaluierten Generation die Abbruchbedingung überprüft wird, welche in diesem Fall die Ausführung beendet und daher wird  keine neue Generation erstellt. Zuletzt soll noch die allgemeine Ausführungszeit und das Verhältnis der verschiedenen Phasen betrachtet werden. Zu erkennen ist, dass die Ausführungszeit pro Generation weniger als eine halbe Sekunde benötigt. Dies ist vor allem für Testzwecke ein großer Vorteil, da der Effekt von Änderungen schnell beobachtet werden kann. Zusätzlich ist zu erkennen, dass die meiste Zeit für das Erstellen und Mutieren von neuen Genomen und Agenten benötigt wird. Allerdings ist diese Verteilung unter Umständen nicht repräsentativ, da die XOR-Funktion ein sehr einfaches Problem ist, welches nur wenige Instruktionen umfasst. Daher werden im nächsten Kapitel aufwändigere Optimierungsprobleme betrachtet.
