% !TeX spellcheck = de_DE
\section{Anforderungen}
\label{sec:requirements}
Aus dem Untertitel dieser Arbeit \emph{Analyse und Optimierung von \ac{NEAT} für ein verteiltes System} können drei verschiedene Ziele abgeleitet werden, mit welchen sich die folgenden Kapitel beschäftigten. Das erste Ziel ist die Implementierung einer sequentiellen Version des \ac{NEAT} Algorithmus. Hierauf basiert die zweite Phase, in welcher die korrekte Funktionalität der Implementierung verifiziert sowie eine Performance Analyse durchgeführt wird. 
Basierend auf der Analyse ist das dritte Ziel die Optimierung des Algorithmus mit \ac{MPI} für einen Bewoulf Cluster
\\\\
Dieses Kapitel befasst sich mit dem ersten Ziel, der Implementierung des sequenziellen Algorithmus. Hierzu werden in einem ersten Schritt verschiedene Anforderungen an die Software definiert, welche sowohl von der sequenziellen als auch der später vorgestellten parallelisierten Implementierung erfüllt werden müssen. Danach wird auf die verschiedenen Datenstrukturen, Schnittstellen und Implementierungsdetails eingegangen.
\\\\
Die erste Anforderung betrifft die Programmiersprache. Für dieses Projekt soll die Sprache Python verwendet werden. Dies ist eine moderne, einfach zu lernende Hochsprache, deren Vorteile eine einfache Syntax sowie die dynamische Typisierung von Variablen und Parametern sind. Dies ermöglicht in vielen Fällen eine schnelle Entwicklung von Prototypen oder auch vollwertigen Softwaresystemen. Zusätzlich bietet die Sprache viele verschiedene \emph{open source} Pakete, welche einfach in bestehende Projekte integriert werden können und fertige Lösungen für diverse Aufgabengebiete bieten. Aus diesem Grund ist Python eine der bekanntesten Sprachen im Bereich Forschung und Entwicklung \cite{dalcin2011parallel}. Dies gilt insbesondere für die Bereiche \emph{Machine Learning} und \ac{KNN}, da viele hierfür verwendete Bibliotheken primär für Python entwickelt sind, wie beispielsweise Tensorflow \cite{tensorflow2015}, Pytorch \cite{pytorch2019} und das OpenAI Gym \cite{OpenAiGym2016}. Letzteres ist eine Bibliothek, welche verschiedene Testumgebungen für das bestärkende Lernen bietet und welche auch in dieser Arbeit eingesetzt wird.  
\\\\
Die nächste Anforderung betrifft das Projekt selbst. Dieses soll wie eine Bibliothek eingesetzt werden können und muss somit eine einfache Programmierschnittstelle für den Anwender bieten. Das Ziel ist, dass mit wenig Aufwand verschiedene Optimierungsprobleme umgesetzt und gelöst werden können. Dies soll sowohl für Testumgebungen aus dem OpenAI Gym als auch für andere Quellen gelten. 
\\\\ % kapitel REF
Eine weitere wichtige Anforderung ist, dass der ganze Optimierungsprozess mithilfe eines \emph{Seeds} beeinflussbar und somit wiederholbar sein muss. Der Grund hierfür ist, dass wie in Kapitel \ref{sec:evolutionary_algos} und Kapitel \ref{sec:neat} aufgezeigt, neuroevolutionäre Algorithmen viele Zufallswerte verwenden, die den Ablauf und das erhaltene Ergebnis stark beeinflussen können. Für einen einfachen Vergleich zwischen der sequentiellen und parallelisierten Implementierung ist es notwendig, dass beide Algorithmen exakt denselben Ablauf an Instruktionen und dieselben Zufallswerte haben und somit letztendlich auch dieselbe Lösung liefern. Dies ist für einen sequenziellen Algorithmus einfach umzusetzen, wenn ein globaler Zufallsgenerator mithilfe eines \emph{Seeds} verwendet wird. Bei der Verwendung eines Beowulf Clusters ist dies nicht möglich, da hierbei physisch getrennte Geräte verwendet werden. Somit ist die Herausforderung, dass sowohl der sequenzielle als auch der parallelisierte Algorithmus unabhängig von der Anzahl an verwendeten Geräten unter Verwendung desselben \emph{Seeds} dieselben Lösungen berechnen.
\\\\
Zwei weitere wichtige Anforderungen betreffen die Performance und Visualisierung. Sowohl in der sequenziellen als auch der parallelisierten Implementierung muss es möglich sein, die benötigte Ausführungszeit zu messen. Die hierbei erhaltenen Ergebnisse sind die Grundlage für den späteren Performance Vergleich. Zusätzlich sollen die erfassten Werte in entsprechenden Diagrammen visualisiert werden können. Neben den Zeiten sollen auch die durch \ac{NEAT} erzielten Ergebnisse dargestellt werden. Dies umfasst unter anderem die Struktur der optimierten \ac{KNN}, die erreichten Fitnesswerte, die Verteilung der Spezies (TODO Eventuell weg?) und in einigen Fällen auch die Lösungsstrategie. Letzteres bezieht sich vor allem auch auf das OpenAI Gym. Die Testumgebungen von diesem können in vielen Anwendungsfällen gerendert werden, was allerdings die Laufzeit enorm erhöht. Deswegen ist es bei dem eigentlichen Optimierungsprozess üblich, hierauf zu verzichten. Das letzte Ziel bezüglich der Visualisierung ist, dass ein gespeichertes Genom nach einem Trainingsverfahren geladen werden kann, hieraus ein \ac{KNN} gebildet wird und die Interaktion von diesem in der Testumgebung gerendert wird. Hierdurch ist es möglich, die entwickelten Strategien und Fortschritte nachzuverfolgen, ohne die Trainingszeit zu erhöhen.
\\\\
Hieraus ergibt sich auch die letzte Anforderung, die persistente Speicherung der Ergebnisse. Es soll möglich sein, die Genome, Fitnesswerte und gemessenen Laufzeiten persistent in einer Datei abzuspeichern. Die Speicherung der Genome ist Voraussetzung, dass diese visualisiert oder auch in einer Produktivumgebung eingesetzt werden können. Bezüglich der Fitnesswerte und Laufzeiten wäre es theoretisch möglich, die erstellten Graphen als Bilddatei oder Ähnliches zu speichern. Dies hat den Nachteil, dass die Werte nicht automatisiert ausgelesen werden können und ein genauer Vergleich mit anderen Datensätzen schwierig ist. Aus diesem Grund sollen in dieser Arbeit die Rohdaten gespeichert werden, sodass auch eine nachträgliche Verarbeitung beziehungsweise ein Vergleich mit anderen Durchläufen möglich ist. Neben der generellen Speicherung der finalen Ergebnisse soll auch eine regelmäßige Zwischenspeicherung möglich sein, zum Beispiel nach jeder Generation. Der Grund hierfür ist \ac{MPI}. In Kapitel \ref{subsubsec:mpi_and_mapreduce} ist erläutert, dass dieses beim Auftreten von Fehlern die Ausführung komplett abbricht und nicht gespeicherte Ergebnisse verloren gehen. Durch die Speicherung der Zwischenergebnisse entsteht kein Datenverlust und somit auch keine Verschwendung der bisher genutzten Rechenzeit.


