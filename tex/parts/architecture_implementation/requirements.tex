% !TeX spellcheck = de_DE
\section{Anforderungen}
\label{sec:requirements}
Aus dem Untertitel dieser Arbeit \emph{Analyse und Optimierung von \ac{NEAT} für ein verteiltes System} lassen sich drei verschiedene Ziele ableiten, mit welchen sich die folgenden Kapitel beschäftigten. Das erste Ziel ist die Implementierung einer sequenziellen Version des \ac{NEAT} Algorithmus. Hierauf basiert die zweite Phase, in welcher die korrekte Funktionalität der Implementierung verifiziert sowie eine Performance Analyse durchgeführt wird. Basierend auf der Analyse ist die Optimierung des Algorithmus mit \ac{MPI} für einen Beowulf-Cluster als das dritte Ziel dieser Arbeit zu benennen.
\\\\
Dieses Kapitel befasst sich mit dem ersten Ziel, der Implementierung des sequenziellen Algorithmus. Hierzu werden in einem ersten Schritt verschiedene Anforderungen an die Software definiert, welche sowohl von der sequenziellen als auch der später vorgestellten parallelisierten Implementierung erfüllt werden müssen. Danach wird auf die verschiedenen Datenstrukturen, Schnittstellen und Implementierungsdetails eingegangen.
\\\\
Die erste Anforderung betrifft die Programmiersprache. Für dieses Projekt soll die moderne, einfach zu lernende Hochsprache Python verwendet werden, deren Vorteile eine einfache Syntax sowie die dynamische Typisierung von Variablen und Parametern sind. Dies ermöglicht in vielen Fällen eine schnelle Entwicklung von Prototypen oder auch vollwertigen Softwaresystemen. Zusätzlich bietet die Sprache viele verschiedene \emph{Open-Source}-Pakete, welche einfach in bestehende Projekte integriert werden können und fertige Lösungen für diverse Aufgabengebiete bieten. Aus diesem Grund ist Python eine der bekanntesten Sprachen im Bereich der Forschung und Entwicklung \cite{dalcin2011parallel}. Dies gilt insbesondere für die Bereiche des \emph{Machine Learning} sowie der \ac{KNN}, da viele der hierfür verwendeten Bibliotheken primär für Python entwickelt sind, wie beispielsweise \emph{Tensorflow} \cite{tensorflow2015}, \emph{PyTorch} \cite{pytorch2019} und das \emph{OpenAI Gym} \cite{OpenAiGym2016}. Bei Letzterem handelt es sich um eine Bibliothek, welche verschiedene Testumgebungen für das bestärkende Lernen bietet und auch in dieser Arbeit eingesetzt wird.  
\\\\
Die nächste Anforderung betrifft das Projekt selbst. Dieses soll wie eine Bibliothek eingesetzt werden können und muss somit eine einfache Programmierschnittstelle für den Anwender bieten. Das Ziel ist, dass mit wenig Aufwand verschiedene Optimierungsprobleme umgesetzt und gelöst werden können. Dies soll sowohl für Testumgebungen aus dem \emph{OpenAI Gym} als auch für andere Quellen gelten. 
\\\\ % kapitel REF
Eine weitere wichtige Anforderung ist, dass der gesamte Optimierungsprozess mithilfe eines \emph{Seeds} beeinflussbar und somit wiederholbar sein muss. Der Grund hierfür ist, dass, wie in Kapitel \ref{sec:evolutionary_algos} und Kapitel \ref{sec:neat} aufgezeigt, neuroevolutionäre Algorithmen viele Zufallswerte verwenden, die den Ablauf und das erhaltene Ergebnis stark beeinflussen. Für einen einfachen Vergleich zwischen der sequenziellen und parallelisierten Implementierung ist es notwendig, dass beide Algorithmen exakt dieselben Zufallswerte haben und somit letztendlich auch dieselbe Lösung liefern. Dies ist für einen sequenziellen Algorithmus einfach umzusetzen, wenn ein globaler Zufallsgenerator mithilfe eines \emph{Seeds} verwendet wird. Bei der Verwendung eines Beowulf-Clusters ist dies durch die Verwendung physisch getrennter Geräte nicht möglich. Somit ist die Herausforderung, dass sowohl der sequenzielle als auch der parallelisierte Algorithmus, unabhängig von der Anzahl an verwendeten Geräten, unter Verwendung desselben \emph{Seeds} dieselben Lösungen berechnen.
\\\\
Zwei weitere wichtige Anforderungen betreffen die Performance und Visualisierung. Sowohl in der sequenziellen als auch der parallelisierten Implementierung besteht die Notwendigkeit, die benötigte Ausführungszeit zu messen. Die hierbei erhaltenen Ergebnisse sind die Grundlage für den späteren Performance Vergleich. Zusätzlich sollen die erfassten Werte in entsprechenden Diagrammen visualisiert werden können. Neben den Zeiten sollen auch die durch \ac{NEAT} erzielten Ergebnisse dargestellt werden. Dies umfasst unter anderem die Struktur der optimierten \ac{KNN}, die erreichten Fitnesswerte und in einigen Fällen auch die Lösungsstrategie. Letzteres bezieht sich vor allem auch auf das \emph{OpenAI Gym}, dessen Testumgebungen in vielen Anwendungsfällen gerendert werden können, was allerdings die Laufzeit enorm erhöht. Deswegen ist es beim eigentlichen Optimierungsprozess üblich, hierauf zu verzichten. Das letzte Ziel bezüglich der Visualisierung ist, dass ein gespeichertes Genom nach einem Trainingsverfahren geladen werden kann, hieraus ein \ac{KNN} gebildet wird und die Interaktion von diesem in der Testumgebung gerendert wird. Hierdurch ist es möglich, die entwickelten Strategien und Fortschritte nachzuverfolgen, ohne die Trainingszeit zu erhöhen.
\\\\
Hieraus ergibt sich auch die persistente Speicherung der Ergebnisse als letzte Anforderung sowohl an die sequenzielle als auch an die parallelisierte Implementierung. Es soll möglich sein, die Genome, Fitnesswerte und gemessenen Laufzeiten persistent in einer Datei abzuspeichern. Die Speicherung der Genome ist Voraussetzung dafür, dass diese visualisiert oder auch in einer Produktivumgebung eingesetzt werden können. Bezüglich der Fitnesswerte und Laufzeiten wäre es theoretisch möglich, die erstellten Graphen als Bilddatei zu speichern. Dies hat den Nachteil, dass die Werte nicht automatisiert ausgelesen werden können und ein genauer Vergleich mit anderen Datensätzen schwierig ist. Aus diesem Grund sollen in dieser Arbeit die Rohdaten gespeichert werden, sodass auch eine nachträgliche Verarbeitung beziehungsweise ein Vergleich mit anderen Durchläufen möglich ist. Neben der generellen Speicherung der finalen Ergebnisse ist zusätzlich eine regelmäßige Zwischenspeicherung, die beispielsweise nach jeder Generation erfolgt, angestrebt. Der Grund hierfür ist \ac{MPI}. In Kapitel \ref{subsubsec:mpi_and_mapreduce} ist erläutert, dass dieses beim Auftreten von Fehlern die Ausführung komplett abbricht und nicht gespeicherte Ergebnisse verloren gehen. Durch die Speicherung der Zwischenergebnisse entsteht kein Datenverlust und somit auch keine Verschwendung der bisher genutzten Rechenzeit.


